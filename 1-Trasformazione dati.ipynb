{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impostiamo il path della cartella contenente i file originali e il path della cartella in cui si vuole che vengano memorizzati i file .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "root=r'C:\\Users\\Luca\\Downloads\\acousticbrainz-lowlevel-json-20150129\\acousticbrainz-lowlevel-json-20150129\\lowlevel'\n",
    "## inserite in root l'url della cartella in cui avete salvato le cartelle del dataset che hanno nomi ad una sola cifra (0,1,..)\n",
    "\n",
    "folder=r'C:\\Users\\Luca\\Desktop\\Univ\\Univ\\3 anno\\Big Data\\PROGETTO_BIGDATA_2019\\CSV\\caricare'\n",
    "## inserite in folder l'url della cartella in cui volete che vengano salvati i fle CSV\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### chiaramente nell'url che inserite in root devono esserci solo le cartelle che volete elaborare perchè lo script elabora \n",
    "### in automatico tutte le cartelle che sono presenti in root\n",
    "\n",
    "###una volta inseriti root e folder far partire le celle qui sotto e verrà fatto tutto in automatico...\n",
    "### se potete andate in impostazioni del pc e impostate SOSPENSIONE: MAI....su windows 10:\n",
    "###  impostazioni -> sistema -> alimentazione e sospensione"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installiamo il modulo 'musicbrainzngs' che ci serve per interrogare il database 'MusicBrainz per recuperare eventualmente i generi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### questa cella va eseguita solo da Francesca che non ha (credo) ancora installato il modulo 'musicbrainzngs'\n",
    "!pip install musicbrainzngs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importiamo i moduli necessari "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import musicbrainzngs as mb\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La seguente funzione è necessaria per normalizzare i file originali dei brani in un'unica riga, in quanto restituisce le posizioni dei dati annidati che sono aggregati in liste, i quali andranno trsformati in dati numerici saparati "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def klist(f,l=[]):\n",
    "    li=[]\n",
    "    if type(f) is list:\n",
    "        if type(f[0]) is list:\n",
    "            return 'll'\n",
    "        return 'l'\n",
    "    elif type(f) is dict:\n",
    "        for k,v in f.items():\n",
    "            t=klist(v,l+[k])\n",
    "            if t=='l':\n",
    "                li.append(l+[k])\n",
    "            elif t=='ll':\n",
    "                li.append(l+[k,'l'])  \n",
    "            elif type(t) is list:\n",
    "                for i in t:\n",
    "                    li.append(l+i)\n",
    "        return li\n",
    "    else:\n",
    "        return 'altro'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La seguente funzione prende in input il vettore dei generi originali e restituisce in output il vettore dei generi aggregati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assegna_genere(generi_originali):\n",
    "    l=[]\n",
    "    for genere_originale in generi_originali:\n",
    "        g=genere_originale.replace(';',' ').replace('.',' ').replace(',',' ').replace(':',' ').replace('!',' ')\\\n",
    "                         .replace('-',' ').replace('\\\\',' ').replace('/',' ').lower().split()\n",
    "        i=0\n",
    "        done=False\n",
    "        while i<len(g) and not done:\n",
    "            \n",
    "            if 'rock' in g[i] or 'country' in g[i] or\\\n",
    "                ('new' in g[i] and (i+1)<len(g) and 'wave' in g[i+1])\\\n",
    "                or ('punk' in g[i] and not 'hardcore' in g):\n",
    "                l.append('Rock')\n",
    "                done=True\n",
    "                \n",
    "            elif 'jazz' in g[i]:\n",
    "                l.append('Jazz')\n",
    "                done=True\n",
    "                \n",
    "            elif 'blues' in g[i]:\n",
    "                l.append('Blues')\n",
    "                done=True\n",
    "                \n",
    "            elif 'metal' in g[i] or ('hardcore' in g[i] and (i+1)<len(g) and 'punk' in g[i+1])\\\n",
    "                or 'grindcore' in g[i]:\n",
    "                l.append('Metal')\n",
    "                done=True\n",
    "                \n",
    "            elif 'ambient' in g[i]:\n",
    "                l.append('Ambient')\n",
    "                done=True\n",
    "                \n",
    "            elif 'funk' in g[i] or ('disco' in g[i] and not 'house' in g and not 'techno' in g):\n",
    "                l.append('Funk')\n",
    "                done=True\n",
    "                \n",
    "            elif 'rap' in g[i] or ('hip' in g[i] and (i+1)<len(g) and 'hop' in g[i+1]):\n",
    "                l.append('Hip-Hop')\n",
    "                done=True\n",
    "                \n",
    "            elif 'classic' in g[i] and not ((i+1)<len(g) and 'rock' in g[i+1]):\n",
    "                l.append('Classical')\n",
    "                done=True\n",
    "                \n",
    "            elif 'house' in g[i] or 'techno' in g[i] or 'hardcore' in g[i] or\\\n",
    "                ('electr' in g[i] and not 'guitar' in g and not 'funk' in g):                                                                                    \n",
    "                l.append('Techno-House')\n",
    "                done=True\n",
    "                \n",
    "            i+=1\n",
    "        \n",
    "        if not done:\n",
    "            l.append('Pop-Altro')\n",
    "    return pd.DataFrame({'GENERE':l})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il codice presente nella seguente cella è il vero e proprio ciclo che trasforma i dati originali in file csv; per la trasformazione dell'intera cartella 'low-level' scaricabile a https://acousticbrainz.org/download sono necessarie almeno 48 ore ininterrotte di elaborazione con un pc di potenza media."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Luca\\Anaconda3\\envs\\msbd\\lib\\site-packages\\ipykernel_launcher.py:156: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\Luca\\\\Desktop\\\\Univ\\\\Univ\\\\3° Anno\\\\Big Data\\\\PROGETTO_BIGDATA_2019\\\\CSV\\\\4_46.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-3861e637cea7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'\\\\'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfold\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'_'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0msbfold\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'.csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\Luca\\\\Desktop\\\\Univ\\\\Univ\\\\3° Anno\\\\Big Data\\\\PROGETTO_BIGDATA_2019\\\\CSV\\\\4_46.csv'"
     ]
    }
   ],
   "source": [
    "D=pd.DataFrame()  ## inizializziamo il dataframe in cui metteremo i dati\n",
    "\n",
    "rec_errlist=[]     ### alcune liste che, alla fine del preprocessamento, conterranno il nome dei files per cui è sorto \n",
    "art_errlist=[]     ### qualche problema e non è stato possibile recuperare il genere. Questi file non vengono inseriti nel \n",
    "notaglist=[]       ### data-frame D e si dovrà decidere che farne\n",
    "structerr=[]\n",
    "\n",
    "\n",
    "for fold in os.listdir(root):\n",
    "    \n",
    "    sbfold_list=os.listdir(root+'\\\\'+fold)\n",
    "    \n",
    "    for sbfold in sbfold_list:\n",
    "        \n",
    "        files=os.listdir(root+'\\\\'+fold+'\\\\'+sbfold)\n",
    "        \n",
    "        del D\n",
    "        D=pd.DataFrame()\n",
    "    \n",
    "        for file in files:   \n",
    "\n",
    "            with open(root+'\\\\'+fold+'\\\\'+sbfold+'\\\\'+file,'r') as f:   \n",
    "                jfile=json.load(f)\n",
    "\n",
    "            ## gen indica se il genere verrà preso direttamente dal file o se verrà effettuata un'interrogazione        \n",
    "            ## infatti alcuni dei file hanno il genere nella sezione metadata, altri no\n",
    "\n",
    "            gen='file'    \n",
    "\n",
    "\n",
    "\n",
    "            ## se la chiave 'genere' non è presente nel dizionario si  interrogherà il database per ottenerlo\n",
    "            try:\n",
    "                jfile['genere']=jfile['metadata']['tags']['genre'][0]   \n",
    "            except:                                                     \n",
    "                gen='int'\n",
    "\n",
    "\n",
    "\n",
    "            ## con il prossimo if si controlla che il genere, anche se presente come chiave, non sia una stringa vuota o una stringa \n",
    "            ##di spazi\n",
    "\n",
    "            if gen=='file' and len(jfile['genere'].replace(' ',''))==0:    \n",
    "                gen='int'                                                  \n",
    "\n",
    "\n",
    "\n",
    "            ## qui inzia il blocco eseguito solo se è necessario ottenere il genere con un interrogazone del database\n",
    "            if gen=='int':\n",
    "\n",
    "                ##alcuni files non hanno l'etichetta 'musicbrainz_recordingid' in ['metadata']['tags'] perciò\n",
    "                ## si usa try except in caso ci sia un KeyError\n",
    "                try:\n",
    "                    jfile['rec_id']=jfile['metadata']['tags']['musicbrainz_recordingid'][0]  \n",
    "                except:\n",
    "\n",
    "                    ## se si presenta un errore si prova comunque ad accedere a 'musicbrainz_artistid'; se c'è di nuovo errore\n",
    "                    ## il genere non è recuperabile in nessun modo e si passa al file successivo con continue\n",
    "                    try:\n",
    "                        jfile['artist_id']=jfile['metadata']['tags']['musicbrainz_artistid'][0]\n",
    "                    except:\n",
    "                        continue\n",
    "\n",
    "                inter='r'     ### variabile che ci dice se i risultati sono presi dal campo 'recording' o dal campo 'artist'\n",
    "\n",
    "\n",
    "                ## si prova ad interrogare il database tramite il recording_id; se c'è un errore (perchè nel punto precedente\n",
    "                ## non si è potuto registrare il recording_id ma solo l'artist_id oppure perchè c'è un errore di connessione)\n",
    "                ## si prova interrogando tramite artist_id\n",
    "                try:\n",
    "                    results=mb.get_recording_by_id(jfile['rec_id'],includes=['tags','user-tags'])\n",
    "                except:\n",
    "                    rec_errlist.append(root+fold+sbfold+file)\n",
    "                    ## se c'è stato errore si prova interroganto tramite artist_id; se si ha successo\n",
    "                    ## la variabile inter assume valore 'a'. Se c'è di nuovo errore il genere non è\n",
    "                    ## in alcun modo recuperabile e si passa al file successivo\n",
    "                    try:\n",
    "                        results=mb.get_artist_by_id(jfile['artist_id'],includes=['tags','user-tags'])\n",
    "                        inter='a'\n",
    "                    except:\n",
    "                        art_errlist.append(root+fold+sbfold+file)\n",
    "                        continue\n",
    "\n",
    "                ## di seguito i due blocchi per il recupero del genere dai risultati dell'interrogazione; i due blocchi if \n",
    "                ## sono necessari perchè a seconda che l'interrogazione sia stata fatta al campo artist o recording, le chiavi \n",
    "                ## per ottenere i tag sono diverse\n",
    "\n",
    "                ## in entrambi i blocchi si usa comunque un costrutto try except perchè in alcuni casi non è presente la chiave\n",
    "                ## 'tag-list' nei risultati; in tal caso e necessario gestire l'errore\n",
    "                if inter=='r':\n",
    "                    try:\n",
    "                        maxcount=max(tag['count'] for tag in results['recording']['tag-list'])\n",
    "                    except:\n",
    "                        try:\n",
    "                            results=mb.get_artist_by_id(jfile['artist_id'],includes=['tags','user-tags'])\n",
    "                            inter='a'\n",
    "                        except:\n",
    "                            art_errlist.append(root+fold+sbfold+file)\n",
    "                            continue\n",
    "                if inter=='a':\n",
    "                    try:\n",
    "                        maxcount=max(tag['count'] for tag in results['artist']['tag-list'])\n",
    "                    except:\n",
    "                        notaglist.append(root+fold+sbfold+file)\n",
    "                        continue\n",
    "\n",
    "\n",
    "                if inter=='r':\n",
    "                    jfile['genere']=[tag['name'] for tag in results['recording']['tag-list'] if tag['count']==maxcount][0]\n",
    "                else:\n",
    "                    jfile['genere']=[tag['name'] for tag in results['artist']['tag-list'] if tag['count']==maxcount][0]\n",
    "\n",
    "\n",
    "                try:\n",
    "                    del jfile['rec_id']\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    del jfile['artist_id']\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "            try:\n",
    "                del jfile['rhythm']['beats_position']\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                del jfile['metadata']\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            vardiag_inv=np.diag(np.diag(jfile['lowlevel']['gfcc']['cov'])**(-0.5))\n",
    "            jfile['lowlevel']['gfcc']['cov']=vardiag_inv.dot(np.array(jfile['lowlevel']['gfcc']['cov']).dot(vardiag_inv))\n",
    "            jfile['lowlevel']['gfcc']['cov']=np.linalg.det(jfile['lowlevel']['gfcc']['cov'])\n",
    "\n",
    "            vardiag_inv=np.diag(np.diag(jfile['lowlevel']['mfcc']['cov'])**(-0.5))\n",
    "            jfile['lowlevel']['mfcc']['cov']=vardiag_inv.dot(np.array(jfile['lowlevel']['mfcc']['cov']).dot(vardiag_inv))\n",
    "            jfile['lowlevel']['mfcc']['cov']=np.linalg.det(jfile['lowlevel']['mfcc']['cov'])\n",
    "\n",
    "            del jfile['lowlevel']['gfcc']['icov']\n",
    "            del jfile['lowlevel']['mfcc']['icov']  \n",
    "\n",
    "            t=klist(jfile)\n",
    "\n",
    "            for i in t:\n",
    "                if len(i)==2:\n",
    "                    jfile[i[0]][i[1]]={str(k):v for k,v in enumerate(jfile[i[0]][i[1]])}\n",
    "                else:\n",
    "                    jfile[i[1]][i[2]][i[3]]={str(k):v for k,v in enumerate(jfile[i[1]][i[2]][i[3]])} \n",
    "\n",
    "            if len(klist(jfile))!=0:\n",
    "                structerr.append(root+fold+sbfold+file)\n",
    "                print('errore di struttura')\n",
    "                continue\n",
    "\n",
    "            D=pd.concat([D,pd.io.json.json_normalize(jfile)],ignore_index=True) \n",
    "            del jfile\n",
    "        \n",
    "        \n",
    "        with open(folder+'\\\\'+fold+'_'+sbfold+'.csv','w'):\n",
    "            pass\n",
    "        \n",
    "        pd.concat([assegna_genere(D['genere']),D],axis=1).to_csv(folder+'\\\\'+fold+'_'+sbfold+'.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
