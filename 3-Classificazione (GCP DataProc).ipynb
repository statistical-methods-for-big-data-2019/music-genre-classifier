{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ATTENZIONE:\n",
    "questo notebook è stato eseguito in ambiente pyspark, utilizzando il cluster e il bucket ad esso collegato(bucketprogetto)\n",
    "per questo non è possibile rieseguire i comandi a meno che non venga creata una macchina virtuale, un nuovo bucket, si importino i file con gli stessi nomi e nelle stesse cartelle, ecc..\n",
    "quindi lasciamo il codice alquanto confuso e spieghiamo in generale cosa si prefigge di fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questo notebook ha lo scopo di analizzare vari modelli per un dataset grande (circa (175000 x 1000) ,training circa (43000 x 1000))\n",
    "per varie combinazioni di iperparametri\n",
    "La parte iniziale riguarda il caricamento dei dati ma anche l'aggiunta di trasformazioni + salvataggio del dataset nuovo su bucket e quindi ricarica dei dati\n",
    "ecco perchè molti pezzi sono commentati, ovviamente bisogna eseguirli se non si hanno i dati pronti\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obiettivi:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install spark-sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vogliamo considerare, per ognuna delle variabili esplicative quantitative già presenti nel dataset, un insieme di trasformazioni non lineari, alcune monotone altre no, da poter aggiungere in modo da considerare nel modello  anche eventuali relazioni non lineari tra le esplicative e la risposta. Per scegliere quali trasformazioni effettivamente aggiungere al dataset valuteremo l'accuratezza di previsione di una LinearDiscriminantAnalysis che abbia come esplicativa solo la trasformazione che si sta considerando; si deciderà quindi di aggiungere tale trasformazione solo se il classificatore così costruito prevede meglio di un classificatore che preveda sempre la classe più frequente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nella cella seguente abbiamo copiato e incollato le funzioni che abbiamo già usato e che useremo in pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "class AbortError(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "class Sost_Mancanti(TransformerMixin):\n",
    "    '''\n",
    "        questa classe e' inseribile in una pipeline di scikitlearn e permette di sostituire eventuali valori mancanti\n",
    "        di un dataset. i parameetri di inzializzazione 'sost_categoriali' e 'elimina' permettono di modificare il comportamento\n",
    "        nel seguente modo:\n",
    "        - se 'sost_categoriali' e' posto uguale a 'True', eventuali valori NaN presenti tra le variabili categoriali del dataset\n",
    "          verranno sostituiti dalla modalita' che le unita' del dataset assumono piu' frequentemente per tali variabili. In caso contrario le\n",
    "          variabili categoriali resteranno inalterate.\n",
    "        - se 'elimina' e' posto pari a 'True' non verra' effettuata alcuna sostitizione ma bensi' verranno eliminate dal dataset tutte le unita' che\n",
    "          assumono valori NaN per almeno una variabile.\n",
    "\n",
    "        I valori Nan presenti nelle variabili quantitative verranno sostituiti con la media delle rispettive variabili, sempre che il parametro\n",
    "        'elimina' non sia 'True'.\n",
    "    '''\n",
    "        \n",
    "    \n",
    "    def __init__(self,sost_categoriali=False,elimina=False):\n",
    "        self.sost_categoriali=sost_categoriali\n",
    "        self.elimina=elimina\n",
    "\n",
    "    def fit(self,X,y=None):\n",
    "        \n",
    "        if self.sost_categoriali:\n",
    "            self.col_quant=X.select_dtypes(include=['int64','float64']).columns\n",
    "            self.col_cat=X.select_dtypes(include=['object']).columns\n",
    "            return self\n",
    "\n",
    "        else:\n",
    "            self.col_quant=X.select_dtypes(include=['int64','float64']).columns\n",
    "            self.col_cat=[]\n",
    "            return self\n",
    "                        \n",
    "\n",
    "    def transform(self,X):\n",
    "        if self.elimina:\n",
    "            for col in self.col_quant:\n",
    "                X=X.drop(D.index([ X[col].isnull()]))\n",
    "            for col in self.col_cat:\n",
    "                X=X.drop(D.index([ X[col].isnull()]))\n",
    "            return \n",
    "                \n",
    "        for col in self.col_quant:\n",
    "            X.loc[ X[col].isnull(), col] = X[col].mean()\n",
    "        for col in self.col_cat:\n",
    "            X.loc[ X[col].isnull(), col] = X[col].value_counts().idxmax()\n",
    "        return X\n",
    "        \n",
    "  \n",
    "class Elimina_Costanti(TransformerMixin):\n",
    "    \n",
    "    '''\n",
    "        questa classe e' inseribile in una pipeline di scikitlearn e permette di eliminare dal dataset eventuali variabili che assumono lo stesso valore su\n",
    "        tutte le unita' del dataset e che non sono percio' informative, permettendo cosi' anche di evitare la creazione di valori NaN nel momento\n",
    "        della standardizzazione (si andrebbe infatti a dividere per la deviazione stardard, che , per tali variabili, sarebbe pari a zero).\n",
    "    '''\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self,X,y=None):\n",
    "        self.col_costanti=[col for col in X.columns if X[col].nunique()==1]\n",
    "        return self\n",
    "\n",
    "    def transform(self,X):\n",
    "        X=X.drop(self.col_costanti,axis=1)\n",
    "        return X\n",
    "\n",
    "\n",
    "\n",
    "class Elimina_Correlate(TransformerMixin):\n",
    "    '''\n",
    "        questa classe e' inseribile in una pipeline di scikitlearn e permette di eliminare dal dataset una variabile per ognuna delle coppie di variabili quantitative\n",
    "        correlate maggiormente di una soglia fissata per default a 0.98 (ma modificabile).Se il parametro 'risparmia_RAM' e' True la funzione fit non calcola all'inizio\n",
    "        una unica matrice di correlazione per tutto il dataset ciclando poi su di essa per trovare le variabili correlate ma calcola ad ogni passo la correlazione\n",
    "        per la coppia di variabili prese in considerazione; questo rende piu' lento l'algoritmo ma permette di non saturare la RAM\n",
    "    '''\n",
    "\n",
    "    def __init__(self,soglia=0.98, risparmia_RAM=False):\n",
    "        self.soglia=soglia\n",
    "        self.risparmia_RAM=risparmia_RAM\n",
    "\n",
    "    def fit(self,X,y=None):\n",
    "        iquant=X.select_dtypes(include=['int64','float64']).columns\n",
    "        self.var_da_togliere=[]\n",
    "        \n",
    "        if self.risparmia_RAM:\n",
    "            for i,ind in enumerate(iquant[:-1]):\n",
    "                if ind in self.var_da_togliere:\n",
    "                    continue                     ### se la variabile e' gia' stata tolta avanzo di una riga\n",
    "                for j in range(i+1,len(iquant)):\n",
    "                    if abs(X.iloc[:,[i,j]].corr().iloc[1,0])>abs(self.soglia) and not iquant[j] in self.var_da_togliere:\n",
    "                        self.var_da_togliere.append(iquant[j])\n",
    "            return self\n",
    "        \n",
    "        corr=X[iquant].corr()\n",
    "        for i,ind in enumerate(corr.index[:-1]):\n",
    "            if ind in self.var_da_togliere:\n",
    "                continue                     ### se la variabile e' gia' stata tolta avanzo di una riga\n",
    "            for j in range(i+1,len(corr.columns)):\n",
    "                if abs(corr.iloc[i,j])>abs(self.soglia) and not corr.columns[j] in self.var_da_togliere:\n",
    "                    self.var_da_togliere.append(corr.columns[j])\n",
    "        return self\n",
    "        \n",
    "\n",
    "    def transform(self,X):\n",
    "        X=X.drop(self.var_da_togliere,axis=1)\n",
    "        return X\n",
    "    \n",
    "                    \n",
    "                    \n",
    "class Standardizza(TransformerMixin):\n",
    "    '''\n",
    "        questa classe e' inseribile in una pipeline di scikitlearn e permette di standardizzare le variabili del dataset permettendo\n",
    "        di scegliere se dividere oppure no per la deviazione standard \n",
    "    '''\n",
    "\n",
    "    def __init__(self,s=True):\n",
    "        self.div_std=s\n",
    "        \n",
    "\n",
    "    def fit(self,X,y=None):\n",
    "        if [col for col in X.select_dtypes(include=['object']).columns]:\n",
    "            print('il dataset contiene variabili categoriali o non numeriche, impossibile standardizzare..')\n",
    "            raise AbortError\n",
    "            \n",
    "        self.media=X.mean()\n",
    "        self.std=X.std()\n",
    "        return self\n",
    "\n",
    "    def transform(self,X):\n",
    "        X-=self.media\n",
    "        if self.div_std:\n",
    "            X/=self.std\n",
    "        return X\n",
    "\n",
    "    def inverse_transform(self,X):\n",
    "        if self.div_std:\n",
    "            X*=self.std\n",
    "        X+=self.media\n",
    "        return X\n",
    "\n",
    "\n",
    "class Ottieni_Dummies(TransformerMixin):\n",
    "    '''\n",
    "        questa classe e' inseribile in una pipeline di scikitlearn e permette di tresformare le variabili categoriali di un dataset in variabili dummy\n",
    "    '''\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self,X):\n",
    "        X=pd.get_dummies(X,drop_first=True)\n",
    "        return X\n",
    "\n",
    "\n",
    "def elimina_ridondanza(D,col_ridondanti=None):\n",
    "    \n",
    "    if not col_ridondanti:\n",
    "        col_ridondanti=[c for c in D.columns if 'erbbands' in c or 'melbands' in c or\\\n",
    "                             'mfcc' in c or 'gfcc' in c or ('hpcp' in c and not 'thpcp' in c) or\\\n",
    "                             c=='rhythm.beats_count']\n",
    "\n",
    "    D=D.drop(col_ridondanti,axis=1)\n",
    "    return X\n",
    "\n",
    "def elimina_generi(D,gen=['Rock','Pop-Altro','Blues','Ambient','Funk']):\n",
    "    t=[i for i in D.index if D.loc[i,'GENERE'] in gen]\n",
    "    D=D.drop(t).reset_index(drop=True)\n",
    "    return D\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caricamento e processamento preliminare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importiamo i dati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "client=storage.Client()\n",
    "bucket = client.get_bucket('bucketprogetto')\n",
    "#bucketprogetto era il nome del bucket collegato al cluster "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nD=pd.DataFrame()\\n\\nfor name in tqdm([str(a)+'_'+str(a)+b+'.csv' for a in ['a','b','c','d','e','f']+[str(i) for i in range(9)] for b in ['a','b','c','d','e','f']+[str(i) for i in range(9)]]):\\n    \\n    blob=storage.blob.Blob('CSV/'+name,bucket)\\n    \\n    try:\\n        content=blob.download_as_string()\\n    except:\\n        continue\\n    T=pd.read_csv(BytesIO(content))\\n    \\n    D=pd.concat([D,elimina_generi(T)],ignore_index=True)\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "D=pd.DataFrame()\n",
    "\n",
    "for name in tqdm([str(a)+'_'+str(a)+b+'.csv' for a in ['a','b','c','d','e','f']+[str(i) for i in range(9)] for b in ['a','b','c','d','e','f']+[str(i) for i in range(9)]]):\n",
    "    \n",
    "    blob=storage.blob.Blob('CSV/'+name,bucket)\n",
    "    \n",
    "    try:\n",
    "        content=blob.download_as_string()\n",
    "    except:\n",
    "        continue\n",
    "    T=pd.read_csv(BytesIO(content))\n",
    "    \n",
    "    D=pd.concat([D,elimina_generi(T)],ignore_index=True)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#D.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### salviamo il dataset semplificato su storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"D.to_csv('D.csv',index=False)\\nblob=bucket.blob('D_senzageneri.csv')\\nblob.upload_from_filename('D.csv')\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''D.to_csv('D.csv',index=False)\n",
    "blob=bucket.blob('D_senzageneri.csv')\n",
    "blob.upload_from_filename('D.csv')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### carichiamo il dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"blob=bucket.blob('D_senzageneri.csv')\\ncontent=blob.download_as_string()\\nD=pd.read_csv(BytesIO(content))\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''blob=bucket.blob('D_senzageneri.csv')\n",
    "content=blob.download_as_string()\n",
    "D=pd.read_csv(BytesIO(content))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#D.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### otteniamo indici Training e Test  (No Validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### creiamo riferimenti a risposta, esplicative quantitative ed esplicative categoriali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y , X_quant_corr, X_cat = D['GENERE'].copy() , D.select_dtypes(include=['int64','float64']).copy(), D.select_dtypes(include=['object']).iloc[:,3:].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creiamo una pipeline di pre_processamento per le esplicative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"pipe=Pipeline([('mancanti',Sost_Mancanti(sost_categoriali=True)),\\n               ('costanti',Elimina_Costanti()),\\n               ('standardizza',Standardizza())])\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''pipe=Pipeline([('mancanti',Sost_Mancanti(sost_categoriali=True)),\n",
    "               ('costanti',Elimina_Costanti()),\n",
    "               ('standardizza',Standardizza())])'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### otteniamo le esplicative preprocessate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_quant_corr=pipe.fit_transform(X_quant_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_quant_corr.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_quant_corr.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scelta delle trasformazioni\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import  accuracy_score\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.dummy import DummyClassifier as DC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mettiamo in una lista le trasformazioni da considerare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "consideriamo la trasformazione seno, esponenziale, densità normale std , cubo e quadrato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trasformazioni={'sin':np.sin,'exp':np.exp,'norm':norm.pdf,'sq':(lambda x: x**2),'cub':(lambda x: x**3)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calcoliamo l'accuratezza di riferimento con cui confrontare l'accuratezza delle trasformazioni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dummy_acc=accuracy_score(y[idx_val], DC(strategy='most_frequent').fit(X_quant_corr.iloc[idx_train,:],y[idx_train]).predict(X_quant_corr.iloc[idx_val,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dummy_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "il classificatore che prevede sempre la classe più frequente ha un'accuratezza del 24.5%...poichè questa soglia è troppo bassa e ci porterebbe ad inserire troppe trasformazioni, la alziamo arbitrariamente a 0.4, in modo da essere sicuri che le trasformazioni che inseriamo nel dataset diano davvero informazione aggiuntiva."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cerchiamo le trasformazioni che ci interessano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cl=LDA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"tr_tenute=[]\\nfor var in tqdm(X_quant_corr.columns):\\n    for ntr,tr in trasformazioni.items():\\n        t=pd.DataFrame(tr(X_quant_corr[var])).rename(columns={var:var+'_'+ntr})\\n        try:\\n            acc=accuracy_score(y[idx_val],cl.fit(t.iloc[idx_train,:] ,y[idx_train]).predict(t.iloc[idx_val,:]))\\n        except:\\n            continue\\n        r=pd.concat([t,X_quant_corr[var]],axis=1).corr().iloc[1,0]  ### calcolo correlazione tra trasf e var originale\\n        if acc>0.4 and not abs(r)>0.9:   ###inserisco solo se la trsformazione non \\xc3\\xa8 troppo correlata \\n            tr_tenute.append(t)\\n            \""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''tr_tenute=[]\n",
    "for var in tqdm(X_quant_corr.columns):\n",
    "    for ntr,tr in trasformazioni.items():\n",
    "        t=pd.DataFrame(tr(X_quant_corr[var])).rename(columns={var:var+'_'+ntr})\n",
    "        try:\n",
    "            acc=accuracy_score(y[idx_val],cl.fit(t.iloc[idx_train,:] ,y[idx_train]).predict(t.iloc[idx_val,:]))\n",
    "        except:\n",
    "            continue\n",
    "        r=pd.concat([t,X_quant_corr[var]],axis=1).corr().iloc[1,0]  ### calcolo correlazione tra trasf e var originale\n",
    "        if acc>0.4 and not abs(r)>0.9:   ###inserisco solo se la trsformazione non è troppo correlata \n",
    "            tr_tenute.append(t)\n",
    "            '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(tr_tenute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_tr=pd.concat(tr_tenute,axis=1) ## DataFrame con solo le trasformazioni"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### standardizziamo le variabili aggiunte, uniamo il tutto e togliamo le correlazioni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_tr=Standardizza().fit(X_tr).transform(X_tr)   ### standardizzo trasformazioni aggiunte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_tr.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'X_qtr_corr=pd.concat([X_quant_corr,X_tr],axis=1)     ### unisco trasformazioni e var originali in un unico dataset\\ndel X_quant_corr\\ndel X_tr'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''X_qtr_corr=pd.concat([X_quant_corr,X_tr],axis=1)     ### unisco trasformazioni e var originali in un unico dataset\n",
    "del X_quant_corr\n",
    "del X_tr'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del tr_tenute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_qtr=Elimina_Correlate(soglia=0.9).fit(X_qtr_corr).transform(X_qtr_corr)     ### elimino var correlate dal dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_qtr.shape[1], X_qtr_corr.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocessiamo anche le variabili categoriali salviamo il dataset definitivo su file in modo da poter ripartire da qui la prossima volta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"pipe3=Pipeline([('mancanti',Sost_Mancanti(sost_categoriali=True)),\\n               ('costanti',Elimina_Costanti()),\\n               ('dummy',Ottieni_Dummies()),\\n               ('standardizza',Standardizza())])\\n\\nX_cat=pipe3.fit_transform(X_cat)\\n\\nD_corr=pd.concat([y,X_qtr_corr,X_cat],axis=1)\\nD=pd.concat([y,X_qtr,X_cat],axis=1)\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''pipe3=Pipeline([('mancanti',Sost_Mancanti(sost_categoriali=True)),\n",
    "               ('costanti',Elimina_Costanti()),\n",
    "               ('dummy',Ottieni_Dummies()),\n",
    "               ('standardizza',Standardizza())])\n",
    "\n",
    "X_cat=pipe3.fit_transform(X_cat)\n",
    "\n",
    "D_corr=pd.concat([y,X_qtr_corr,X_cat],axis=1)\n",
    "D=pd.concat([y,X_qtr,X_cat],axis=1)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#D_corr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### salviamo i dataset creati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"D.to_csv('D1.csv',index=False)\\nblob=bucket.blob('D.csv')#nome a caso  dove andr\\xc3\\xb2 a salvare\\nblob.upload_from_filename('D1.csv')\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''D.to_csv('D1.csv',index=False)\n",
    "blob=bucket.blob('D.csv')#nome a caso  dove andrò a salvare\n",
    "blob.upload_from_filename('D1.csv')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"D_corr.to_csv('D2.csv',index=False)\\nblob=bucket.blob('D_corr.csv')\\nblob.upload_from_filename('D2.csv')\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''D_corr.to_csv('D2.csv',index=False)\n",
    "blob=bucket.blob('D_corr.csv')\n",
    "blob.upload_from_filename('D2.csv')''' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### carichiamo i dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob=bucket.blob('D.csv')\n",
    "content=blob.download_as_string()\n",
    "D=pd.read_csv(BytesIO(content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nblob=bucket.blob('D_corr.csv')\\ncontent=blob.download_as_string()\\nD_corr=pd.read_csv(BytesIO(content))\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "blob=bucket.blob('D_corr.csv')\n",
    "content=blob.download_as_string()\n",
    "D_corr=pd.read_csv(BytesIO(content))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "idx_train, idx_test = train_test_split(D.index.values, test_size=0.75, random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(175506, 1033)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(175506, 1033)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43876, 131630)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(idx_train),len(idx_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividiamo esplicative da risposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "y,X=D['GENERE'],D.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_corr=D_corr.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del D_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X.shape,y.shape,X_corr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((175506, 1032), (175506,))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.hist(y[idx_test])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Ora proviamo a selezionare le variabili più importanti tramite una regressione Lasso sia sul dataset con correlazioni che su quello senza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### prima però troviamo i migliori LDA possibili sia sul dataset con correlazioni che su quello senza, questo per vere un raffronto sul modello che troveremo dopo aver tolto le variabili tramite la lasso. Vogliamo infatti capire se togliere quelle variabili sia effettivamente vantaggioso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensione training set : 43876 unita'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,make_scorer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from spark_sklearn.grid_search import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvs=KFold(random_state=40) #di default sono 3 splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREIAMO UNA BASELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = DummyClassifier()\n",
    "dc0=GridSearchCV(sc,dc,param_grid={\"strategy\":[\"most_frequent\",\"uniform\"]},scoring=make_scorer(accuracy_score),cv=cvs)\n",
    "dc0.fit(X.iloc[idx_train,:],y[idx_train])\n",
    "max(dc0.cv_results_[\"mean_test_score\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## La baseline non arriva al 25% di accuratezza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA + LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ho ristretto la griglia dopo una prima stima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe=Pipeline([('pca',PCA(whiten=True)),\n",
    "               ('lda',LDA(solver='eigen'))])\n",
    "pca_lda=GridSearchCV(sc,pipe,param_grid={'pca__n_components':[100,200,300,400,500,600,700,800,900,1000,1032],'lda__shrinkage':[0,0.01,0.02,0.5,1]},scoring=make_scorer(accuracy_score),cv=cvs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=3, random_state=40, shuffle=False),\n",
       "       error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('pca', PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=True)), ('lda', LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
       "              solver='eigen', store_covariance=False, tol=0.0001))]),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'pca__n_components': [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1032], 'lda__shrinkage': [0, 0.01, 0.02, 0.5, 1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       sc=<SparkContext master=yarn appName=PySparkShell>,\n",
       "       scoring=make_scorer(accuracy_score), verbose=0)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_lda.fit(X.iloc[idx_train,:],y[idx_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 6.192403  ,  7.6289506 ,  9.58170867, 13.79273931, 17.69491394,\n",
       "        20.549107  , 25.53360438, 29.16726065,  5.63935328,  6.78140903,\n",
       "         9.54412405, 12.98745537, 17.47984227, 20.37140171, 24.72460357,\n",
       "        29.16654929,  5.69890229,  6.78317738,  9.73138404, 13.29314971,\n",
       "        17.38771534, 20.59424233, 23.0933853 , 28.28355948]),\n",
       " 'mean_score_time': array([0.23232492, 0.31175073, 0.35736767, 0.46768936, 0.59160868,\n",
       "        0.63444201, 0.66669798, 0.79927834, 0.21737234, 0.29377699,\n",
       "        0.37948338, 0.45444496, 0.56038809, 0.59958792, 0.68972437,\n",
       "        0.82047113, 0.24149958, 0.29353833, 0.39462304, 0.43554163,\n",
       "        0.47862236, 0.64302198, 0.5268654 , 0.58176994]),\n",
       " 'mean_test_score': array([0.80962257, 0.82744553, 0.83633421, 0.84080135, 0.84353633,\n",
       "        0.84811742, 0.85089799, 0.85237943, 0.80923512, 0.82664783,\n",
       "        0.83729146, 0.84052785, 0.84465311, 0.84720576, 0.84998633,\n",
       "        0.85265293, 0.80932628, 0.82621479, 0.83656213, 0.84032273,\n",
       "        0.84392379, 0.84772997, 0.84994074, 0.85253897]),\n",
       " 'mean_train_score': array([0.81124079, 0.83133147, 0.84125719, 0.8476388 , 0.85229968,\n",
       "        0.85749612, 0.86090346, 0.86448171, 0.81063682, 0.83038563,\n",
       "        0.84243094, 0.84803765, 0.85232246, 0.85725682, 0.86100602,\n",
       "        0.86431078, 0.8112408 , 0.83121752, 0.84135975, 0.84760462,\n",
       "        0.85231107, 0.85725683, 0.86121114, 0.86458428]),\n",
       " 'param_lda__shrinkage': masked_array(data=[0, 0, 0, 0, 0, 0, 0, 0, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02,\n",
       "                    0.02, 0.02],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_pca__n_components': masked_array(data=[100, 200, 300, 400, 500, 600, 700, 800, 100, 200, 300,\n",
       "                    400, 500, 600, 700, 800, 100, 200, 300, 400, 500, 600,\n",
       "                    700, 800],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': ({'lda__shrinkage': 0, 'pca__n_components': 100},\n",
       "  {'lda__shrinkage': 0, 'pca__n_components': 200},\n",
       "  {'lda__shrinkage': 0, 'pca__n_components': 300},\n",
       "  {'lda__shrinkage': 0, 'pca__n_components': 400},\n",
       "  {'lda__shrinkage': 0, 'pca__n_components': 500},\n",
       "  {'lda__shrinkage': 0, 'pca__n_components': 600},\n",
       "  {'lda__shrinkage': 0, 'pca__n_components': 700},\n",
       "  {'lda__shrinkage': 0, 'pca__n_components': 800},\n",
       "  {'lda__shrinkage': 0.01, 'pca__n_components': 100},\n",
       "  {'lda__shrinkage': 0.01, 'pca__n_components': 200},\n",
       "  {'lda__shrinkage': 0.01, 'pca__n_components': 300},\n",
       "  {'lda__shrinkage': 0.01, 'pca__n_components': 400},\n",
       "  {'lda__shrinkage': 0.01, 'pca__n_components': 500},\n",
       "  {'lda__shrinkage': 0.01, 'pca__n_components': 600},\n",
       "  {'lda__shrinkage': 0.01, 'pca__n_components': 700},\n",
       "  {'lda__shrinkage': 0.01, 'pca__n_components': 800},\n",
       "  {'lda__shrinkage': 0.02, 'pca__n_components': 100},\n",
       "  {'lda__shrinkage': 0.02, 'pca__n_components': 200},\n",
       "  {'lda__shrinkage': 0.02, 'pca__n_components': 300},\n",
       "  {'lda__shrinkage': 0.02, 'pca__n_components': 400},\n",
       "  {'lda__shrinkage': 0.02, 'pca__n_components': 500},\n",
       "  {'lda__shrinkage': 0.02, 'pca__n_components': 600},\n",
       "  {'lda__shrinkage': 0.02, 'pca__n_components': 700},\n",
       "  {'lda__shrinkage': 0.02, 'pca__n_components': 800}),\n",
       " 'rank_test_score': array([22, 19, 18, 13, 12,  7,  4,  3, 24, 20, 16, 14, 10,  9,  5,  1, 23,\n",
       "        21, 17, 15, 11,  8,  6,  2], dtype=int32),\n",
       " 'split0_test_score': array([0.80842336, 0.82763572, 0.83713934, 0.84110488, 0.8422672 ,\n",
       "        0.84794202, 0.85074525, 0.85149733, 0.80780801, 0.82722549,\n",
       "        0.83693423, 0.84014768, 0.84356625, 0.84657459, 0.85006153,\n",
       "        0.85265965, 0.80767127, 0.82893477, 0.83577191, 0.84055791,\n",
       "        0.84322439, 0.84739505, 0.84978805, 0.85211268]),\n",
       " 'split0_train_score': array([0.81312821, 0.8305641 , 0.84225641, 0.84752137, 0.85350427,\n",
       "        0.85726496, 0.86157265, 0.86389744, 0.81309402, 0.8305641 ,\n",
       "        0.84259829, 0.84765812, 0.85288889, 0.85733333, 0.86088889,\n",
       "        0.86403419, 0.81384615, 0.8314188 , 0.84205128, 0.84820513,\n",
       "        0.85302564, 0.85822222, 0.86123077, 0.86471795]),\n",
       " 'split1_test_score': array([0.81107692, 0.82721368, 0.83644444, 0.84054701, 0.84526496,\n",
       "        0.85059829, 0.85264957, 0.85449573, 0.80977778, 0.82673504,\n",
       "        0.83671795, 0.84013675, 0.84758974, 0.84957265, 0.85210256,\n",
       "        0.85463248, 0.81046154, 0.82700855, 0.83664957, 0.84006838,\n",
       "        0.8465641 , 0.84957265, 0.85176068, 0.8545641 ]),\n",
       " 'split1_train_score': array([0.81186968, 0.83111688, 0.84171481, 0.84841544, 0.85156063,\n",
       "        0.85764589, 0.86020991, 0.86417558, 0.8092031 , 0.82954429,\n",
       "        0.84250111, 0.84841544, 0.85183413, 0.85778264, 0.86027828,\n",
       "        0.86362859, 0.81053639, 0.83101432, 0.84116782, 0.84821032,\n",
       "        0.85132132, 0.85716728, 0.86082527, 0.8641414 ]),\n",
       " 'split2_test_score': array([0.80936752, 0.82748718, 0.8354188 , 0.84075214, 0.84307692,\n",
       "        0.84581197, 0.84929915, 0.8511453 , 0.81011966, 0.82598291,\n",
       "        0.83822222, 0.84129915, 0.84280342, 0.84547009, 0.84779487,\n",
       "        0.85066667, 0.80984615, 0.82270085, 0.83726496, 0.84034188,\n",
       "        0.84198291, 0.84622222, 0.8482735 , 0.85094017]),\n",
       " 'split2_train_score': array([0.80872449, 0.83231343, 0.83980035, 0.84697959, 0.85183413,\n",
       "        0.85757752, 0.86092783, 0.86537212, 0.80961335, 0.83104851,\n",
       "        0.84219343, 0.84803938, 0.85224437, 0.85665447, 0.86185088,\n",
       "        0.86526956, 0.80933985, 0.83121945, 0.84086014, 0.84639841,\n",
       "        0.85258624, 0.85638098, 0.86157738, 0.86489351]),\n",
       " 'std_fit_time': array([0.16758805, 0.47890198, 0.16506977, 0.50354779, 0.37537969,\n",
       "        0.47948817, 0.60276078, 0.97719099, 0.09963639, 0.04921933,\n",
       "        0.15288059, 0.44403255, 0.11380984, 0.11075283, 0.45223774,\n",
       "        0.16393816, 0.16633185, 0.29367007, 0.22557479, 0.75652761,\n",
       "        0.20477058, 0.19626838, 1.59673012, 0.50790572]),\n",
       " 'std_score_time': array([2.10943806e-02, 4.00775795e-03, 6.72421296e-03, 4.59505079e-02,\n",
       "        3.10055949e-03, 2.47620746e-02, 6.37583150e-02, 1.21748890e-02,\n",
       "        1.10035660e-02, 1.25998968e-02, 1.66031805e-02, 3.05699159e-02,\n",
       "        1.52888476e-02, 2.61193549e-02, 1.25484504e-02, 6.22465605e-02,\n",
       "        3.50749726e-02, 1.83142257e-02, 1.50277071e-02, 9.06515043e-03,\n",
       "        1.37777657e-04, 3.67875755e-02, 1.22408584e-01, 1.42987838e-01]),\n",
       " 'std_test_score': array([0.00109823, 0.0001748 , 0.00070672, 0.0002304 , 0.00126622,\n",
       "        0.00195792, 0.00137205, 0.00150331, 0.00101876, 0.00051102,\n",
       "        0.00066404, 0.0005454 , 0.0020997 , 0.00173329, 0.00175939,\n",
       "        0.00161902, 0.00119697, 0.00260616, 0.00061266, 0.00020031,\n",
       "        0.00193453, 0.00138814, 0.00142771, 0.00150985]),\n",
       " 'std_train_score': array([0.00185199, 0.0007301 , 0.0010536 , 0.00059203, 0.00085907,\n",
       "        0.00016582, 0.0005566 , 0.00063977, 0.00174555, 0.00062693,\n",
       "        0.00017257, 0.00030918, 0.00043413, 0.00046374, 0.00064733,\n",
       "        0.00069789, 0.00190593, 0.00016513, 0.00050486, 0.00085292,\n",
       "        0.00072248, 0.00075435, 0.00030736, 0.00032127])}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_lda.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.852652930987328"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(pca_lda.cv_results_[\"mean_test_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('pca', PCA(copy=True, iterated_power='auto', n_components=1032, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=True)), ('lda', LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=0,\n",
       "              solver='eigen', store_covariance=False, tol=0.0001))])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_lda.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('pca', PCA(copy=True, iterated_power='auto', n_components=800, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=True)), ('lda', LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=0.01,\n",
       "              solver='eigen', store_covariance=False, tol=0.0001))])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_lda.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe00=Pipeline([('pca',PCA(whiten=True)),\n",
    "               ('lda',LDA(solver='eigen'))])\n",
    "pca_lda00=GridSearchCV(sc,pipe00,param_grid={'pca__n_components':[100, 200, 300, 400, 500, 600, 700,800,900,1000,1032],'lda__shrinkage':[0]},scoring=make_scorer(accuracy_score),cv=cvs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=3, random_state=40, shuffle=False),\n",
       "       error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('pca', PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=True)), ('lda', LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
       "              solver='eigen', store_covariance=False, tol=0.0001))]),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'pca__n_components': [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1032], 'lda__shrinkage': [0]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       sc=<SparkContext master=yarn appName=PySparkShell>,\n",
       "       scoring=make_scorer(accuracy_score), verbose=0)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_lda00.fit(X.iloc[idx_train,:],y[idx_train])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA + PCA con solver=svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rifare con più valori di pca per il grafico acc-n_comp\n",
    "#creare baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe0=Pipeline([('pca',PCA(whiten=True)),\n",
    "               ('lda',LDA())])\n",
    "pca_lda0=GridSearchCV(sc,pipe0,param_grid={'pca__n_components':[800,900,960,980,990,1000,1010,1020,1032]},scoring=make_scorer(accuracy_score),cv=cvs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=3, random_state=40, shuffle=False),\n",
       "       error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('pca', PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=True)), ('lda', LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
       "              solver='svd', store_covariance=False, tol=0.0001))]),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'pca__n_components': [800, 900, 960, 980, 990, 1000, 1010, 1020, 1032]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       sc=<SparkContext master=yarn appName=PySparkShell>,\n",
       "       scoring=make_scorer(accuracy_score), verbose=0)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_lda0.fit(X.iloc[idx_train,:],y[idx_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([34.50218733, 18.19824235, 19.26414768, 19.99280365, 20.34329502,\n",
       "        20.29002364, 20.34361076, 20.93585602, 20.54009922]),\n",
       " 'mean_score_time': array([0.75784206, 0.85208829, 0.89003142, 0.8888127 , 0.91178497,\n",
       "        0.86921867, 0.87389127, 0.90049974, 0.76232934]),\n",
       " 'mean_test_score': array([0.8516501 , 0.85304039, 0.8535418 , 0.854066  , 0.85395205,\n",
       "        0.85335947, 0.85340505, 0.85349622, 0.85324551]),\n",
       " 'mean_train_score': array([0.86278375, 0.86598595, 0.86780927, 0.86829929, 0.86835627,\n",
       "        0.86831069, 0.86858419, 0.86893746, 0.86878931]),\n",
       " 'param_pca__n_components': masked_array(data=[800, 900, 960, 980, 990, 1000, 1010, 1020, 1032],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': ({'pca__n_components': 800},\n",
       "  {'pca__n_components': 900},\n",
       "  {'pca__n_components': 960},\n",
       "  {'pca__n_components': 980},\n",
       "  {'pca__n_components': 990},\n",
       "  {'pca__n_components': 1000},\n",
       "  {'pca__n_components': 1010},\n",
       "  {'pca__n_components': 1020},\n",
       "  {'pca__n_components': 1032}),\n",
       " 'rank_test_score': array([9, 8, 3, 1, 2, 6, 5, 4, 7], dtype=int32),\n",
       " 'split0_test_score': array([0.84944619, 0.85149733, 0.85218105, 0.85259128, 0.85286476,\n",
       "        0.85265965, 0.85259128, 0.85293313, 0.85245453]),\n",
       " 'split0_train_score': array([0.86215385, 0.86509402, 0.86717949, 0.8674188 , 0.8674188 ,\n",
       "        0.86776068, 0.86830769, 0.86882051, 0.86810256]),\n",
       " 'split1_test_score': array([0.85490598, 0.85606838, 0.85593162, 0.85723077, 0.85647863,\n",
       "        0.85606838, 0.85558974, 0.85606838, 0.85497436]),\n",
       " 'split1_train_score': array([0.86314998, 0.86526956, 0.86721821, 0.86790195, 0.86790195,\n",
       "        0.86783358, 0.86773102, 0.86790195, 0.86769683]),\n",
       " 'split2_test_score': array([0.85059829, 0.85155556, 0.85251282, 0.85237607, 0.85251282,\n",
       "        0.85135043, 0.85203419, 0.85148718, 0.85230769]),\n",
       " 'split2_train_score': array([0.86304742, 0.86759427, 0.86903012, 0.86957711, 0.86974804,\n",
       "        0.8693378 , 0.86971386, 0.87008991, 0.87056853]),\n",
       " 'std_fit_time': array([1.0762796 , 0.29432629, 0.21659566, 0.20272309, 0.18272857,\n",
       "        0.3469332 , 0.29662871, 0.33205219, 0.05447412]),\n",
       " 'std_score_time': array([0.01541205, 0.03720558, 0.0425991 , 0.01033446, 0.0323311 ,\n",
       "        0.02646267, 0.01540034, 0.00668185, 0.15328739]),\n",
       " 'std_test_score': array([0.00234977, 0.00214121, 0.00169525, 0.00223951, 0.0017923 ,\n",
       "        0.00198863, 0.00156144, 0.00191216, 0.00122393]),\n",
       " 'std_train_score': array([0.00044737, 0.00113951, 0.00086341, 0.00092483, 0.00100371,\n",
       "        0.00072689, 0.00083277, 0.00089705, 0.00126896])}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_lda0.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8540660041936367"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(pca_lda0.cv_results_[\"mean_test_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('pca', PCA(copy=True, iterated_power='auto', n_components=980, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=True)), ('lda', LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
       "              solver='svd', store_covariance=False, tol=0.0001))])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_lda0.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8562637696573729"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(pca_lda0.best_estimator_.predict(X.iloc[idx_test]),y[idx_test])\n",
    "#accuratezza sulle prime 20000 unità del test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "### rifacciamo la grid per fare il grafico dell' accuratezza al variare del numero di componenti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe00=Pipeline([('pca',PCA(whiten=True)),\n",
    "               ('lda',LDA())])\n",
    "pca_lda00=GridSearchCV(sc,pipe00,param_grid={'pca__n_components':np.arange(100,800,100)},scoring=make_scorer(accuracy_score),cv=cvs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=3, random_state=40, shuffle=False),\n",
       "       error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('pca', PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=True)), ('lda', LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
       "              solver='svd', store_covariance=False, tol=0.0001))]),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'pca__n_components': array([100, 200, 300, 400, 500, 600, 700])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       sc=<SparkContext master=yarn appName=PySparkShell>,\n",
       "       scoring=make_scorer(accuracy_score), verbose=0)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_lda00.fit(X.iloc[idx_train,:],y[idx_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 6.8722384 ,  7.6902554 , 11.38646706, 15.08707396, 19.72544066,\n",
       "        23.46198273, 25.36757636]),\n",
       " 'mean_score_time': array([0.22618119, 0.28807195, 0.40090569, 0.46444066, 0.54992398,\n",
       "        0.55858898, 0.48525802]),\n",
       " 'mean_test_score': array([0.8087565 , 0.82710366, 0.83560489, 0.84036831, 0.84371866,\n",
       "        0.84647643, 0.84891512]),\n",
       " 'mean_train_score': array([0.80989609, 0.83004375, 0.84104067, 0.84623712, 0.85153615,\n",
       "        0.85628817, 0.85934223]),\n",
       " 'param_pca__n_components': masked_array(data=[100, 200, 300, 400, 500, 600, 700],\n",
       "              mask=[False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': ({'pca__n_components': 100},\n",
       "  {'pca__n_components': 200},\n",
       "  {'pca__n_components': 300},\n",
       "  {'pca__n_components': 400},\n",
       "  {'pca__n_components': 500},\n",
       "  {'pca__n_components': 600},\n",
       "  {'pca__n_components': 700}),\n",
       " 'rank_test_score': array([7, 6, 5, 4, 3, 2, 1], dtype=int32),\n",
       " 'split0_test_score': array([0.8076029 , 0.82736223, 0.83495146, 0.84021605, 0.84363462,\n",
       "        0.84431834, 0.84814714]),\n",
       " 'split0_train_score': array([0.81176068, 0.82929915, 0.84191453, 0.84625641, 0.85148718,\n",
       "        0.85562393, 0.85911111]),\n",
       " 'split1_test_score': array([0.80847863, 0.82810256, 0.83651282, 0.84157265, 0.84588034,\n",
       "        0.84936752, 0.85223932]),\n",
       " 'split1_train_score': array([0.8092031 , 0.83070664, 0.84147551, 0.84667191, 0.85145807,\n",
       "        0.85641517, 0.85894499]),\n",
       " 'split2_test_score': array([0.81018803, 0.82584615, 0.83535043, 0.83931624, 0.84164103,\n",
       "        0.84574359, 0.84635897]),\n",
       " 'split2_train_score': array([0.80872449, 0.83012547, 0.83973197, 0.84578305, 0.85166319,\n",
       "        0.85682541, 0.8599706 ]),\n",
       " 'std_fit_time': array([0.16634059, 0.1267784 , 0.0887303 , 0.14796939, 0.39222725,\n",
       "        1.00194719, 3.06293513]),\n",
       " 'std_score_time': array([0.01580985, 0.02674963, 0.03767063, 0.0103055 , 0.03027527,\n",
       "        0.10362929, 0.06616352]),\n",
       " 'std_test_score': array([0.00107352, 0.00093914, 0.00066234, 0.00092744, 0.00173169,\n",
       "        0.00212547, 0.00246127]),\n",
       " 'std_train_score': array([1.33286538e-03, 5.77506164e-04, 9.42584283e-04, 3.63131158e-04,\n",
       "        9.06164875e-05, 4.98653102e-04, 4.49466677e-04])}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_lda00.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1=[100, 200, 300, 400, 500, 600, 700,800,900,960,980,990,1000,1010,1020,1032]\n",
    "v2=[0.8087565 , 0.82710366, 0.83560489, 0.84036831, 0.84371866,\n",
    "        0.84647643, 0.84891512,0.8516501 , 0.85304039, 0.8535418 , 0.854066  , 0.85395205,\n",
    "        0.85335947, 0.85340505, 0.85349622, 0.85324551]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa56ff08210>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(v1,v2)\n",
    "plt.xlabel('numero componenti')\n",
    "plt.ylabel('accuratezza')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MATRICE DI CONFUSIONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[23998,    91,  1990,   604,  1004],\n",
       "       [   55, 10977,   278,   466,  1685],\n",
       "       [ 1145,   381, 21892,   375,  1598],\n",
       "       [  469,   238,   632, 29379,  1897],\n",
       "       [  763,  1616,  1383,  2250, 26464]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y[idx_test],pca_lda0.best_estimator_.predict(X.iloc[idx_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe17f8fe510>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "y_pred =pca_lda0.best_estimator_.predict(X.iloc[idx_test])\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \n",
    "        \n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = classes\n",
    "    \n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    print(\"Normalized confusion matrix\")\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(15,5))\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    #plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "     #        rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' \n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n",
    "\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plot_confusion_matrix(y[idx_test],pca_lda0.best_estimator_.predict(X.iloc[idx_test]), classes=set(y[idx_test]),\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Il richiamo per una modalità è il numero dei correttamente classificati fratto i veri di quella classe\n",
    "#La precisione per una modalità è il numero dei correttamente classificati fratto tutti quelli classificati con quella classe\n",
    "\n",
    "## gli elementi sulla diagonale sono i richiami delle rispettive classi\n",
    "## la precisione per una classe si calcola come elsulladiag/(sommasucolonna)\n",
    "\n",
    "##l'isoF1 è 2*(p*r)/(p+r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=GridSearchCV(sc,LDA(solver=\"eigen\"),param_grid={\"shrinkage\":np.arange(0.2,-0.01,-0.02)},scoring=make_scorer(accuracy_score),cv=cvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=3, random_state=40, shuffle=False),\n",
       "       error_score='raise',\n",
       "       estimator=LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
       "              solver='eigen', store_covariance=False, tol=0.0001),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'shrinkage': array([2.00000e-01, 1.80000e-01, 1.60000e-01, 1.40000e-01, 1.20000e-01,\n",
       "       1.00000e-01, 8.00000e-02, 6.00000e-02, 4.00000e-02, 2.00000e-02,\n",
       "       1.11022e-16])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       sc=<SparkContext master=yarn appName=PySparkShell>,\n",
       "       scoring=make_scorer(accuracy_score), verbose=0)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.fit(X.iloc[idx_train,:],y[idx_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([4.56301133, 4.10758932, 3.84608666, 3.75467126, 3.88214127,\n",
       "        3.762544  , 3.8688666 , 3.71770732, 3.80989035, 3.68389996,\n",
       "        3.39764961]),\n",
       " 'mean_score_time': array([0.0734907 , 0.07554197, 0.07387161, 0.07507666, 0.07740466,\n",
       "        0.07126339, 0.07482473, 0.07188145, 0.08243688, 0.07853103,\n",
       "        0.06657203]),\n",
       " 'mean_test_score': array([0.83473881, 0.83603793, 0.83749658, 0.83925153, 0.84105206,\n",
       "        0.84232838, 0.84344516, 0.8449494 , 0.84622573, 0.84745647,\n",
       "        0.24810831]),\n",
       " 'mean_train_score': array([0.84143951, 0.84297794, 0.84426566, 0.84563315, 0.84704622,\n",
       "        0.84885814, 0.85090938, 0.85275548, 0.8551486 , 0.85780381,\n",
       "        0.2481083 ]),\n",
       " 'param_shrinkage': masked_array(data=[0.2, 0.18000000000000002, 0.16000000000000003,\n",
       "                    0.14000000000000004, 0.12000000000000005,\n",
       "                    0.10000000000000006, 0.08000000000000007,\n",
       "                    0.06000000000000008, 0.04000000000000009,\n",
       "                    0.0200000000000001, 1.1102230246251565e-16],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': ({'shrinkage': 0.2},\n",
       "  {'shrinkage': 0.18000000000000002},\n",
       "  {'shrinkage': 0.16000000000000003},\n",
       "  {'shrinkage': 0.14000000000000004},\n",
       "  {'shrinkage': 0.12000000000000005},\n",
       "  {'shrinkage': 0.10000000000000006},\n",
       "  {'shrinkage': 0.08000000000000007},\n",
       "  {'shrinkage': 0.06000000000000008},\n",
       "  {'shrinkage': 0.04000000000000009},\n",
       "  {'shrinkage': 0.0200000000000001},\n",
       "  {'shrinkage': 1.1102230246251565e-16}),\n",
       " 'rank_test_score': array([10,  9,  8,  7,  6,  5,  4,  3,  2,  1, 11], dtype=int32),\n",
       " 'split0_test_score': array([0.83454123, 0.83631888, 0.83809654, 0.83994257, 0.84254068,\n",
       "        0.84342951, 0.84363462, 0.84534391, 0.84677971, 0.84787365,\n",
       "        0.24873513]),\n",
       " 'split0_train_score': array([0.84123077, 0.84276923, 0.84410256, 0.84557265, 0.84680342,\n",
       "        0.84851282, 0.85070085, 0.85203419, 0.85517949, 0.8577094 ,\n",
       "        0.24779487]),\n",
       " 'split1_test_score': array([0.83507692, 0.83623932, 0.83788034, 0.83931624, 0.84109402,\n",
       "        0.84266667, 0.84369231, 0.84540171, 0.84649573, 0.84861538,\n",
       "        0.24711111]),\n",
       " 'split1_train_score': array([0.84205668, 0.84328741, 0.84455232, 0.84581724, 0.84738983,\n",
       "        0.84896243, 0.85091108, 0.85309904, 0.85487676, 0.85726984,\n",
       "        0.24860689]),\n",
       " 'split2_test_score': array([0.83459829, 0.83555556, 0.83651282, 0.83849573, 0.83952137,\n",
       "        0.84088889, 0.84300855, 0.84410256, 0.84540171, 0.84588034,\n",
       "        0.24847863]),\n",
       " 'split2_train_score': array([0.84103108, 0.84287717, 0.84414208, 0.84550956, 0.8469454 ,\n",
       "        0.84909918, 0.8511162 , 0.85313323, 0.85538956, 0.85843219,\n",
       "        0.24792315]),\n",
       " 'std_fit_time': array([0.3373358 , 0.1887461 , 0.16157583, 0.05362054, 0.0931957 ,\n",
       "        0.0489296 , 0.02529874, 0.06173234, 0.01247399, 0.02992712,\n",
       "        0.39227715]),\n",
       " 'std_score_time': array([0.00356887, 0.0009991 , 0.00559763, 0.00846358, 0.00309178,\n",
       "        0.00201091, 0.0002034 , 0.00163   , 0.00532265, 0.00307023,\n",
       "        0.01239703]),\n",
       " 'std_test_score': array([0.00024021, 0.00034262, 0.00070119, 0.00059244, 0.00123299,\n",
       "        0.00106443, 0.00030963, 0.00059926, 0.00059408, 0.00115488,\n",
       "        0.00071284]),\n",
       " 'std_train_score': array([0.00044396, 0.00022322, 0.00020335, 0.0001327 , 0.00024979,\n",
       "        0.00025048, 0.00016957, 0.00051022, 0.00021049, 0.0004792 ,\n",
       "        0.00035642])}"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearDiscriminantAnalysis(n_components=None, priors=None,\n",
       "              shrinkage=0.0200000000000001, solver='eigen',\n",
       "              store_covariance=False, tol=0.0001)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8474564682286444"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(p.cv_results_[\"mean_test_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8505"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(p.best_estimator_.predict(X.iloc[idx_test[:20000]]),y[idx_test[:20000]])\n",
    "#accuratezza sulle prime 20000 unità del test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Proviamo LDA con shrinkage=None per vedere se cambia\n",
    "## uso la grid con un solo parametro per possibilità di replicazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1=LDA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/anaconda/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
       "              solver='svd', store_covariance=False, tol=0.0001)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1.fit(X.iloc[idx_train,:],y[idx_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8558"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(p1.predict(X.iloc[idx_test,:][:10000]),y[idx_test][:10000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RIDGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "r=GridSearchCV(sc,LogisticRegression(fit_intercept=False,solver=\"saga\",multi_class=\"multinomial\",warm_start=True,class_weight=\"balanced\",random_state=40),param_grid={'C':[0.05,0.1,0.2,0.6,1.5,200,1e5]},scoring=make_scorer(accuracy_score),cv=cvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=3, random_state=40, shuffle=False),\n",
       "       error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "          fit_intercept=False, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='multinomial', n_jobs=1, penalty='l2',\n",
       "          random_state=40, solver='saga', tol=0.0001, verbose=0,\n",
       "          warm_start=True),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [0.05, 0.1, 0.2, 0.6, 1.5, 200, 100000.0]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       sc=<SparkContext master=yarn appName=PySparkShell>,\n",
       "       scoring=make_scorer(accuracy_score), verbose=0)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.fit(X.iloc[idx_train,:],y[idx_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([112.8649958 , 111.15948439, 112.88175925, 111.42127633,\n",
       "        112.13075995, 112.21429801, 111.48967568]),\n",
       " 'mean_score_time': array([0.10594567, 0.11097089, 0.07519507, 0.08216731, 0.0846947 ,\n",
       "        0.07217232, 0.06845236]),\n",
       " 'mean_test_score': array([0.82286444, 0.82286444, 0.82286444, 0.82288723, 0.82288723,\n",
       "        0.82288723, 0.82288723]),\n",
       " 'mean_train_score': array([0.82837995, 0.82841414, 0.82842553, 0.82841414, 0.82841414,\n",
       "        0.82841414, 0.82841414]),\n",
       " 'param_C': masked_array(data=[0.05, 0.1, 0.2, 0.6, 1.5, 200, 100000.0],\n",
       "              mask=[False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': ({'C': 0.05},\n",
       "  {'C': 0.1},\n",
       "  {'C': 0.2},\n",
       "  {'C': 0.6},\n",
       "  {'C': 1.5},\n",
       "  {'C': 200},\n",
       "  {'C': 100000.0}),\n",
       " 'rank_test_score': array([5, 5, 5, 1, 1, 1, 1], dtype=int32),\n",
       " 'split0_test_score': array([0.82168741, 0.82168741, 0.82168741, 0.82175578, 0.82175578,\n",
       "        0.82175578, 0.82175578]),\n",
       " 'split0_train_score': array([0.82557265, 0.82560684, 0.82564103, 0.82564103, 0.82564103,\n",
       "        0.82564103, 0.82564103]),\n",
       " 'split1_test_score': array([0.82441026, 0.82441026, 0.82441026, 0.82441026, 0.82441026,\n",
       "        0.82441026, 0.82441026]),\n",
       " 'split1_train_score': array([0.83453557, 0.83453557, 0.83453557, 0.83453557, 0.83453557,\n",
       "        0.83453557, 0.83453557]),\n",
       " 'split2_test_score': array([0.82249573, 0.82249573, 0.82249573, 0.82249573, 0.82249573,\n",
       "        0.82249573, 0.82249573]),\n",
       " 'split2_train_score': array([0.82503162, 0.8251    , 0.8251    , 0.82506581, 0.82506581,\n",
       "        0.82506581, 0.82506581]),\n",
       " 'std_fit_time': array([0.33905233, 0.99019185, 0.17104762, 1.13248705, 0.93565944,\n",
       "        1.33182342, 1.450481  ]),\n",
       " 'std_score_time': array([0.00316327, 0.0117272 , 0.00337264, 0.00526134, 0.0106639 ,\n",
       "        0.00402204, 0.00739016]),\n",
       " 'std_test_score': array([0.00114177, 0.00114177, 0.00114177, 0.00111849, 0.00111849,\n",
       "        0.00111849, 0.00111849]),\n",
       " 'std_train_score': array([0.00435828, 0.00433345, 0.00432609, 0.00433487, 0.00433487,\n",
       "        0.00433487, 0.00433487])}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8228872276415352"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(r.cv_results_[\"mean_test_score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA + RIDGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe1=Pipeline([('pca',PCA(whiten=True)),\n",
    "               ('ridge',LogisticRegression(fit_intercept=False,solver=\"saga\",multi_class=\"multinomial\",warm_start=True,class_weight=\"balanced\",random_state=40))])\n",
    "\n",
    "pca_ridge=GridSearchCV(sc,pipe1,param_grid={'pca__n_components':range(32,X.shape[1],100),'ridge__C':[0.05,2,200,1e5]},scoring=make_scorer(accuracy_score),cv=cvs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/anaconda/lib/python2.7/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=3, random_state=40, shuffle=False),\n",
       "       error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('pca', PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=True)), ('ridge', LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "          fit_intercept=False, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='multinomial', n_jobs=1, penalty='l2',\n",
       "          random_state=40, solver='saga', tol=0.0001, verbose=0,\n",
       "          warm_start=True))]),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'pca__n_components': [32, 132, 232, 332, 432, 532, 632, 732, 832, 932], 'ridge__C': [0.05, 2, 200, 100000.0]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       sc=<SparkContext master=yarn appName=PySparkShell>,\n",
       "       scoring=make_scorer(accuracy_score), verbose=0)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_ridge.fit(X.iloc[idx_train,:],y[idx_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([  8.56166371,   8.57385222,   8.83586295,   8.83140095,\n",
       "         22.09583728,  21.83433565,  22.34416135,  22.24869839,\n",
       "         34.95788169,  35.85410237,  35.20329698,  35.67124399,\n",
       "         48.9748071 ,  48.56030265,  49.40970333,  49.0133884 ,\n",
       "         62.68388971,  63.6579361 ,  63.10169363,  63.14547865,\n",
       "         77.80790194,  76.98433868,  78.35658503,  78.54686642,\n",
       "         90.84930793,  91.10645334,  90.58969776,  92.20552262,\n",
       "        106.07869339, 104.5127244 , 106.02823369, 106.36904494,\n",
       "        100.45368997, 102.35714706, 102.55371229,  99.90800667,\n",
       "        113.70990864, 110.00945075, 111.22995623, 112.28901728]),\n",
       " 'mean_score_time': array([0.16662963, 0.17775043, 0.16837533, 0.17364144, 0.23325404,\n",
       "        0.25015998, 0.22549367, 0.2278107 , 0.27296972, 0.31280835,\n",
       "        0.27876377, 0.27037732, 0.36860228, 0.35769256, 0.35522493,\n",
       "        0.34286571, 0.42888141, 0.49576664, 0.45229101, 0.46087098,\n",
       "        0.51260734, 0.49558425, 0.52659933, 0.5078036 , 0.63953535,\n",
       "        0.5677491 , 0.56532232, 0.61611311, 0.66085331, 0.72207928,\n",
       "        0.63461097, 0.65890344, 0.65756035, 0.77993361, 0.71634698,\n",
       "        0.75079107, 0.73911834, 0.7539076 , 0.63598434, 0.68258667]),\n",
       " 'mean_test_score': array([0.76301395, 0.76326465, 0.76353815, 0.76346978, 0.8208132 ,\n",
       "        0.82113228, 0.82085878, 0.82113228, 0.83257362, 0.83398669,\n",
       "        0.83453369, 0.8331662 , 0.83836266, 0.83911478, 0.83875011,\n",
       "        0.83863616, 0.84294375, 0.84216884, 0.84155347, 0.84141672,\n",
       "        0.84529128, 0.84538244, 0.84499499, 0.84613456, 0.84825417,\n",
       "        0.84754763, 0.84775276, 0.8470918 , 0.84770717, 0.84706901,\n",
       "        0.84734251, 0.84731972, 0.85016866, 0.84964445, 0.84964445,\n",
       "        0.84964445, 0.84905187, 0.8484365 , 0.84841371, 0.84841371]),\n",
       " 'mean_train_score': array([0.7637091 , 0.76474611, 0.7645182 , 0.76463215, 0.82465356,\n",
       "        0.82603245, 0.82556523, 0.82459659, 0.84153067, 0.8422714 ,\n",
       "        0.84238535, 0.84170161, 0.85152476, 0.85198059, 0.85266433,\n",
       "        0.85223129, 0.85815708, 0.85853314, 0.85894339, 0.85847616,\n",
       "        0.86557571, 0.86603153, 0.86583781, 0.8658606 , 0.87301714,\n",
       "        0.8729032 , 0.87327923, 0.87278924, 0.87776916, 0.87788312,\n",
       "        0.87738171, 0.8779401 , 0.88306819, 0.88351263, 0.88351263,\n",
       "        0.88351263, 0.88751253, 0.88810511, 0.88810511, 0.88810511]),\n",
       " 'param_pca__n_components': masked_array(data=[32, 32, 32, 32, 132, 132, 132, 132, 232, 232, 232, 232,\n",
       "                    332, 332, 332, 332, 432, 432, 432, 432, 532, 532, 532,\n",
       "                    532, 632, 632, 632, 632, 732, 732, 732, 732, 832, 832,\n",
       "                    832, 832, 932, 932, 932, 932],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_ridge__C': masked_array(data=[0.05, 2, 200, 100000.0, 0.05, 2, 200, 100000.0, 0.05,\n",
       "                    2, 200, 100000.0, 0.05, 2, 200, 100000.0, 0.05, 2, 200,\n",
       "                    100000.0, 0.05, 2, 200, 100000.0, 0.05, 2, 200,\n",
       "                    100000.0, 0.05, 2, 200, 100000.0, 0.05, 2, 200,\n",
       "                    100000.0, 0.05, 2, 200, 100000.0],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': ({'pca__n_components': 32, 'ridge__C': 0.05},\n",
       "  {'pca__n_components': 32, 'ridge__C': 2},\n",
       "  {'pca__n_components': 32, 'ridge__C': 200},\n",
       "  {'pca__n_components': 32, 'ridge__C': 100000.0},\n",
       "  {'pca__n_components': 132, 'ridge__C': 0.05},\n",
       "  {'pca__n_components': 132, 'ridge__C': 2},\n",
       "  {'pca__n_components': 132, 'ridge__C': 200},\n",
       "  {'pca__n_components': 132, 'ridge__C': 100000.0},\n",
       "  {'pca__n_components': 232, 'ridge__C': 0.05},\n",
       "  {'pca__n_components': 232, 'ridge__C': 2},\n",
       "  {'pca__n_components': 232, 'ridge__C': 200},\n",
       "  {'pca__n_components': 232, 'ridge__C': 100000.0},\n",
       "  {'pca__n_components': 332, 'ridge__C': 0.05},\n",
       "  {'pca__n_components': 332, 'ridge__C': 2},\n",
       "  {'pca__n_components': 332, 'ridge__C': 200},\n",
       "  {'pca__n_components': 332, 'ridge__C': 100000.0},\n",
       "  {'pca__n_components': 432, 'ridge__C': 0.05},\n",
       "  {'pca__n_components': 432, 'ridge__C': 2},\n",
       "  {'pca__n_components': 432, 'ridge__C': 200},\n",
       "  {'pca__n_components': 432, 'ridge__C': 100000.0},\n",
       "  {'pca__n_components': 532, 'ridge__C': 0.05},\n",
       "  {'pca__n_components': 532, 'ridge__C': 2},\n",
       "  {'pca__n_components': 532, 'ridge__C': 200},\n",
       "  {'pca__n_components': 532, 'ridge__C': 100000.0},\n",
       "  {'pca__n_components': 632, 'ridge__C': 0.05},\n",
       "  {'pca__n_components': 632, 'ridge__C': 2},\n",
       "  {'pca__n_components': 632, 'ridge__C': 200},\n",
       "  {'pca__n_components': 632, 'ridge__C': 100000.0},\n",
       "  {'pca__n_components': 732, 'ridge__C': 0.05},\n",
       "  {'pca__n_components': 732, 'ridge__C': 2},\n",
       "  {'pca__n_components': 732, 'ridge__C': 200},\n",
       "  {'pca__n_components': 732, 'ridge__C': 100000.0},\n",
       "  {'pca__n_components': 832, 'ridge__C': 0.05},\n",
       "  {'pca__n_components': 832, 'ridge__C': 2},\n",
       "  {'pca__n_components': 832, 'ridge__C': 200},\n",
       "  {'pca__n_components': 832, 'ridge__C': 100000.0},\n",
       "  {'pca__n_components': 932, 'ridge__C': 0.05},\n",
       "  {'pca__n_components': 932, 'ridge__C': 2},\n",
       "  {'pca__n_components': 932, 'ridge__C': 200},\n",
       "  {'pca__n_components': 932, 'ridge__C': 100000.0}),\n",
       " 'rank_test_score': array([40, 39, 37, 38, 36, 33, 35, 33, 32, 30, 29, 31, 28, 25, 26, 27, 21,\n",
       "        22, 23, 24, 19, 18, 20, 17,  9, 12, 10, 15, 11, 16, 13, 14,  1,  2,\n",
       "         2,  2,  5,  6,  7,  7], dtype=int32),\n",
       " 'split0_test_score': array([0.76466566, 0.76480241, 0.76562286, 0.76528101, 0.82045672,\n",
       "        0.82216601, 0.82161903, 0.82059346, 0.83419937, 0.8350882 ,\n",
       "        0.83611377, 0.83481471, 0.83871188, 0.84048954, 0.8403528 ,\n",
       "        0.84007931, 0.84315602, 0.8408314 , 0.84096814, 0.84042117,\n",
       "        0.84602762, 0.84493368, 0.84568577, 0.84705319, 0.84732668,\n",
       "        0.84725831, 0.84753179, 0.84671134, 0.84821551, 0.84705319,\n",
       "        0.84801039, 0.84732668, 0.85040339, 0.84937782, 0.84930945,\n",
       "        0.84930945, 0.84999316, 0.84944619, 0.84944619, 0.84944619]),\n",
       " 'split0_train_score': array([0.76468376, 0.76529915, 0.76540171, 0.76540171, 0.82396581,\n",
       "        0.82594872, 0.82584615, 0.82499145, 0.84095726, 0.84215385,\n",
       "        0.84150427, 0.84174359, 0.85203419, 0.85247863, 0.85326496,\n",
       "        0.85264957, 0.85839316, 0.85846154, 0.85897436, 0.85863248,\n",
       "        0.86502564, 0.86502564, 0.86564103, 0.86519658, 0.87323077,\n",
       "        0.87422222, 0.87268376, 0.87374359, 0.87709402, 0.87740171,\n",
       "        0.87736752, 0.87774359, 0.88317949, 0.88386325, 0.88389744,\n",
       "        0.88389744, 0.88680342, 0.88738462, 0.88745299, 0.88745299]),\n",
       " 'split1_test_score': array([0.76088889, 0.7617094 , 0.76232479, 0.76177778, 0.81955556,\n",
       "        0.82030769, 0.82023932, 0.82044444, 0.83220513, 0.83302564,\n",
       "        0.83384615, 0.83329915, 0.83781197, 0.83842735, 0.83794872,\n",
       "        0.83760684, 0.84307692, 0.84280342, 0.84177778, 0.84246154,\n",
       "        0.84547009, 0.84670085, 0.84519658, 0.84574359, 0.84923077,\n",
       "        0.8477265 , 0.84738462, 0.8477265 , 0.84676923, 0.84683761,\n",
       "        0.84724786, 0.84731624, 0.85135043, 0.85182906, 0.85189744,\n",
       "        0.85189744, 0.84909402, 0.84834188, 0.8482735 , 0.8482735 ]),\n",
       " 'split1_train_score': array([0.76325596, 0.76544392, 0.76462343, 0.76520461, 0.82554443,\n",
       "        0.82684353, 0.82650166, 0.8253393 , 0.84181737, 0.84291135,\n",
       "        0.84315066, 0.84198831, 0.85200506, 0.85248368, 0.85282554,\n",
       "        0.85285973, 0.8591843 , 0.85976548, 0.8596971 , 0.85887662,\n",
       "        0.86756008, 0.86766264, 0.86653448, 0.86735496, 0.87426071,\n",
       "        0.87381628, 0.87463676, 0.87296161, 0.87832895, 0.87849988,\n",
       "        0.87744009, 0.87887594, 0.88393559, 0.88420909, 0.8841749 ,\n",
       "        0.8841749 , 0.88872175, 0.88947386, 0.88950805, 0.88950805]),\n",
       " 'split2_test_score': array([0.76348718, 0.76328205, 0.76266667, 0.76335043, 0.82242735,\n",
       "        0.82092308, 0.82071795, 0.82235897, 0.83131624, 0.83384615,\n",
       "        0.83364103, 0.83138462, 0.8385641 , 0.83842735, 0.83794872,\n",
       "        0.83822222, 0.84259829, 0.84287179, 0.84191453, 0.84136752,\n",
       "        0.84437607, 0.84451282, 0.84410256, 0.84560684, 0.84820513,\n",
       "        0.84765812, 0.84834188, 0.84683761, 0.84813675, 0.84731624,\n",
       "        0.84676923, 0.84731624, 0.84875214, 0.8477265 , 0.8477265 ,\n",
       "        0.8477265 , 0.84806838, 0.84752137, 0.84752137, 0.84752137]),\n",
       " 'split2_train_score': array([0.76318758, 0.76349527, 0.76352945, 0.76329014, 0.82445045,\n",
       "        0.82530512, 0.82434789, 0.82345903, 0.84181737, 0.841749  ,\n",
       "        0.84250111, 0.84137294, 0.85053502, 0.85097945, 0.8519025 ,\n",
       "        0.85118457, 0.85689378, 0.8573724 , 0.8581587 , 0.85791939,\n",
       "        0.8641414 , 0.86540631, 0.86533794, 0.86503026, 0.87155995,\n",
       "        0.87067109, 0.87251718, 0.87166251, 0.87788452, 0.87774777,\n",
       "        0.87733753, 0.87720078, 0.8820895 , 0.88246556, 0.88246556,\n",
       "        0.88246556, 0.88701241, 0.88745684, 0.88735428, 0.88735428]),\n",
       " 'std_fit_time': array([0.35335245, 0.18017516, 0.1802179 , 0.09642203, 0.15089951,\n",
       "        0.04025159, 0.50836263, 0.05498051, 0.26565669, 0.54119955,\n",
       "        0.33508899, 0.89414463, 0.06831704, 0.18697495, 0.54620156,\n",
       "        0.3010165 , 0.44468418, 0.76386049, 0.18320604, 1.28763593,\n",
       "        0.36077848, 0.57956979, 1.53920603, 0.74557721, 2.23523047,\n",
       "        0.87072273, 0.96053792, 2.46016661, 0.34507603, 0.69162967,\n",
       "        1.67146778, 1.11629109, 1.15281261, 1.5447503 , 2.28181283,\n",
       "        0.8053432 , 2.39052472, 0.53524861, 0.79939226, 0.7404766 ]),\n",
       " 'std_score_time': array([0.0032982 , 0.00622081, 0.00589301, 0.00965397, 0.0262367 ,\n",
       "        0.0159206 , 0.00801103, 0.0164596 , 0.00875217, 0.02934716,\n",
       "        0.02801505, 0.00456569, 0.01884024, 0.03628146, 0.01138192,\n",
       "        0.0061733 , 0.02410832, 0.00691094, 0.03697539, 0.03970503,\n",
       "        0.03779279, 0.02299106, 0.06208559, 0.02942818, 0.08074387,\n",
       "        0.02494132, 0.03101259, 0.07884243, 0.05648381, 0.06791629,\n",
       "        0.03510603, 0.08052722, 0.0288542 , 0.040799  , 0.10957876,\n",
       "        0.08809003, 0.01056015, 0.05774453, 0.07721763, 0.06571998]),\n",
       " 'std_test_score': array([1.57776276e-03, 1.26278110e-03, 1.48075564e-03, 1.43268300e-03,\n",
       "        1.19918568e-03, 7.72945000e-04, 5.72006119e-04, 8.69518634e-04,\n",
       "        1.20553446e-03, 8.47883962e-04, 1.12046022e-03, 1.40349162e-03,\n",
       "        3.94037894e-04, 9.72136177e-04, 1.13330636e-03, 1.05096785e-03,\n",
       "        2.46398217e-04, 9.46159425e-04, 4.17653046e-04, 8.33708699e-04,\n",
       "        6.86000052e-04, 9.47943997e-04, 6.61875082e-04, 6.51987676e-04,\n",
       "        7.78119319e-04, 2.06487649e-04, 4.20876470e-04, 4.51737994e-04,\n",
       "        6.63994093e-04, 1.95718621e-04, 5.11105564e-04, 4.92114284e-06,\n",
       "        1.07364424e-03, 1.68542484e-03, 1.71915923e-03, 1.71915923e-03,\n",
       "        7.86360232e-04, 7.88653889e-04, 7.92039820e-04, 7.92039820e-04]),\n",
       " 'std_train_score': array([6.89753968e-04, 8.86452630e-04, 7.67959462e-04, 9.52349827e-04,\n",
       "        6.60276338e-04, 6.30837714e-04, 9.01432795e-04, 8.16821339e-04,\n",
       "        4.05459180e-04, 4.81754107e-04, 6.77101207e-04, 2.52968441e-04,\n",
       "        6.99947892e-04, 7.07911366e-04, 5.67782113e-04, 7.45097613e-04,\n",
       "        9.49884557e-04, 9.78282010e-04, 6.28434564e-04, 4.06119510e-04,\n",
       "        1.44885793e-03, 1.16379329e-03, 5.07918129e-04, 1.05885341e-03,\n",
       "        1.11288122e-03, 1.58701581e-03, 9.62324556e-04, 8.58296932e-04,\n",
       "        5.10713721e-04, 4.58428220e-04, 4.30557635e-05, 6.97853831e-04,\n",
       "        7.57760942e-04, 7.53734587e-04, 7.49008136e-04, 7.49008136e-04,\n",
       "        8.59298044e-04, 9.68307040e-04, 9.92849440e-04, 9.92849440e-04])}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_ridge.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.850168657124624"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(pca_ridge.cv_results_[\"mean_test_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('pca', PCA(copy=True, iterated_power='auto', n_components=832, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=True)), ('ridge', LogisticRegression(C=0.05, class_weight='balanced', dual=False,\n",
       "          fit_intercept=False, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='multinomial', n_jobs=1, penalty='l2',\n",
       "          random_state=40, solver='saga', tol=0.0001, verbose=0,\n",
       "          warm_start=True))])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_ridge.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## rifacciaamo la ridge campionando maggiormente tra 800 e 900 cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe1=Pipeline([('pca',PCA(whiten=True)),\n",
    "               ('ridge',LogisticRegression(fit_intercept=False,solver=\"saga\",multi_class=\"multinomial\",warm_start=True,class_weight=\"balanced\",random_state=40))])\n",
    "\n",
    "pca_ridge1=GridSearchCV(sc,pipe1,param_grid={'pca__n_components':range(780,920,10),'ridge__C':[0.05,2]},scoring=make_scorer(accuracy_score),cv=cvs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=3, random_state=40, shuffle=False),\n",
       "       error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('pca', PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=True)), ('ridge', LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "          fit_intercept=False, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='multinomial', n_jobs=1, penalty='l2',\n",
       "          random_state=40, solver='saga', tol=0.0001, verbose=0,\n",
       "          warm_start=True))]),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'pca__n_components': [780, 790, 800, 810, 820, 830, 840, 850, 860, 870, 880, 890, 900, 910], 'ridge__C': [0.05, 2]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       sc=<SparkContext master=yarn appName=PySparkShell>,\n",
       "       scoring=make_scorer(accuracy_score), verbose=0)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_ridge1.fit(X.iloc[idx_train,:],y[idx_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([114.13880293, 113.98353998, 113.42727701, 113.01315633,\n",
       "        115.71227638, 115.99496627, 115.77176372, 117.93987497,\n",
       "        119.3805987 , 117.8400503 , 102.03172731, 100.92102806,\n",
       "        102.05239296, 102.24349729, 103.49170065, 103.12941766,\n",
       "        105.18932533, 104.03287609, 105.58795659, 104.84977357,\n",
       "        106.4919823 , 106.48724341, 106.9984204 , 107.33876006,\n",
       "        109.9896094 , 108.0324436 , 109.570738  , 109.41887101]),\n",
       " 'mean_score_time': array([0.67344673, 0.68616072, 0.75547004, 0.67897836, 0.63602599,\n",
       "        0.71137404, 0.6504186 , 0.73128271, 0.72012599, 0.71970733,\n",
       "        0.74032203, 0.71407127, 0.74406163, 0.77477105, 0.68848165,\n",
       "        0.813272  , 0.67481995, 0.78119365, 0.74641109, 0.77034028,\n",
       "        0.77649132, 0.68910193, 0.76580826, 0.76426029, 0.81305035,\n",
       "        0.73928006, 0.65109436, 0.74131497]),\n",
       " 'mean_test_score': array([0.84859604, 0.84802626, 0.84964445, 0.84859604, 0.84914304,\n",
       "        0.84927979, 0.84916583, 0.8489835 , 0.85035099, 0.84891512,\n",
       "        0.85030541, 0.8497812 , 0.84916583, 0.84866442, 0.84868721,\n",
       "        0.8484365 , 0.84959887, 0.84966724, 0.84969004, 0.84905187,\n",
       "        0.84934816, 0.84900629, 0.84969004, 0.84916583, 0.84980399,\n",
       "        0.84937095, 0.84957608, 0.84896071]),\n",
       " 'mean_train_score': array([0.88011669, 0.88109673, 0.88091439, 0.88179187, 0.88122208,\n",
       "        0.88181465, 0.88214513, 0.88260096, 0.88284028, 0.88274911,\n",
       "        0.88298843, 0.88331891, 0.88293145, 0.88323913, 0.88366077,\n",
       "        0.88403683, 0.88450405, 0.8848915 , 0.88467498, 0.88494848,\n",
       "        0.88533594, 0.88578037, 0.88557525, 0.88599689, 0.88629318,\n",
       "        0.8867946 , 0.88649831, 0.88699972]),\n",
       " 'param_pca__n_components': masked_array(data=[780, 780, 790, 790, 800, 800, 810, 810, 820, 820, 830,\n",
       "                    830, 840, 840, 850, 850, 860, 860, 870, 870, 880, 880,\n",
       "                    890, 890, 900, 900, 910, 910],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_ridge__C': masked_array(data=[0.05, 2, 0.05, 2, 0.05, 2, 0.05, 2, 0.05, 2, 0.05, 2,\n",
       "                    0.05, 2, 0.05, 2, 0.05, 2, 0.05, 2, 0.05, 2, 0.05, 2,\n",
       "                    0.05, 2, 0.05, 2],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': ({'pca__n_components': 780, 'ridge__C': 0.05},\n",
       "  {'pca__n_components': 780, 'ridge__C': 2},\n",
       "  {'pca__n_components': 790, 'ridge__C': 0.05},\n",
       "  {'pca__n_components': 790, 'ridge__C': 2},\n",
       "  {'pca__n_components': 800, 'ridge__C': 0.05},\n",
       "  {'pca__n_components': 800, 'ridge__C': 2},\n",
       "  {'pca__n_components': 810, 'ridge__C': 0.05},\n",
       "  {'pca__n_components': 810, 'ridge__C': 2},\n",
       "  {'pca__n_components': 820, 'ridge__C': 0.05},\n",
       "  {'pca__n_components': 820, 'ridge__C': 2},\n",
       "  {'pca__n_components': 830, 'ridge__C': 0.05},\n",
       "  {'pca__n_components': 830, 'ridge__C': 2},\n",
       "  {'pca__n_components': 840, 'ridge__C': 0.05},\n",
       "  {'pca__n_components': 840, 'ridge__C': 2},\n",
       "  {'pca__n_components': 850, 'ridge__C': 0.05},\n",
       "  {'pca__n_components': 850, 'ridge__C': 2},\n",
       "  {'pca__n_components': 860, 'ridge__C': 0.05},\n",
       "  {'pca__n_components': 860, 'ridge__C': 2},\n",
       "  {'pca__n_components': 870, 'ridge__C': 0.05},\n",
       "  {'pca__n_components': 870, 'ridge__C': 2},\n",
       "  {'pca__n_components': 880, 'ridge__C': 0.05},\n",
       "  {'pca__n_components': 880, 'ridge__C': 2},\n",
       "  {'pca__n_components': 890, 'ridge__C': 0.05},\n",
       "  {'pca__n_components': 890, 'ridge__C': 2},\n",
       "  {'pca__n_components': 900, 'ridge__C': 0.05},\n",
       "  {'pca__n_components': 900, 'ridge__C': 2},\n",
       "  {'pca__n_components': 910, 'ridge__C': 0.05},\n",
       "  {'pca__n_components': 910, 'ridge__C': 2}),\n",
       " 'rank_test_score': array([25, 28,  8, 25, 17, 13, 14, 20,  1, 22,  2,  4, 14, 24, 23, 27,  9,\n",
       "         7,  5, 18, 12, 19,  5, 14,  3, 11, 10, 21], dtype=int32),\n",
       " 'split0_test_score': array([0.84814714, 0.84814714, 0.85006153, 0.84807876, 0.84937782,\n",
       "        0.84937782, 0.84910433, 0.84773691, 0.85047176, 0.84992479,\n",
       "        0.85149733, 0.85067688, 0.85019828, 0.84944619, 0.84958293,\n",
       "        0.84937782, 0.85136059, 0.85122385, 0.85095036, 0.85006153,\n",
       "        0.85074525, 0.85019828, 0.85108711, 0.85033502, 0.84951456,\n",
       "        0.84978805, 0.85012991, 0.84910433]),\n",
       " 'split0_train_score': array([0.88030769, 0.88160684, 0.88088889, 0.88194872, 0.88150427,\n",
       "        0.88136752, 0.88194872, 0.88215385, 0.88328205, 0.88294017,\n",
       "        0.88348718, 0.88389744, 0.88324786, 0.88355556, 0.88348718,\n",
       "        0.88389744, 0.88382906, 0.88420513, 0.88379487, 0.88403419,\n",
       "        0.88434188, 0.88468376, 0.88464957, 0.8848547 , 0.88564103,\n",
       "        0.88622222, 0.88581197, 0.88635897]),\n",
       " 'split1_test_score': array([0.84950427, 0.84882051, 0.85018803, 0.84909402, 0.85011966,\n",
       "        0.85011966, 0.85087179, 0.8511453 , 0.85148718, 0.84957265,\n",
       "        0.85107692, 0.85087179, 0.84998291, 0.84950427, 0.84895726,\n",
       "        0.84841026, 0.84916239, 0.84950427, 0.84909402, 0.84895726,\n",
       "        0.84895726, 0.84813675, 0.84923077, 0.84875214, 0.85046154,\n",
       "        0.84977778, 0.85018803, 0.84957265]),\n",
       " 'split1_train_score': array([0.88092715, 0.88222625, 0.8820895 , 0.8828758 , 0.88246556,\n",
       "        0.88321767, 0.88301255, 0.8836621 , 0.88379884, 0.88403815,\n",
       "        0.88355954, 0.88379884, 0.88318348, 0.88345698, 0.88407234,\n",
       "        0.88444839, 0.88591843, 0.88605518, 0.88588424, 0.88605518,\n",
       "        0.88684148, 0.88725172, 0.88639705, 0.88708078, 0.88708078,\n",
       "        0.88759359, 0.88773033, 0.88848245]),\n",
       " 'split2_test_score': array([0.84813675, 0.84711111, 0.84868376, 0.84861538, 0.84793162,\n",
       "        0.84834188, 0.84752137, 0.84806838, 0.84909402, 0.84724786,\n",
       "        0.84834188, 0.84779487, 0.84731624, 0.84704274, 0.84752137,\n",
       "        0.84752137, 0.8482735 , 0.8482735 , 0.84902564, 0.84813675,\n",
       "        0.84834188, 0.84868376, 0.84875214, 0.84841026, 0.8494359 ,\n",
       "        0.84854701, 0.84841026, 0.84820513]),\n",
       " 'split2_train_score': array([0.87911524, 0.87945711, 0.87976479, 0.88055109, 0.87969642,\n",
       "        0.88085877, 0.88147414, 0.88198694, 0.88143995, 0.88126902,\n",
       "        0.88191857, 0.88226044, 0.882363  , 0.88270486, 0.88342279,\n",
       "        0.88376466, 0.88376466, 0.88441421, 0.88434583, 0.88475608,\n",
       "        0.88482445, 0.88540563, 0.88567912, 0.88605518, 0.88615774,\n",
       "        0.88656798, 0.88595262, 0.88615774]),\n",
       " 'std_fit_time': array([0.45771046, 2.52180236, 0.45578481, 0.53973403, 0.86537292,\n",
       "        0.46400939, 1.09928276, 0.90033633, 0.77056222, 0.76568012,\n",
       "        0.14875261, 0.39350431, 0.99663845, 0.89765111, 0.72282743,\n",
       "        0.57091539, 1.01163949, 1.60997041, 0.75140604, 0.83879408,\n",
       "        0.38793842, 1.05081761, 1.40448917, 0.6125134 , 1.0075919 ,\n",
       "        0.49876508, 0.37092542, 0.71494675]),\n",
       " 'std_score_time': array([0.05490618, 0.05900719, 0.01555011, 0.01115799, 0.07642204,\n",
       "        0.06349893, 0.01744729, 0.07674137, 0.07054264, 0.05605299,\n",
       "        0.09475178, 0.09246757, 0.0653165 , 0.08456906, 0.04256766,\n",
       "        0.01010803, 0.04261049, 0.07828868, 0.05484245, 0.08637325,\n",
       "        0.09217562, 0.05036803, 0.05411337, 0.05849517, 0.08819291,\n",
       "        0.07837867, 0.06962555, 0.1719191 ]),\n",
       " 'std_test_score': array([0.00064222, 0.00070307, 0.00068126, 0.0004147 , 0.00090855,\n",
       "        0.00072907, 0.00136848, 0.00153458, 0.00098072, 0.00118764,\n",
       "        0.00139897, 0.00140678, 0.00131079, 0.00114693, 0.00086303,\n",
       "        0.00075813, 0.00129754, 0.00120998, 0.00089165, 0.00078864,\n",
       "        0.00101937, 0.00087197, 0.00100705, 0.00083847, 0.00046605,\n",
       "        0.00058262, 0.00082469, 0.00056744]),\n",
       " 'std_train_score': array([0.00075193, 0.00118664, 0.00094923, 0.00095552, 0.00114797,\n",
       "        0.00101359, 0.00064323, 0.00075342, 0.00101241, 0.00113854,\n",
       "        0.00075708, 0.00074953, 0.00040281, 0.00037992, 0.00029221,\n",
       "        0.00029603, 0.00100046, 0.00082726, 0.00088417, 0.00083621,\n",
       "        0.00108265, 0.00108133, 0.00071717, 0.00090973, 0.00059553,\n",
       "        0.00058234, 0.00087307, 0.00105166])}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_ridge1.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8503509891512444"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(pca_ridge1.cv_results_[\"mean_test_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('pca', PCA(copy=True, iterated_power='auto', n_components=820, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=True)), ('ridge', LogisticRegression(C=0.05, class_weight='balanced', dual=False,\n",
       "          fit_intercept=False, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='multinomial', n_jobs=1, penalty='l2',\n",
       "          random_state=40, solver='saga', tol=0.0001, verbose=0,\n",
       "          warm_start=True))])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_ridge1.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=GridSearchCV(sc,LogisticRegression(fit_intercept=False,solver=\"saga\",penalty=\"l1\",multi_class=\"multinomial\",warm_start=True,class_weight=\"balanced\",random_state=40),param_grid={'C':[0.01,0.05,0.1,0.5,1,3,5]},cv=cvs,scoring=make_scorer(accuracy_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=3, random_state=40, shuffle=False),\n",
       "       error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "          fit_intercept=False, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
       "          random_state=40, solver='saga', tol=0.0001, verbose=0,\n",
       "          warm_start=True),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [0.01, 0.05, 0.1, 0.5, 1, 3, 5]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       sc=<SparkContext master=yarn appName=PySparkShell>,\n",
       "       scoring=make_scorer(accuracy_score), verbose=0)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.fit(X.iloc[idx_train,:],y[idx_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([239.87324492, 311.89896925, 300.26413862, 291.7510554 ,\n",
       "        291.36158689, 300.58888761, 297.67239006]),\n",
       " 'mean_score_time': array([0.1018788 , 0.10065071, 0.07656527, 0.08165932, 0.07655644,\n",
       "        0.07625238, 0.06400927]),\n",
       " 'mean_test_score': array([0.82051691, 0.83029447, 0.83138846, 0.83200383, 0.83214058,\n",
       "        0.83225454, 0.83225454]),\n",
       " 'mean_train_score': array([0.82347979, 0.83625442, 0.83798657, 0.83906917, 0.83935406,\n",
       "        0.83947941, 0.8395136 ]),\n",
       " 'param_C': masked_array(data=[0.01, 0.05, 0.1, 0.5, 1, 3, 5],\n",
       "              mask=[False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': ({'C': 0.01},\n",
       "  {'C': 0.05},\n",
       "  {'C': 0.1},\n",
       "  {'C': 0.5},\n",
       "  {'C': 1},\n",
       "  {'C': 3},\n",
       "  {'C': 5}),\n",
       " 'rank_test_score': array([7, 6, 5, 4, 3, 1, 1], dtype=int32),\n",
       " 'split0_test_score': array([0.82079858, 0.82941337, 0.83050732, 0.83160126, 0.83187474,\n",
       "        0.83201149, 0.83201149]),\n",
       " 'split0_train_score': array([0.82218803, 0.83452991, 0.83582906, 0.83675214, 0.83695726,\n",
       "        0.83709402, 0.83709402]),\n",
       " 'split1_test_score': array([0.82099145, 0.83035897, 0.83254701, 0.83302564, 0.83329915,\n",
       "        0.83357265, 0.83357265]),\n",
       " 'split1_train_score': array([0.82667259, 0.84062083, 0.84263786, 0.84369765, 0.84421045,\n",
       "        0.84441558, 0.84441558]),\n",
       " 'split2_test_score': array([0.81976068, 0.83111111, 0.83111111, 0.83138462, 0.83124786,\n",
       "        0.83117949, 0.83117949]),\n",
       " 'split2_train_score': array([0.82157875, 0.83361253, 0.8354928 , 0.83675772, 0.83689447,\n",
       "        0.83692865, 0.83703121]),\n",
       " 'std_fit_time': array([5.77116078, 5.24361676, 3.39975241, 4.57146931, 0.87074401,\n",
       "        3.95610207, 1.69416515]),\n",
       " 'std_score_time': array([0.0066602 , 0.00261459, 0.00119499, 0.00319177, 0.00538276,\n",
       "        0.00638884, 0.00487706]),\n",
       " 'std_test_score': array([0.00054049, 0.0006946 , 0.00085549, 0.00072791, 0.00085826,\n",
       "        0.000992  , 0.000992  ]),\n",
       " 'std_train_score': array([0.00227131, 0.00311015, 0.00329182, 0.00327283, 0.00343408,\n",
       "        0.00349105, 0.00346631])}"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8322545355091622"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(l.cv_results_[\"mean_test_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=3, class_weight='balanced', dual=False,\n",
       "          fit_intercept=False, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
       "          random_state=40, solver='saga', tol=0.0001, verbose=0,\n",
       "          warm_start=True)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA + LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe2=Pipeline([('pca',PCA(whiten=True)),\n",
    "               ('lasso',LogisticRegression(fit_intercept=False,solver=\"saga\",penalty='l1',multi_class=\"multinomial\",warm_start=True,class_weight=\"balanced\",random_state=40))])\n",
    "\n",
    "pca_lasso=GridSearchCV(sc,pipe2,param_grid={'pca__n_components':range(10,X.shape[1]-500,40),'lasso__C':[0.05,2,1e5],'lasso__class_weight':[None,\"balanced\"]},scoring=make_scorer(accuracy_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('pca', PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=True)), ('lasso', LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "          fit_intercept=False, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
       "          random_state=40, solver='saga', tol=0.0001, verbose=0,\n",
       "          warm_start=True))]),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'pca__n_components': [10, 50, 90, 130, 170, 210, 250, 290, 330, 370, 410, 450, 490, 530], 'lasso__class_weight': [None, 'balanced'], 'lasso__C': [0.05, 2, 100000.0]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       sc=<SparkContext master=yarn appName=PySparkShell>,\n",
       "       scoring=make_scorer(accuracy_score), verbose=0)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_lasso.fit(X.iloc[idx_train,:],y[idx_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([  6.58879296,  15.89841135,  24.42942238,  31.0088559 ,\n",
       "         40.63648136,  49.27992972,  61.78216672,  74.23528965,\n",
       "         88.65011628, 102.08132998, 120.21582357, 132.49315429,\n",
       "        147.65239263, 160.75267609,   6.6288813 ,  15.82506291,\n",
       "         24.06807566,  31.59432737,  39.90563838,  50.38453762,\n",
       "         60.51824466,  74.24831096,  87.88278619, 102.99543405,\n",
       "        117.90694133, 133.47404901, 145.0253466 , 161.6949327 ,\n",
       "          6.71532003,  16.95604467,  26.77706726,  35.499657  ,\n",
       "         46.57971891,  55.62436064,  67.24716894,  75.95985436,\n",
       "         89.31928825,  98.25859292, 113.22013529, 124.00471266,\n",
       "        138.8244706 , 149.04242595,   6.59207106,  17.28755538,\n",
       "         27.51485856,  36.10664972,  46.60365931,  55.67255004,\n",
       "         67.30598823,  75.80473741,  89.57990289,  98.33617274,\n",
       "        113.18212636, 123.28853138, 138.75613499, 148.41634329,\n",
       "          6.87162534,  17.68525632,  28.41836802,  39.42652957,\n",
       "         50.51877666,  64.22005137,  75.708227  ,  90.9247733 ,\n",
       "        102.35334961, 118.31074508, 129.47887826, 146.87256543,\n",
       "        156.55112831, 173.11852034,   6.73773996,  17.29633133,\n",
       "         27.55485702,  37.51929633,  50.48241146,  63.45016209,\n",
       "         75.33121045,  90.0653944 , 102.8620046 , 116.71173604,\n",
       "        130.40610361, 145.45524661, 157.06366857, 170.17099539]),\n",
       " 'mean_score_time': array([0.1766034 , 0.16669997, 0.18779771, 0.21452745, 0.23822395,\n",
       "        0.25447853, 0.29069797, 0.30753835, 0.34755333, 0.34968098,\n",
       "        0.44754299, 0.4658227 , 0.50853864, 0.52085837, 0.16967964,\n",
       "        0.16695126, 0.19410928, 0.20846367, 0.23939967, 0.26437902,\n",
       "        0.30341673, 0.324512  , 0.35169236, 0.37589836, 0.44060628,\n",
       "        0.46557935, 0.47136911, 0.48262191, 0.14469703, 0.16496094,\n",
       "        0.19570502, 0.21441833, 0.25207663, 0.26833495, 0.30288307,\n",
       "        0.32730532, 0.33262364, 0.392085  , 0.44952567, 0.47732067,\n",
       "        0.44741376, 0.47345201, 0.1744496 , 0.17020607, 0.20454009,\n",
       "        0.20847297, 0.23747937, 0.25633669, 0.29731941, 0.30480035,\n",
       "        0.34615906, 0.3854363 , 0.45068645, 0.47890099, 0.50002106,\n",
       "        0.4915127 , 0.1532867 , 0.16633534, 0.18901467, 0.21694469,\n",
       "        0.23210843, 0.27601194, 0.31495969, 0.32010905, 0.35652804,\n",
       "        0.37059029, 0.45735574, 0.44614291, 0.46768506, 0.46261827,\n",
       "        0.14640379, 0.16593536, 0.18846091, 0.22500165, 0.24002361,\n",
       "        0.26225225, 0.30168025, 0.35342399, 0.36077571, 0.36794798,\n",
       "        0.44424041, 0.46942202, 0.4960564 , 0.38852994]),\n",
       " 'mean_test_score': array([0.71000091, 0.79786216, 0.81814659, 0.82359376, 0.83061355,\n",
       "        0.83533139, 0.83881849, 0.84207767, 0.84369587, 0.84403774,\n",
       "        0.84595223, 0.84743368, 0.84927979, 0.8505789 , 0.69792141,\n",
       "        0.79246057, 0.81119519, 0.819742  , 0.82491567, 0.83031726,\n",
       "        0.83339411, 0.83726867, 0.83913757, 0.83938828, 0.84068739,\n",
       "        0.842807  , 0.84456195, 0.84508615, 0.71239402, 0.79913848,\n",
       "        0.81846568, 0.82669341, 0.83109217, 0.8363798 , 0.83888686,\n",
       "        0.8430805 , 0.84394658, 0.84515453, 0.84643085, 0.84649923,\n",
       "        0.84893792, 0.84955329, 0.70054244, 0.79282523, 0.8135655 ,\n",
       "        0.82074483, 0.82662503, 0.83045401, 0.83330294, 0.83856778,\n",
       "        0.83913757, 0.8403911 , 0.84262467, 0.84326283, 0.84551919,\n",
       "        0.84533686, 0.71248519, 0.79929802, 0.81898988, 0.82701249,\n",
       "        0.83186708, 0.83592397, 0.84000365, 0.84244234, 0.84349075,\n",
       "        0.84531407, 0.8460434 , 0.84672714, 0.84875558, 0.84996353,\n",
       "        0.70072477, 0.79321269, 0.81269943, 0.82024341, 0.82585012,\n",
       "        0.83138846, 0.83617467, 0.83738262, 0.83947944, 0.84164463,\n",
       "        0.8414623 , 0.84251071, 0.84458474, 0.84588385]),\n",
       " 'mean_train_score': array([0.71242827, 0.80027822, 0.8212577 , 0.82926889, 0.83685844,\n",
       "        0.84269302, 0.84754763, 0.85123985, 0.85485239, 0.85761011,\n",
       "        0.85959293, 0.86178091, 0.86440198, 0.8669774 , 0.69942578,\n",
       "        0.79347495, 0.81492168, 0.82371912, 0.82982724, 0.83701795,\n",
       "        0.84225998, 0.84638529, 0.84955328, 0.85225408, 0.85473833,\n",
       "        0.85737079, 0.86001457, 0.86213418, 0.71426303, 0.80116707,\n",
       "        0.82285309, 0.83102378, 0.83807777, 0.84344513, 0.84899492,\n",
       "        0.85358738, 0.85722263, 0.85992342, 0.86221398, 0.86441334,\n",
       "        0.86821951, 0.87080637, 0.70119213, 0.79461449, 0.81682472,\n",
       "        0.82573624, 0.83241404, 0.83759914, 0.84411752, 0.84893798,\n",
       "        0.85302903, 0.85592357, 0.8584876 , 0.8612681 , 0.86362709,\n",
       "        0.86613409, 0.71437699, 0.80140638, 0.82261376, 0.83173028,\n",
       "        0.83814618, 0.84387818, 0.84990652, 0.85366717, 0.8571429 ,\n",
       "        0.85971831, 0.86206585, 0.86538202, 0.86808279, 0.87145596,\n",
       "        0.70112376, 0.79495635, 0.8177022 , 0.82582735, 0.83170753,\n",
       "        0.83862473, 0.84497221, 0.84937098, 0.85346209, 0.85533095,\n",
       "        0.85859016, 0.86044765, 0.86400314, 0.86665832]),\n",
       " 'param_lasso__C': masked_array(data=[0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05,\n",
       "                    0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05,\n",
       "                    0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05,\n",
       "                    0.05, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "                    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 100000.0, 100000.0,\n",
       "                    100000.0, 100000.0, 100000.0, 100000.0, 100000.0,\n",
       "                    100000.0, 100000.0, 100000.0, 100000.0, 100000.0,\n",
       "                    100000.0, 100000.0, 100000.0, 100000.0, 100000.0,\n",
       "                    100000.0, 100000.0, 100000.0, 100000.0, 100000.0,\n",
       "                    100000.0, 100000.0, 100000.0, 100000.0, 100000.0,\n",
       "                    100000.0],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_lasso__class_weight': masked_array(data=[None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, None, 'balanced', 'balanced',\n",
       "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
       "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
       "                    'balanced', 'balanced', 'balanced', 'balanced', None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, 'balanced', 'balanced',\n",
       "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
       "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
       "                    'balanced', 'balanced', 'balanced', 'balanced', None,\n",
       "                    None, None, None, None, None, None, None, None, None,\n",
       "                    None, None, None, None, 'balanced', 'balanced',\n",
       "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
       "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
       "                    'balanced', 'balanced', 'balanced', 'balanced'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_pca__n_components': masked_array(data=[10, 50, 90, 130, 170, 210, 250, 290, 330, 370, 410,\n",
       "                    450, 490, 530, 10, 50, 90, 130, 170, 210, 250, 290,\n",
       "                    330, 370, 410, 450, 490, 530, 10, 50, 90, 130, 170,\n",
       "                    210, 250, 290, 330, 370, 410, 450, 490, 530, 10, 50,\n",
       "                    90, 130, 170, 210, 250, 290, 330, 370, 410, 450, 490,\n",
       "                    530, 10, 50, 90, 130, 170, 210, 250, 290, 330, 370,\n",
       "                    410, 450, 490, 530, 10, 50, 90, 130, 170, 210, 250,\n",
       "                    290, 330, 370, 410, 450, 490, 530],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': ({'lasso__C': 0.05,\n",
       "   'lasso__class_weight': None,\n",
       "   'pca__n_components': 10},\n",
       "  {'lasso__C': 0.05, 'lasso__class_weight': None, 'pca__n_components': 50},\n",
       "  {'lasso__C': 0.05, 'lasso__class_weight': None, 'pca__n_components': 90},\n",
       "  {'lasso__C': 0.05, 'lasso__class_weight': None, 'pca__n_components': 130},\n",
       "  {'lasso__C': 0.05, 'lasso__class_weight': None, 'pca__n_components': 170},\n",
       "  {'lasso__C': 0.05, 'lasso__class_weight': None, 'pca__n_components': 210},\n",
       "  {'lasso__C': 0.05, 'lasso__class_weight': None, 'pca__n_components': 250},\n",
       "  {'lasso__C': 0.05, 'lasso__class_weight': None, 'pca__n_components': 290},\n",
       "  {'lasso__C': 0.05, 'lasso__class_weight': None, 'pca__n_components': 330},\n",
       "  {'lasso__C': 0.05, 'lasso__class_weight': None, 'pca__n_components': 370},\n",
       "  {'lasso__C': 0.05, 'lasso__class_weight': None, 'pca__n_components': 410},\n",
       "  {'lasso__C': 0.05, 'lasso__class_weight': None, 'pca__n_components': 450},\n",
       "  {'lasso__C': 0.05, 'lasso__class_weight': None, 'pca__n_components': 490},\n",
       "  {'lasso__C': 0.05, 'lasso__class_weight': None, 'pca__n_components': 530},\n",
       "  {'lasso__C': 0.05,\n",
       "   'lasso__class_weight': 'balanced',\n",
       "   'pca__n_components': 10},\n",
       "  {'lasso__C': 0.05,\n",
       "   'lasso__class_weight': 'balanced',\n",
       "   'pca__n_components': 50},\n",
       "  {'lasso__C': 0.05,\n",
       "   'lasso__class_weight': 'balanced',\n",
       "   'pca__n_components': 90},\n",
       "  {'lasso__C': 0.05,\n",
       "   'lasso__class_weight': 'balanced',\n",
       "   'pca__n_components': 130},\n",
       "  {'lasso__C': 0.05,\n",
       "   'lasso__class_weight': 'balanced',\n",
       "   'pca__n_components': 170},\n",
       "  {'lasso__C': 0.05,\n",
       "   'lasso__class_weight': 'balanced',\n",
       "   'pca__n_components': 210},\n",
       "  {'lasso__C': 0.05,\n",
       "   'lasso__class_weight': 'balanced',\n",
       "   'pca__n_components': 250},\n",
       "  {'lasso__C': 0.05,\n",
       "   'lasso__class_weight': 'balanced',\n",
       "   'pca__n_components': 290},\n",
       "  {'lasso__C': 0.05,\n",
       "   'lasso__class_weight': 'balanced',\n",
       "   'pca__n_components': 330},\n",
       "  {'lasso__C': 0.05,\n",
       "   'lasso__class_weight': 'balanced',\n",
       "   'pca__n_components': 370},\n",
       "  {'lasso__C': 0.05,\n",
       "   'lasso__class_weight': 'balanced',\n",
       "   'pca__n_components': 410},\n",
       "  {'lasso__C': 0.05,\n",
       "   'lasso__class_weight': 'balanced',\n",
       "   'pca__n_components': 450},\n",
       "  {'lasso__C': 0.05,\n",
       "   'lasso__class_weight': 'balanced',\n",
       "   'pca__n_components': 490},\n",
       "  {'lasso__C': 0.05,\n",
       "   'lasso__class_weight': 'balanced',\n",
       "   'pca__n_components': 530},\n",
       "  {'lasso__C': 2, 'lasso__class_weight': None, 'pca__n_components': 10},\n",
       "  {'lasso__C': 2, 'lasso__class_weight': None, 'pca__n_components': 50},\n",
       "  {'lasso__C': 2, 'lasso__class_weight': None, 'pca__n_components': 90},\n",
       "  {'lasso__C': 2, 'lasso__class_weight': None, 'pca__n_components': 130},\n",
       "  {'lasso__C': 2, 'lasso__class_weight': None, 'pca__n_components': 170},\n",
       "  {'lasso__C': 2, 'lasso__class_weight': None, 'pca__n_components': 210},\n",
       "  {'lasso__C': 2, 'lasso__class_weight': None, 'pca__n_components': 250},\n",
       "  {'lasso__C': 2, 'lasso__class_weight': None, 'pca__n_components': 290},\n",
       "  {'lasso__C': 2, 'lasso__class_weight': None, 'pca__n_components': 330},\n",
       "  {'lasso__C': 2, 'lasso__class_weight': None, 'pca__n_components': 370},\n",
       "  {'lasso__C': 2, 'lasso__class_weight': None, 'pca__n_components': 410},\n",
       "  {'lasso__C': 2, 'lasso__class_weight': None, 'pca__n_components': 450},\n",
       "  {'lasso__C': 2, 'lasso__class_weight': None, 'pca__n_components': 490},\n",
       "  {'lasso__C': 2, 'lasso__class_weight': None, 'pca__n_components': 530},\n",
       "  {'lasso__C': 2, 'lasso__class_weight': 'balanced', 'pca__n_components': 10},\n",
       "  {'lasso__C': 2, 'lasso__class_weight': 'balanced', 'pca__n_components': 50},\n",
       "  {'lasso__C': 2, 'lasso__class_weight': 'balanced', 'pca__n_components': 90},\n",
       "  {'lasso__C': 2, 'lasso__class_weight': 'balanced', 'pca__n_components': 130},\n",
       "  {'lasso__C': 2, 'lasso__class_weight': 'balanced', 'pca__n_components': 170},\n",
       "  {'lasso__C': 2, 'lasso__class_weight': 'balanced', 'pca__n_components': 210},\n",
       "  {'lasso__C': 2, 'lasso__class_weight': 'balanced', 'pca__n_components': 250},\n",
       "  {'lasso__C': 2, 'lasso__class_weight': 'balanced', 'pca__n_components': 290},\n",
       "  {'lasso__C': 2, 'lasso__class_weight': 'balanced', 'pca__n_components': 330},\n",
       "  {'lasso__C': 2, 'lasso__class_weight': 'balanced', 'pca__n_components': 370},\n",
       "  {'lasso__C': 2, 'lasso__class_weight': 'balanced', 'pca__n_components': 410},\n",
       "  {'lasso__C': 2, 'lasso__class_weight': 'balanced', 'pca__n_components': 450},\n",
       "  {'lasso__C': 2, 'lasso__class_weight': 'balanced', 'pca__n_components': 490},\n",
       "  {'lasso__C': 2, 'lasso__class_weight': 'balanced', 'pca__n_components': 530},\n",
       "  {'lasso__C': 100000.0, 'lasso__class_weight': None, 'pca__n_components': 10},\n",
       "  {'lasso__C': 100000.0, 'lasso__class_weight': None, 'pca__n_components': 50},\n",
       "  {'lasso__C': 100000.0, 'lasso__class_weight': None, 'pca__n_components': 90},\n",
       "  {'lasso__C': 100000.0,\n",
       "   'lasso__class_weight': None,\n",
       "   'pca__n_components': 130},\n",
       "  {'lasso__C': 100000.0,\n",
       "   'lasso__class_weight': None,\n",
       "   'pca__n_components': 170},\n",
       "  {'lasso__C': 100000.0,\n",
       "   'lasso__class_weight': None,\n",
       "   'pca__n_components': 210},\n",
       "  {'lasso__C': 100000.0,\n",
       "   'lasso__class_weight': None,\n",
       "   'pca__n_components': 250},\n",
       "  {'lasso__C': 100000.0,\n",
       "   'lasso__class_weight': None,\n",
       "   'pca__n_components': 290},\n",
       "  {'lasso__C': 100000.0,\n",
       "   'lasso__class_weight': None,\n",
       "   'pca__n_components': 330},\n",
       "  {'lasso__C': 100000.0,\n",
       "   'lasso__class_weight': None,\n",
       "   'pca__n_components': 370},\n",
       "  {'lasso__C': 100000.0,\n",
       "   'lasso__class_weight': None,\n",
       "   'pca__n_components': 410},\n",
       "  {'lasso__C': 100000.0,\n",
       "   'lasso__class_weight': None,\n",
       "   'pca__n_components': 450},\n",
       "  {'lasso__C': 100000.0,\n",
       "   'lasso__class_weight': None,\n",
       "   'pca__n_components': 490},\n",
       "  {'lasso__C': 100000.0,\n",
       "   'lasso__class_weight': None,\n",
       "   'pca__n_components': 530},\n",
       "  {'lasso__C': 100000.0,\n",
       "   'lasso__class_weight': 'balanced',\n",
       "   'pca__n_components': 10},\n",
       "  {'lasso__C': 100000.0,\n",
       "   'lasso__class_weight': 'balanced',\n",
       "   'pca__n_components': 50},\n",
       "  {'lasso__C': 100000.0,\n",
       "   'lasso__class_weight': 'balanced',\n",
       "   'pca__n_components': 90},\n",
       "  {'lasso__C': 100000.0,\n",
       "   'lasso__class_weight': 'balanced',\n",
       "   'pca__n_components': 130},\n",
       "  {'lasso__C': 100000.0,\n",
       "   'lasso__class_weight': 'balanced',\n",
       "   'pca__n_components': 170},\n",
       "  {'lasso__C': 100000.0,\n",
       "   'lasso__class_weight': 'balanced',\n",
       "   'pca__n_components': 210},\n",
       "  {'lasso__C': 100000.0,\n",
       "   'lasso__class_weight': 'balanced',\n",
       "   'pca__n_components': 250},\n",
       "  {'lasso__C': 100000.0,\n",
       "   'lasso__class_weight': 'balanced',\n",
       "   'pca__n_components': 290},\n",
       "  {'lasso__C': 100000.0,\n",
       "   'lasso__class_weight': 'balanced',\n",
       "   'pca__n_components': 330},\n",
       "  {'lasso__C': 100000.0,\n",
       "   'lasso__class_weight': 'balanced',\n",
       "   'pca__n_components': 370},\n",
       "  {'lasso__C': 100000.0,\n",
       "   'lasso__class_weight': 'balanced',\n",
       "   'pca__n_components': 410},\n",
       "  {'lasso__C': 100000.0,\n",
       "   'lasso__class_weight': 'balanced',\n",
       "   'pca__n_components': 450},\n",
       "  {'lasso__C': 100000.0,\n",
       "   'lasso__class_weight': 'balanced',\n",
       "   'pca__n_components': 490},\n",
       "  {'lasso__C': 100000.0,\n",
       "   'lasso__class_weight': 'balanced',\n",
       "   'pca__n_components': 530}),\n",
       " 'rank_test_score': array([81, 75, 69, 63, 55, 49, 42, 31, 23, 21, 12,  7,  4,  1, 84, 78, 72,\n",
       "        66, 62, 57, 50, 45, 39, 38, 34, 27, 20, 18, 80, 74, 68, 59, 54, 46,\n",
       "        41, 26, 22, 17, 10,  9,  5,  3, 83, 77, 70, 64, 60, 56, 51, 43, 39,\n",
       "        35, 28, 25, 14, 15, 79, 73, 67, 58, 52, 48, 36, 30, 24, 16, 11,  8,\n",
       "         6,  2, 82, 76, 71, 65, 61, 53, 47, 44, 37, 32, 33, 29, 19, 13],\n",
       "       dtype=int32),\n",
       " 'split0_test_score': array([0.71171725, 0.79648619, 0.81761006, 0.82355756, 0.83100902,\n",
       "        0.83565764, 0.839691  , 0.84160514, 0.84310911, 0.84543342,\n",
       "        0.84515997, 0.84652721, 0.84891988, 0.85001367, 0.69961717,\n",
       "        0.79211102, 0.81193601, 0.82048127, 0.82560842, 0.83326497,\n",
       "        0.83442713, 0.83873393, 0.83921247, 0.84016954, 0.84126333,\n",
       "        0.84338255, 0.84481816, 0.8461854 , 0.71472518, 0.79669128,\n",
       "        0.81870386, 0.82629204, 0.83237626, 0.83791359, 0.83907575,\n",
       "        0.84351928, 0.84433962, 0.84543342, 0.84700574, 0.84604867,\n",
       "        0.847621  , 0.84721083, 0.70242002, 0.79265792, 0.81248291,\n",
       "        0.82232704, 0.82868471, 0.83100902, 0.83367514, 0.83798195,\n",
       "        0.83962264, 0.83996445, 0.84304074, 0.84399781, 0.84659557,\n",
       "        0.84481816, 0.71458846, 0.79696473, 0.81904567, 0.82567678,\n",
       "        0.83305989, 0.83654635, 0.84126333, 0.8427673 , 0.84495488,\n",
       "        0.84604867, 0.84604867, 0.8456385 , 0.84673229, 0.8490566 ,\n",
       "        0.70269346, 0.79224774, 0.812688  , 0.82178015, 0.82868471,\n",
       "        0.8334017 , 0.83606782, 0.83798195, 0.83962264, 0.84283566,\n",
       "        0.84133169, 0.84242549, 0.84331419, 0.84673229]),\n",
       " 'split0_train_score': array([0.71334792, 0.80460202, 0.82203911, 0.82997128, 0.83725383,\n",
       "        0.84224562, 0.84648523, 0.85106674, 0.85564825, 0.8575971 ,\n",
       "        0.858657  , 0.86118709, 0.86457194, 0.8664866 , 0.70162062,\n",
       "        0.79735367, 0.81557713, 0.82320159, 0.82952681, 0.8370145 ,\n",
       "        0.84169858, 0.84662199, 0.8490837 , 0.85185312, 0.85366521,\n",
       "        0.85701586, 0.85906729, 0.8614948 , 0.71601477, 0.8047046 ,\n",
       "        0.82337254, 0.82983452, 0.83766411, 0.84292943, 0.84901532,\n",
       "        0.85359683, 0.85677653, 0.85958014, 0.86176833, 0.86361461,\n",
       "        0.8672046 , 0.87052106, 0.70377462, 0.79779814, 0.81670542,\n",
       "        0.82624453, 0.83144147, 0.83749316, 0.84392095, 0.84990427,\n",
       "        0.85359683, 0.85670815, 0.85848605, 0.86070842, 0.86378556,\n",
       "        0.86498222, 0.71615153, 0.80545678, 0.82285968, 0.83041575,\n",
       "        0.8387924 , 0.84306619, 0.84911789, 0.85397292, 0.85780224,\n",
       "        0.85940919, 0.86214442, 0.86573441, 0.86751231, 0.87134163,\n",
       "        0.70380881, 0.79800328, 0.81797046, 0.82576586, 0.83178337,\n",
       "        0.83814278, 0.84535695, 0.84956236, 0.85424644, 0.85561406,\n",
       "        0.85858862, 0.86050328, 0.86419584, 0.86600793]),\n",
       " 'split1_test_score': array([0.7105641 , 0.79589744, 0.81606838, 0.82064957, 0.82981197,\n",
       "        0.83309402, 0.83774359, 0.84082051, 0.84307692, 0.84239316,\n",
       "        0.84505983, 0.84758974, 0.85011966, 0.85100855, 0.69900855,\n",
       "        0.78974359, 0.80936752, 0.81791453, 0.8237265 , 0.82974359,\n",
       "        0.83323077, 0.83589744, 0.83719658, 0.83952137, 0.83911111,\n",
       "        0.84198291, 0.84588034, 0.84437607, 0.71323077, 0.79733333,\n",
       "        0.81661538, 0.82659829, 0.82953846, 0.8354188 , 0.8382906 ,\n",
       "        0.84088889, 0.84355556, 0.84382906, 0.84711111, 0.84615385,\n",
       "        0.84882051, 0.85162393, 0.70105983, 0.79008547, 0.81128205,\n",
       "        0.81852991, 0.82611966, 0.83083761, 0.8337094 , 0.83760684,\n",
       "        0.83815385, 0.84136752, 0.84198291, 0.84410256, 0.84437607,\n",
       "        0.84622222, 0.71357265, 0.79740171, 0.81682051, 0.8271453 ,\n",
       "        0.83076923, 0.83432479, 0.83917949, 0.84020513, 0.84088889,\n",
       "        0.84478632, 0.84560684, 0.8465641 , 0.8494359 , 0.85059829,\n",
       "        0.70140171, 0.79049573, 0.81100855, 0.81859829, 0.82386325,\n",
       "        0.82967521, 0.83617094, 0.83617094, 0.83979487, 0.8417094 ,\n",
       "        0.84075214, 0.84177778, 0.84594872, 0.84615385]),\n",
       " 'split1_train_score': array([0.71310383, 0.79682746, 0.8219548 , 0.82930498, 0.83699703,\n",
       "        0.84263786, 0.84985129, 0.85135551, 0.85621004, 0.85863731,\n",
       "        0.86130389, 0.86236368, 0.86513282, 0.86851732, 0.69949745,\n",
       "        0.79077638, 0.81689515, 0.82503162, 0.83060408, 0.83665516,\n",
       "        0.84270623, 0.8469454 , 0.8506034 , 0.85326997, 0.85651773,\n",
       "        0.85884243, 0.8617825 , 0.86311579, 0.71453967, 0.79870774,\n",
       "        0.8238009 , 0.83350997, 0.8391508 , 0.84342416, 0.84988547,\n",
       "        0.85357766, 0.85863731, 0.86085946, 0.86376534, 0.8659533 ,\n",
       "        0.8698506 , 0.87173088, 0.70052306, 0.79193874, 0.81836518,\n",
       "        0.82773239, 0.83323647, 0.83781751, 0.84509931, 0.84940686,\n",
       "        0.85330416, 0.85665447, 0.86020991, 0.86195344, 0.86530375,\n",
       "        0.86848313, 0.71467642, 0.79754538, 0.82318553, 0.8328946 ,\n",
       "        0.83829613, 0.84486   , 0.85053502, 0.85378278, 0.85723565,\n",
       "        0.86109877, 0.86294486, 0.86585074, 0.87008991, 0.87357697,\n",
       "        0.70045469, 0.79231479, 0.81857031, 0.82694609, 0.83115107,\n",
       "        0.83839869, 0.84479163, 0.85002222, 0.85429558, 0.85545793,\n",
       "        0.86031247, 0.86140645, 0.86526956, 0.868825  ]),\n",
       " 'split2_test_score': array([0.70772071, 0.80120358, 0.82076181, 0.82657457, 0.83101963,\n",
       "        0.8372427 , 0.83902072, 0.8438077 , 0.84490187, 0.8442864 ,\n",
       "        0.84763728, 0.84818437, 0.84879984, 0.85071463, 0.6951378 ,\n",
       "        0.79552759, 0.81228202, 0.8208302 , 0.82541202, 0.82794228,\n",
       "        0.83252411, 0.83717431, 0.8410039 , 0.83847364, 0.84168775,\n",
       "        0.84305546, 0.84298708, 0.84469671, 0.70922519, 0.80339192,\n",
       "        0.82007796, 0.82719004, 0.83136155, 0.83580661, 0.83929426,\n",
       "        0.84483348, 0.84394447, 0.84620119, 0.84517541, 0.84729536,\n",
       "        0.8503727 , 0.84982562, 0.69814676, 0.79573275, 0.81693223,\n",
       "        0.82137728, 0.8250701 , 0.82951515, 0.83252411, 0.84011489,\n",
       "        0.83963619, 0.83984135, 0.8428503 , 0.84168775, 0.84558572,\n",
       "        0.84497025, 0.70929358, 0.80352869, 0.82110374, 0.82821582,\n",
       "        0.83177187, 0.83690077, 0.8395678 , 0.84435478, 0.84462833,\n",
       "        0.84510702, 0.84647473, 0.84797921, 0.85009916, 0.85023593,\n",
       "        0.69807837, 0.7968953 , 0.81440197, 0.8203515 , 0.82500171,\n",
       "        0.83108801, 0.8362853 , 0.83799494, 0.83902072, 0.84038843,\n",
       "        0.84230322, 0.843329  , 0.84449155, 0.8447651 ]),\n",
       " 'split2_train_score': array([0.71083308, 0.79940519, 0.81977917, 0.82853041, 0.83632448,\n",
       "        0.84319557, 0.84630636, 0.8512973 , 0.85269887, 0.8565959 ,\n",
       "        0.8588179 , 0.86179195, 0.86350118, 0.86592828, 0.69715927,\n",
       "        0.79229481, 0.81229276, 0.82292414, 0.82935084, 0.8373842 ,\n",
       "        0.84237514, 0.84558849, 0.84897275, 0.85163915, 0.85403207,\n",
       "        0.85625406, 0.85919393, 0.86179195, 0.71223464, 0.80008888,\n",
       "        0.82138584, 0.82972687, 0.83741838, 0.84398181, 0.84808396,\n",
       "        0.85358767, 0.85625406, 0.85933067, 0.86110826, 0.8636721 ,\n",
       "        0.86760332, 0.87016716, 0.69927871, 0.79410659, 0.81540355,\n",
       "        0.82323181, 0.83256418, 0.83748675, 0.84333231, 0.84750282,\n",
       "        0.8521861 , 0.85440809, 0.85676683, 0.86114245, 0.86179195,\n",
       "        0.86493693, 0.71230301, 0.80121697, 0.82179606, 0.83188049,\n",
       "        0.83735002, 0.84370834, 0.85006666, 0.85324582, 0.8563908 ,\n",
       "        0.85864698, 0.86110826, 0.8645609 , 0.86664616, 0.86944929,\n",
       "        0.69910778, 0.79455099, 0.81656582, 0.82477011, 0.83218815,\n",
       "        0.83933272, 0.84476806, 0.84852836, 0.85184426, 0.85492086,\n",
       "        0.85686938, 0.85943322, 0.86254401, 0.86514204]),\n",
       " 'std_fit_time': array([0.24937012, 0.66275088, 0.35815113, 0.41182366, 0.17190853,\n",
       "        0.92105479, 0.31267502, 0.58020106, 0.18128253, 1.78749157,\n",
       "        1.20138626, 1.60712318, 0.40856689, 1.60811773, 0.25499949,\n",
       "        0.53818319, 0.70984796, 0.74279124, 0.46669182, 0.23447079,\n",
       "        0.61563122, 0.34465054, 1.04425713, 0.93657205, 0.92583334,\n",
       "        0.7615349 , 1.94138802, 0.28847994, 0.21345662, 0.28935009,\n",
       "        0.04914326, 0.50506057, 0.15891394, 1.21832698, 0.23014766,\n",
       "        2.18675797, 0.37342845, 1.80001687, 0.1801951 , 1.84642684,\n",
       "        0.55440335, 1.54530221, 0.18367258, 0.28572007, 0.50622929,\n",
       "        0.68611296, 0.19191356, 0.87508765, 0.10643801, 1.44434536,\n",
       "        0.10153967, 2.18229058, 0.58518716, 2.18908566, 0.3394463 ,\n",
       "        1.82689771, 0.15673153, 0.56187587, 0.67816255, 0.61924351,\n",
       "        0.94689618, 0.63392217, 1.72220802, 0.23834935, 1.67818021,\n",
       "        0.73061061, 2.14177588, 1.28673164, 1.42942422, 1.88911707,\n",
       "        0.4276649 , 0.10435379, 0.2295075 , 0.13747662, 0.6128165 ,\n",
       "        1.40368086, 1.51070201, 1.22744301, 0.76913217, 2.19489025,\n",
       "        2.01788704, 2.84886615, 2.53137996, 3.95884244]),\n",
       " 'std_score_time': array([0.028106  , 0.00202201, 0.00394012, 0.00152714, 0.00937537,\n",
       "        0.00875403, 0.00634129, 0.00939956, 0.01066441, 0.00888681,\n",
       "        0.01146343, 0.03972528, 0.0283147 , 0.05657813, 0.03548187,\n",
       "        0.0032654 , 0.00183098, 0.00430424, 0.01254464, 0.02706676,\n",
       "        0.01928819, 0.03510595, 0.03730937, 0.02984414, 0.03433831,\n",
       "        0.02996179, 0.01400226, 0.02411905, 0.00086121, 0.00585342,\n",
       "        0.00204276, 0.01010062, 0.02725911, 0.0311918 , 0.03552566,\n",
       "        0.04304162, 0.01959027, 0.04788982, 0.05272827, 0.07256383,\n",
       "        0.01032503, 0.01778028, 0.02314064, 0.01384223, 0.01231133,\n",
       "        0.00122135, 0.00638972, 0.00377374, 0.01359597, 0.00702601,\n",
       "        0.01598351, 0.0287467 , 0.03625941, 0.04352845, 0.05060619,\n",
       "        0.0078587 , 0.00086295, 0.00364535, 0.00439073, 0.00978174,\n",
       "        0.00558719, 0.02104319, 0.04507378, 0.0227585 , 0.02875138,\n",
       "        0.03532157, 0.05089479, 0.03507222, 0.00898976, 0.02332105,\n",
       "        0.00573043, 0.00072956, 0.0019485 , 0.01925562, 0.01082046,\n",
       "        0.0048606 , 0.02196646, 0.06917756, 0.03208303, 0.0163293 ,\n",
       "        0.0341738 , 0.0422659 , 0.03064152, 0.03413427]),\n",
       " 'std_test_score': array([1.67948594e-03, 2.37465914e-03, 1.95321033e-03, 2.41889703e-03,\n",
       "        5.66810524e-04, 1.70925972e-03, 8.07814686e-04, 1.26441814e-03,\n",
       "        8.52767665e-04, 1.25361607e-03, 1.19207231e-03, 6.85477360e-04,\n",
       "        5.95886076e-04, 4.17353519e-04, 1.98370378e-03, 2.37410709e-03,\n",
       "        1.30002944e-03, 1.30002269e-03, 8.44674000e-04, 2.21052735e-03,\n",
       "        7.85447387e-04, 1.15996184e-03, 1.55516205e-03, 6.98718975e-04,\n",
       "        1.12796740e-03, 5.97818560e-04, 1.19493467e-03, 7.88333562e-04,\n",
       "        2.32201879e-03, 3.01867594e-03, 1.42352649e-03, 3.72727639e-04,\n",
       "        1.17412532e-03, 1.09619556e-03, 4.30950234e-04, 1.63992530e-03,\n",
       "        3.20110274e-04, 9.88255120e-04, 8.88667134e-04, 5.64517994e-04,\n",
       "        1.12644622e-03, 1.81197272e-03, 1.78250869e-03, 2.30842189e-03,\n",
       "        2.43031534e-03, 1.61343614e-03, 1.51832194e-03, 6.67473360e-04,\n",
       "        5.50833897e-04, 1.10450676e-03, 6.95607558e-04, 6.92247625e-04,\n",
       "        4.60399588e-04, 1.11443697e-03, 9.07364022e-04, 6.29107843e-04,\n",
       "        2.29433017e-03, 2.99649032e-03, 1.74898575e-03, 1.04080988e-03,\n",
       "        9.37612789e-04, 1.13999245e-03, 9.04847080e-04, 1.70952964e-03,\n",
       "        1.84458383e-03, 5.35758438e-04, 3.54319749e-04, 9.62524757e-04,\n",
       "        1.45627025e-03, 6.58221529e-04, 1.94396663e-03, 2.70015307e-03,\n",
       "        1.38531936e-03, 1.30128542e-03, 2.05780188e-03, 1.53614847e-03,\n",
       "        8.88291911e-05, 8.56791440e-04, 3.31860970e-04, 1.00013157e-03,\n",
       "        6.39900244e-04, 6.36117743e-04, 1.07759953e-03, 8.25488900e-04]),\n",
       " 'std_train_score': array([1.13236839e-03, 3.23343041e-03, 1.04604332e-03, 5.88787266e-04,\n",
       "        3.91855626e-04, 3.89770224e-04, 1.63057018e-03, 1.24693078e-04,\n",
       "        1.53994284e-03, 8.33451590e-04, 1.21161159e-03, 4.80404414e-04,\n",
       "        6.76867349e-04, 1.11248646e-03, 1.82204671e-03, 2.81184567e-03,\n",
       "        1.93523802e-03, 9.34967151e-04, 5.53987167e-04, 2.97640510e-04,\n",
       "        4.19354944e-04, 5.78691131e-04, 7.43923106e-04, 7.23637011e-04,\n",
       "        1.26710312e-03, 1.08609266e-03, 1.25118415e-03, 7.04623350e-04,\n",
       "        1.55557933e-03, 2.56416978e-03, 1.05213790e-03, 1.75854559e-03,\n",
       "        7.65351866e-04, 4.29889447e-04, 7.35607617e-04, 7.82936382e-06,\n",
       "        1.02281581e-03, 6.69667224e-04, 1.12959298e-03, 1.08917226e-03,\n",
       "        1.16478961e-03, 6.69504315e-04, 1.89544059e-03, 2.41890100e-03,\n",
       "        1.21202200e-03, 1.87217763e-03, 7.40458076e-04, 1.54432034e-04,\n",
       "        7.34646043e-04, 1.03493004e-03, 6.07898133e-04, 1.07182894e-03,\n",
       "        1.40563196e-03, 5.15982178e-04, 1.43805770e-03, 1.66112196e-03,\n",
       "        1.58535418e-03, 3.23259139e-03, 5.93307855e-04, 1.01754360e-03,\n",
       "        5.98319114e-04, 7.42102857e-04, 5.89520256e-04, 3.07887285e-04,\n",
       "        5.79940730e-04, 1.02452738e-03, 7.51842150e-04, 5.82556207e-04,\n",
       "        1.46263496e-03, 1.68705834e-03, 1.97663862e-03, 2.33993884e-03,\n",
       "        8.40024646e-04, 8.89402813e-04, 4.26768717e-04, 5.11409534e-04,\n",
       "        2.72219112e-04, 6.24702084e-04, 1.14415990e-03, 2.96898943e-04,\n",
       "        1.40563481e-03, 8.06526509e-04, 1.12101373e-03, 1.57232423e-03])}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_lasso.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85057890418452"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(pca_lasso.cv_results_[\"mean_test_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('pca', PCA(copy=True, iterated_power='auto', n_components=530, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=True)), ('lasso', LogisticRegression(C=0.05, class_weight=None, dual=False, fit_intercept=False,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='multinomial',\n",
       "          n_jobs=1, penalty='l1', random_state=40, solver='saga',\n",
       "          tol=0.0001, verbose=0, warm_start=True))])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_lasso.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe2=Pipeline([('pca',PCA(whiten=True)),\n",
    "               ('lasso',LogisticRegression(fit_intercept=False,solver=\"saga\",penalty='l1',multi_class=\"multinomial\",warm_start=True,class_weight=\"balanced\",random_state=40))])\n",
    "\n",
    "pca_lasso1=GridSearchCV(sc,pipe2,param_grid={'pca__n_components':[500,520,540,560,600,700,800],'lasso__C':[0.05,2,1e5],'lasso__class_weight':[None,\"balanced\"]},scoring=make_scorer(accuracy_score),cv=cvs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_lasso1.fit(X.iloc[idx_train,:],y[idx_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_lasso1.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In definitiva i modelli migliori sono LDA e PCA+LDA\n",
    "## Ora adattiamo una lasso e teniamo le variabili i cui coefficienti sono diversi da zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l è un'istanza della classe lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(l.best_estimator_.coef_[0]==0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(l.best_estimator_.coef_<0.05,l.best_estimator_.coef_>-0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.08927208, -0.01010742,  0.00896678, ..., -0.01353914,\n",
       "        0.00284145, -0.00599544])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.best_estimator_.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "jk=LogisticRegression(fit_intercept=False,solver=\"saga\",penalty=\"l1\",multi_class=\"multinomial\",warm_start=True,class_weight=\"balanced\",random_state=40,C=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/anaconda/lib/python2.7/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.001, class_weight='balanced', dual=False,\n",
       "          fit_intercept=False, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
       "          random_state=40, solver='saga', tol=0.0001, verbose=0,\n",
       "          warm_start=True)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jk.fit(X.iloc[idx_train,:],y[idx_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7874"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(jk.predict(X.iloc[idx_test[:20000]]),y[idx_test[:20000]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.13053332,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jk.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "225"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_lasso=[NOME for NOME,w in {nome:[k[i] for k in jk.coef_] for i,nome in enumerate(X.columns)}.items() if any(w)]\n",
    "#restituisce i nomi delle colonne che hanno almeno un coefficiente diverso da zero\n",
    "len(col_lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "dizio={sum(abs(b) for b in list):name for name,list in {nome:[k[i] for k in jk.coef_] for i,nome in enumerate(X.columns)}.items() if any(list)}\n",
    "#dizionario con chiavi la somma dei coefficienti in valore assoluto(si spera non ce ne siano 2 uguali data la precisione) e con valori il nome delle variabili"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.15736714, 1.27542987, 0.66713425, 0.66034663, 1.41321833,\n",
       "        1.4076768 , 1.20769003, 0.99865771, 2.08630193, 0.47456279]),\n",
       " array([  0. ,  22.4,  44.8,  67.2,  89.6, 112. , 134.4, 156.8, 179.2,\n",
       "        201.6, 224. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb8f0de1b10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(dizio.values(),weights=dizio.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.00042504987335262025: 'lowlevel.barkbands.dmean.6',\n",
       " 0.0006713634053913806: 'tonal.hpcp.var.3',\n",
       " 0.0007185182765048143: 'tonal.hpcp.median.7',\n",
       " 0.0007938397533549231: 'lowlevel.spectral_contrast_coeffs.max.5',\n",
       " 0.0010967951910380105: 'tonal.hpcp.median.27',\n",
       " 0.0011441159352432373: 'lowlevel.spectral_spread.min',\n",
       " 0.0011594000409584197: 'lowlevel.barkbands.median.13_sin',\n",
       " 0.0011992883625023718: 'tonal.thpcp.21',\n",
       " 0.0019328794324121605: 'lowlevel.spectral_contrast_valleys.dvar2.1',\n",
       " 0.002071195954185004: 'lowlevel.erbbands.dmean.12',\n",
       " 0.0021024674533294437: 'lowlevel.spectral_contrast_valleys.dmean2.4_sin',\n",
       " 0.002350043979226656: 'lowlevel.erbbands.max.14',\n",
       " 0.0025067197916904113: 'lowlevel.barkbands.median.14_sin',\n",
       " 0.003208774499848502: 'tonal.hpcp.median.28',\n",
       " 0.0034974665321574113: 'lowlevel.melbands_flatness_db.dvar_sin',\n",
       " 0.0036551606410802325: 'lowlevel.spectral_entropy.var',\n",
       " 0.004010838625496092: 'tonal.thpcp.8',\n",
       " 0.004585629075979916: 'lowlevel.melbands_spread.dmean',\n",
       " 0.00496114191293598: 'rhythm.bpm_histogram_second_peak_bpm.max',\n",
       " 0.005276114332330926: 'lowlevel.gfcc.mean.3',\n",
       " 0.005491258541673798: 'lowlevel.dissonance.dmean_sin',\n",
       " 0.005832048647182728: 'lowlevel.spectral_flux.dmean',\n",
       " 0.005899100973013972: 'rhythm.beats_loudness_band_ratio.var.0',\n",
       " 0.005918697184284322: 'lowlevel.erbbands.dvar.1_sin',\n",
       " 0.0065956886036730306: 'lowlevel.erbbands.median.4_sin',\n",
       " 0.006633015309044467: 'lowlevel.gfcc.mean.2',\n",
       " 0.006860725970181304: 'lowlevel.melbands.mean.1',\n",
       " 0.007010620510790412: 'lowlevel.spectral_contrast_coeffs.max.1',\n",
       " 0.007186525135670387: 'lowlevel.barkbands.median.14',\n",
       " 0.007466600637228307: 'lowlevel.barkbands.dvar.2_sin',\n",
       " 0.007489150439087425: 'lowlevel.erbbands_spread.var_sin',\n",
       " 0.008195882869557735: 'lowlevel.spectral_contrast_valleys.dmean.0',\n",
       " 0.008417138435717486: 'tonal.hpcp.var.9',\n",
       " 0.008574436450981885: 'lowlevel.barkbands.var.2_sin',\n",
       " 0.008893244586388998: 'lowlevel.barkbands.dmean.21_sin',\n",
       " 0.008903109961849525: 'lowlevel.spectral_complexity.max_exp',\n",
       " 0.00910429730273772: 'lowlevel.spectral_centroid.dvar',\n",
       " 0.009673822017217122: 'lowlevel.melbands.dmean.35',\n",
       " 0.009867901726496656: 'lowlevel.erbbands.dmean.31',\n",
       " 0.00992212557245645: 'lowlevel.melbands.var.1_sin',\n",
       " 0.01008863588242674: 'lowlevel.spectral_flux.mean',\n",
       " 0.010232791020206364: 'lowlevel.spectral_contrast_valleys.median.5',\n",
       " 0.010296381469047591: 'lowlevel.zerocrossingrate.min',\n",
       " 0.010361302736072076: 'rhythm.beats_loudness_band_ratio.mean.0_exp',\n",
       " 0.010590275424638482: 'lowlevel.barkbands_spread.var_sin',\n",
       " 0.010621865977346287: 'rhythm.beats_loudness_band_ratio.dvar.1',\n",
       " 0.010777978391500196: 'lowlevel.spectral_contrast_valleys.dmean.3',\n",
       " 0.01089815414250738: 'lowlevel.spectral_contrast_valleys.dmean.1',\n",
       " 0.010974774391799634: 'tonal.thpcp.30',\n",
       " 0.011209741608650108: 'lowlevel.spectral_contrast_coeffs.max.0',\n",
       " 0.011386542639741933: 'tonal.thpcp.26',\n",
       " 0.011471657087687165: 'lowlevel.erbbands.dvar2.0_sin',\n",
       " 0.011702812235219977: 'lowlevel.dynamic_complexity_sin',\n",
       " 0.012081673903848823: 'lowlevel.melbands_spread.dvar',\n",
       " 0.012264688848398105: 'lowlevel.barkbands.median.20_sin',\n",
       " 0.012367304175561554: 'lowlevel.spectral_spread.dvar_sin',\n",
       " 0.012380890720937605: 'lowlevel.barkbands.mean.15_sin',\n",
       " 0.012406786826253038: 'lowlevel.barkbands_spread.dvar_sin',\n",
       " 0.013124131815361234: 'lowlevel.erbbands.median.4',\n",
       " 0.013269338236784743: 'lowlevel.spectral_spread.mean',\n",
       " 0.013287630061705054: 'tonal.thpcp.15',\n",
       " 0.013586596510092742: 'lowlevel.barkbands.median.11',\n",
       " 0.013855811794898806: 'lowlevel.melbands.median.1_sin',\n",
       " 0.01426741396285142: 'tonal.hpcp.var.30',\n",
       " 0.014420193425319123: 'lowlevel.spectral_contrast_coeffs.dvar.2',\n",
       " 0.014897466935738372: 'lowlevel.spectral_spread.dmean_sin',\n",
       " 0.015000632535245481: 'tonal.thpcp.16',\n",
       " 0.015157241598533228: 'rhythm.beats_loudness.mean_sin',\n",
       " 0.015511327294128617: 'lowlevel.erbbands_crest.max',\n",
       " 0.01653513315431739: 'lowlevel.erbbands.median.26',\n",
       " 0.016590294566848136: 'lowlevel.barkbands.median.13',\n",
       " 0.016614399386401815: 'tonal.tuning_frequency',\n",
       " 0.017057577101092534: 'lowlevel.barkbands.dmean.1_sin',\n",
       " 0.01707723085669715: 'lowlevel.spectral_skewness.min',\n",
       " 0.017374893780760525: 'lowlevel.barkbands_spread.max',\n",
       " 0.018127635177834785: 'lowlevel.melbands.mean.35',\n",
       " 0.018213278906807635: 'lowlevel.melbands.mean.22',\n",
       " 0.018385894959457222: 'lowlevel.erbbands_flatness_db.mean_sin',\n",
       " 0.01907335596859392: 'lowlevel.barkbands_crest.dvar',\n",
       " 0.019964519076601846: 'lowlevel.barkbands.dmean2.3_sin',\n",
       " 0.02000681287819734: 'rhythm.beats_loudness_band_ratio.mean.2_sin',\n",
       " 0.020443709732810362: 'rhythm.beats_loudness_band_ratio.dvar.2_sin',\n",
       " 0.020661174442632813: 'lowlevel.mfcc.mean.6',\n",
       " 0.02072444336031825: 'lowlevel.barkbands.dvar.1_sin',\n",
       " 0.021115033502221204: 'lowlevel.melbands_crest.dmean',\n",
       " 0.02143612162498017: 'lowlevel.silence_rate_60dB.median',\n",
       " 0.02211908792778749: 'lowlevel.barkbands.dmean.3',\n",
       " 0.02218661406134149: 'lowlevel.dynamic_complexity',\n",
       " 0.02271437127149202: 'tonal.hpcp_entropy.var',\n",
       " 0.023064141764948344: 'rhythm.beats_loudness_band_ratio.dmean.3',\n",
       " 0.023105292767378674: 'lowlevel.spectral_flux.dmean_sin',\n",
       " 0.02349449937292434: 'lowlevel.erbbands.mean.20',\n",
       " 0.023844914221473695: 'lowlevel.mfcc.mean.2',\n",
       " 0.023924816313117242: 'lowlevel.spectral_contrast_coeffs.dvar.0_sin',\n",
       " 0.024261446458117796: 'lowlevel.erbbands_spread.dmean_sin',\n",
       " 0.024364777379699016: 'lowlevel.barkbands_spread.mean',\n",
       " 0.024500628428844762: 'lowlevel.erbbands_flatness_db.max',\n",
       " 0.025375701814716583: 'lowlevel.spectral_flux.dvar_sin',\n",
       " 0.025463862304006265: 'lowlevel.mfcc.mean.3_sin',\n",
       " 0.02570261157582582: 'lowlevel.pitch_salience.dvar_sin',\n",
       " 0.02592271777572311: 'lowlevel.spectral_decrease.median_sin',\n",
       " 0.026315632870792572: 'lowlevel.melbands_spread.max',\n",
       " 0.026507008654347932: 'lowlevel.spectral_contrast_valleys.mean.0',\n",
       " 0.026590554728070887: 'lowlevel.spectral_contrast_valleys.max.3',\n",
       " 0.0267857980323021: 'lowlevel.melbands.dmean.8',\n",
       " 0.027108848924999436: 'lowlevel.spectral_contrast_coeffs.mean.3',\n",
       " 0.027299623402797537: 'lowlevel.mfcc.mean.5',\n",
       " 0.02743477272479013: 'lowlevel.barkbands_flatness_db.min',\n",
       " 0.027652060466304494: 'lowlevel.erbbands_crest.var_sin',\n",
       " 0.028367040831523638: 'lowlevel.mfcc.mean.5_sin',\n",
       " 0.028480421376059138: 'lowlevel.spectral_rolloff.dmean',\n",
       " 0.029390023451730373: 'lowlevel.spectral_complexity.max',\n",
       " 0.030436436160430305: 'tonal.thpcp.9',\n",
       " 0.03072031596698734: 'tonal.hpcp_entropy.mean',\n",
       " 0.03092003633224882: 'rhythm.bpm',\n",
       " 0.031149404815073986: 'tonal.hpcp.var.29',\n",
       " 0.0313497488385507: 'tonal.thpcp.6',\n",
       " 0.03166800483876902: 'lowlevel.barkbands.median.2',\n",
       " 0.03202943945292546: 'lowlevel.pitch_salience.max',\n",
       " 0.03245039791164632: 'lowlevel.spectral_energyband_low.dvar_sin',\n",
       " 0.03538013491090862: 'lowlevel.melbands_crest.var',\n",
       " 0.03592362507077891: 'lowlevel.spectral_energyband_middle_high.median_sin',\n",
       " 0.03668250239688202: 'lowlevel.spectral_contrast_coeffs.dmean.4',\n",
       " 0.037388963499691306: 'lowlevel.erbbands.dmean.9',\n",
       " 0.037865131545358914: 'lowlevel.barkbands.mean.1_sin',\n",
       " 0.03837499846697018: 'rhythm.beats_loudness_band_ratio.dmean.5',\n",
       " 0.03895052730095304: 'lowlevel.spectral_contrast_coeffs.dmean.2',\n",
       " 0.03949803177973011: 'lowlevel.spectral_contrast_coeffs.dvar.0',\n",
       " 0.0397495987344904: 'tonal.hpcp_entropy.mean_exp',\n",
       " 0.04140878276682003: 'rhythm.bpm_histogram_first_peak_spread.max',\n",
       " 0.04216832298351321: 'tonal.tuning_equal_tempered_deviation',\n",
       " 0.04241206926686464: 'lowlevel.barkbands.dmean.7',\n",
       " 0.04295474421883838: 'lowlevel.barkbands.dmean.22_sin',\n",
       " 0.04297983809883896: 'lowlevel.erbbands_spread.dvar_sin',\n",
       " 0.0431031309054516: 'lowlevel.erbbands.mean.35_sin',\n",
       " 0.0436669293434207: 'lowlevel.barkbands.median.18_sin',\n",
       " 0.04476446785939193: 'rhythm.beats_count',\n",
       " 0.04538574664965119: 'lowlevel.spectral_centroid.dmean',\n",
       " 0.04555460916547076: 'lowlevel.spectral_contrast_coeffs.max.3',\n",
       " 0.045585956248470505: 'lowlevel.spectral_spread.mean_sin',\n",
       " 0.04744112962552713: 'tonal.hpcp_entropy.max',\n",
       " 0.0475134045481678: 'lowlevel.barkbands.median.17_sin',\n",
       " 0.0488184021648943: 'lowlevel.spectral_skewness.max',\n",
       " 0.04882987923291725: 'lowlevel.melbands_spread.dvar_sin',\n",
       " 0.04883188136944643: 'tonal.thpcp.27',\n",
       " 0.04914747451580828: 'tonal.hpcp_entropy.max_sin',\n",
       " 0.05062975939721028: 'lowlevel.spectral_contrast_valleys.max.4_sin',\n",
       " 0.05305925083997335: 'lowlevel.pitch_salience.dvar',\n",
       " 0.053401736156364885: 'lowlevel.barkbands_spread.median_sin',\n",
       " 0.053883921740660264: 'lowlevel.spectral_centroid.dmean_sin',\n",
       " 0.05439219746772226: 'lowlevel.spectral_rolloff.max',\n",
       " 0.05508565083173094: 'lowlevel.spectral_energyband_high.dmean_sin',\n",
       " 0.055569659196133915: 'lowlevel.spectral_contrast_coeffs.dvar.3',\n",
       " 0.05604892029099365: 'lowlevel.barkbands.median.3',\n",
       " 0.05761420087035701: 'rhythm.beats_loudness_band_ratio.dvar.0',\n",
       " 0.05877582411471927: 'lowlevel.barkbands_flatness_db.dvar',\n",
       " 0.05936531554919358: 'lowlevel.gfcc.mean.5',\n",
       " 0.05959448553964182: 'rhythm.beats_loudness_band_ratio.mean.0',\n",
       " 0.06108831766943232: 'lowlevel.barkbands.mean.24_sin',\n",
       " 0.0618678343949446: 'lowlevel.spectral_decrease.mean_sin',\n",
       " 0.06303177574074986: 'lowlevel.spectral_contrast_coeffs.var.1_sin',\n",
       " 0.06313777620192962: 'lowlevel.barkbands.median.3_sin',\n",
       " 0.06501445920046486: 'rhythm.beats_loudness_band_ratio.dmean.2',\n",
       " 0.06878800527743871: 'lowlevel.silence_rate_60dB.dmean',\n",
       " 0.07004994120419347: 'rhythm.beats_loudness_band_ratio.mean.2',\n",
       " 0.07026700036991661: 'lowlevel.barkbands_crest.dmean',\n",
       " 0.07090519244111143: 'lowlevel.spectral_contrast_coeffs.max.2',\n",
       " 0.07148580187957444: 'lowlevel.spectral_energyband_middle_low.max',\n",
       " 0.07157692527448649: 'lowlevel.spectral_contrast_valleys.mean.0_sin',\n",
       " 0.07346401532548673: 'lowlevel.spectral_rolloff.mean',\n",
       " 0.07393373286036134: 'lowlevel.spectral_complexity.dmean',\n",
       " 0.07425683634737527: 'lowlevel.erbbands_skewness.mean',\n",
       " 0.07467262980177587: 'rhythm.beats_loudness_band_ratio.dmean.1',\n",
       " 0.07479361094231993: 'lowlevel.spectral_contrast_coeffs.var.0_sin',\n",
       " 0.07487131173881055: 'lowlevel.erbbands_flatness_db.var',\n",
       " 0.07574839498219234: 'lowlevel.pitch_salience.var',\n",
       " 0.07699661682890496: 'lowlevel.barkbands.dmean.24_sin',\n",
       " 0.07748199375169354: 'lowlevel.spectral_contrast_coeffs.var.2',\n",
       " 0.07790059115299931: 'lowlevel.spectral_contrast_coeffs.mean.4',\n",
       " 0.0779357825666593: 'lowlevel.spectral_centroid.max',\n",
       " 0.08210725902337195: 'lowlevel.barkbands.median.2_sin',\n",
       " 0.08231093527756038: 'rhythm.beats_loudness.dmean',\n",
       " 0.08331299941145649: 'lowlevel.spectral_contrast_valleys.median.3_exp',\n",
       " 0.08401418699901181: 'lowlevel.barkbands.median.17',\n",
       " 0.08424405429834293: 'lowlevel.erbbands_skewness.mean_sin',\n",
       " 0.08732825721390519: 'lowlevel.spectral_contrast_coeffs.dmean.3',\n",
       " 0.08750662820785163: 'lowlevel.spectral_contrast_valleys.dmean.1_sin',\n",
       " 0.08828069651133538: 'lowlevel.barkbands.dmean.23_sin',\n",
       " 0.08913771473303048: 'lowlevel.spectral_contrast_coeffs.dmean.5',\n",
       " 0.08979626706244041: 'lowlevel.silence_rate_60dB.mean',\n",
       " 0.09099958117265407: 'lowlevel.barkbands.median.15',\n",
       " 0.09177494424493254: 'tonal.chords_strength.mean',\n",
       " 0.09726564015295501: 'lowlevel.barkbands_flatness_db.var',\n",
       " 0.09788072068410689: 'lowlevel.barkbands.median.18',\n",
       " 0.1021506871125575: 'lowlevel.spectral_contrast_valleys.max.4',\n",
       " 0.10696689246016539: 'lowlevel.spectral_contrast_valleys.dvar.1_sin',\n",
       " 0.11536383788208669: 'lowlevel.spectral_contrast_coeffs.var.3',\n",
       " 0.11673657545245565: 'lowlevel.barkbands_crest.var',\n",
       " 0.11705922352801665: 'lowlevel.melbands_crest.min',\n",
       " 0.12132988109655629: 'lowlevel.barkbands.median.15_sin',\n",
       " 0.12335416114734117: 'rhythm.danceability_sin',\n",
       " 0.12459614485980311: 'lowlevel.barkbands.median.16',\n",
       " 0.12464710744920396: 'lowlevel.spectral_contrast_coeffs.var.3_sin',\n",
       " 0.12582013078864837: 'lowlevel.erbbands_crest.dmean',\n",
       " 0.12685603640246332: 'lowlevel.barkbands.median.16_sin',\n",
       " 0.12952288485381644: 'lowlevel.spectral_contrast_coeffs.dvar.1',\n",
       " 0.12977196502692137: 'lowlevel.spectral_complexity.dvar_sin',\n",
       " 0.13053331838032486: 'lowlevel.average_loudness',\n",
       " 0.1317531554035801: 'tonal.chords_strength.min',\n",
       " 0.13286749458300245: 'lowlevel.spectral_contrast_coeffs.dmean.1',\n",
       " 0.13479096539666563: 'lowlevel.spectral_complexity.mean',\n",
       " 0.14203787521293165: 'lowlevel.melbands_flatness_db.min',\n",
       " 0.15589193571946972: 'rhythm.beats_loudness_band_ratio.dmean.4',\n",
       " 0.156552772326071: 'lowlevel.spectral_centroid.dvar_sin',\n",
       " 0.15704725389141946: 'lowlevel.spectral_contrast_coeffs.var.2_sin',\n",
       " 0.1602898214714658: 'lowlevel.spectral_complexity.var',\n",
       " 0.17239113487264485: 'lowlevel.silence_rate_60dB.dmean_sin',\n",
       " 0.172672248707917: 'lowlevel.spectral_complexity.dvar',\n",
       " 0.1757629816704825: 'rhythm.bpm_histogram_first_peak_weight.max',\n",
       " 0.19223145274160863: 'tonal.chords_changes_rate',\n",
       " 0.23355981279232524: 'rhythm.beats_loudness_band_ratio.dmean2.0_sin',\n",
       " 0.24761247276498344: 'rhythm.onset_rate',\n",
       " 0.2574024996480387: 'rhythm.beats_loudness_band_ratio.dmean.0',\n",
       " 0.3148458373665902: 'lowlevel.average_loudness_sq',\n",
       " 0.3410404905396907: 'tonal.chords_strength.dmean'}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dizio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.3410404905396907, 'tonal.chords_strength.dmean'),\n",
       " (0.3148458373665902, 'lowlevel.average_loudness_sq'),\n",
       " (0.2574024996480387, 'rhythm.beats_loudness_band_ratio.dmean.0'),\n",
       " (0.24761247276498344, 'rhythm.onset_rate'),\n",
       " (0.23355981279232524, 'rhythm.beats_loudness_band_ratio.dmean2.0_sin'),\n",
       " (0.19223145274160863, 'tonal.chords_changes_rate'),\n",
       " (0.1757629816704825, 'rhythm.bpm_histogram_first_peak_weight.max'),\n",
       " (0.172672248707917, 'lowlevel.spectral_complexity.dvar'),\n",
       " (0.17239113487264485, 'lowlevel.silence_rate_60dB.dmean_sin'),\n",
       " (0.1602898214714658, 'lowlevel.spectral_complexity.var'),\n",
       " (0.15704725389141946, 'lowlevel.spectral_contrast_coeffs.var.2_sin'),\n",
       " (0.156552772326071, 'lowlevel.spectral_centroid.dvar_sin'),\n",
       " (0.15589193571946972, 'rhythm.beats_loudness_band_ratio.dmean.4'),\n",
       " (0.14203787521293165, 'lowlevel.melbands_flatness_db.min'),\n",
       " (0.13479096539666563, 'lowlevel.spectral_complexity.mean'),\n",
       " (0.13286749458300245, 'lowlevel.spectral_contrast_coeffs.dmean.1'),\n",
       " (0.1317531554035801, 'tonal.chords_strength.min'),\n",
       " (0.13053331838032486, 'lowlevel.average_loudness'),\n",
       " (0.12977196502692137, 'lowlevel.spectral_complexity.dvar_sin'),\n",
       " (0.12952288485381644, 'lowlevel.spectral_contrast_coeffs.dvar.1'),\n",
       " (0.12685603640246332, 'lowlevel.barkbands.median.16_sin'),\n",
       " (0.12582013078864837, 'lowlevel.erbbands_crest.dmean'),\n",
       " (0.12464710744920396, 'lowlevel.spectral_contrast_coeffs.var.3_sin'),\n",
       " (0.12459614485980311, 'lowlevel.barkbands.median.16'),\n",
       " (0.12335416114734117, 'rhythm.danceability_sin'),\n",
       " (0.12132988109655629, 'lowlevel.barkbands.median.15_sin'),\n",
       " (0.11705922352801665, 'lowlevel.melbands_crest.min'),\n",
       " (0.11673657545245565, 'lowlevel.barkbands_crest.var'),\n",
       " (0.11536383788208669, 'lowlevel.spectral_contrast_coeffs.var.3'),\n",
       " (0.10696689246016539, 'lowlevel.spectral_contrast_valleys.dvar.1_sin'),\n",
       " (0.1021506871125575, 'lowlevel.spectral_contrast_valleys.max.4'),\n",
       " (0.09788072068410689, 'lowlevel.barkbands.median.18'),\n",
       " (0.09726564015295501, 'lowlevel.barkbands_flatness_db.var'),\n",
       " (0.09177494424493254, 'tonal.chords_strength.mean'),\n",
       " (0.09099958117265407, 'lowlevel.barkbands.median.15'),\n",
       " (0.08979626706244041, 'lowlevel.silence_rate_60dB.mean'),\n",
       " (0.08913771473303048, 'lowlevel.spectral_contrast_coeffs.dmean.5'),\n",
       " (0.08828069651133538, 'lowlevel.barkbands.dmean.23_sin'),\n",
       " (0.08750662820785163, 'lowlevel.spectral_contrast_valleys.dmean.1_sin'),\n",
       " (0.08732825721390519, 'lowlevel.spectral_contrast_coeffs.dmean.3'),\n",
       " (0.08424405429834293, 'lowlevel.erbbands_skewness.mean_sin'),\n",
       " (0.08401418699901181, 'lowlevel.barkbands.median.17'),\n",
       " (0.08331299941145649, 'lowlevel.spectral_contrast_valleys.median.3_exp'),\n",
       " (0.08231093527756038, 'rhythm.beats_loudness.dmean'),\n",
       " (0.08210725902337195, 'lowlevel.barkbands.median.2_sin'),\n",
       " (0.0779357825666593, 'lowlevel.spectral_centroid.max'),\n",
       " (0.07790059115299931, 'lowlevel.spectral_contrast_coeffs.mean.4'),\n",
       " (0.07748199375169354, 'lowlevel.spectral_contrast_coeffs.var.2'),\n",
       " (0.07699661682890496, 'lowlevel.barkbands.dmean.24_sin'),\n",
       " (0.07574839498219234, 'lowlevel.pitch_salience.var'),\n",
       " (0.07487131173881055, 'lowlevel.erbbands_flatness_db.var'),\n",
       " (0.07479361094231993, 'lowlevel.spectral_contrast_coeffs.var.0_sin'),\n",
       " (0.07467262980177587, 'rhythm.beats_loudness_band_ratio.dmean.1'),\n",
       " (0.07425683634737527, 'lowlevel.erbbands_skewness.mean'),\n",
       " (0.07393373286036134, 'lowlevel.spectral_complexity.dmean'),\n",
       " (0.07346401532548673, 'lowlevel.spectral_rolloff.mean'),\n",
       " (0.07157692527448649, 'lowlevel.spectral_contrast_valleys.mean.0_sin'),\n",
       " (0.07148580187957444, 'lowlevel.spectral_energyband_middle_low.max'),\n",
       " (0.07090519244111143, 'lowlevel.spectral_contrast_coeffs.max.2'),\n",
       " (0.07026700036991661, 'lowlevel.barkbands_crest.dmean'),\n",
       " (0.07004994120419347, 'rhythm.beats_loudness_band_ratio.mean.2'),\n",
       " (0.06878800527743871, 'lowlevel.silence_rate_60dB.dmean'),\n",
       " (0.06501445920046486, 'rhythm.beats_loudness_band_ratio.dmean.2'),\n",
       " (0.06313777620192962, 'lowlevel.barkbands.median.3_sin'),\n",
       " (0.06303177574074986, 'lowlevel.spectral_contrast_coeffs.var.1_sin'),\n",
       " (0.0618678343949446, 'lowlevel.spectral_decrease.mean_sin'),\n",
       " (0.06108831766943232, 'lowlevel.barkbands.mean.24_sin'),\n",
       " (0.05959448553964182, 'rhythm.beats_loudness_band_ratio.mean.0'),\n",
       " (0.05936531554919358, 'lowlevel.gfcc.mean.5'),\n",
       " (0.05877582411471927, 'lowlevel.barkbands_flatness_db.dvar'),\n",
       " (0.05761420087035701, 'rhythm.beats_loudness_band_ratio.dvar.0'),\n",
       " (0.05604892029099365, 'lowlevel.barkbands.median.3'),\n",
       " (0.055569659196133915, 'lowlevel.spectral_contrast_coeffs.dvar.3'),\n",
       " (0.05508565083173094, 'lowlevel.spectral_energyband_high.dmean_sin'),\n",
       " (0.05439219746772226, 'lowlevel.spectral_rolloff.max'),\n",
       " (0.053883921740660264, 'lowlevel.spectral_centroid.dmean_sin'),\n",
       " (0.053401736156364885, 'lowlevel.barkbands_spread.median_sin'),\n",
       " (0.05305925083997335, 'lowlevel.pitch_salience.dvar'),\n",
       " (0.05062975939721028, 'lowlevel.spectral_contrast_valleys.max.4_sin'),\n",
       " (0.04914747451580828, 'tonal.hpcp_entropy.max_sin'),\n",
       " (0.04883188136944643, 'tonal.thpcp.27'),\n",
       " (0.04882987923291725, 'lowlevel.melbands_spread.dvar_sin'),\n",
       " (0.0488184021648943, 'lowlevel.spectral_skewness.max'),\n",
       " (0.0475134045481678, 'lowlevel.barkbands.median.17_sin'),\n",
       " (0.04744112962552713, 'tonal.hpcp_entropy.max'),\n",
       " (0.045585956248470505, 'lowlevel.spectral_spread.mean_sin'),\n",
       " (0.04555460916547076, 'lowlevel.spectral_contrast_coeffs.max.3'),\n",
       " (0.04538574664965119, 'lowlevel.spectral_centroid.dmean'),\n",
       " (0.04476446785939193, 'rhythm.beats_count'),\n",
       " (0.0436669293434207, 'lowlevel.barkbands.median.18_sin'),\n",
       " (0.0431031309054516, 'lowlevel.erbbands.mean.35_sin'),\n",
       " (0.04297983809883896, 'lowlevel.erbbands_spread.dvar_sin'),\n",
       " (0.04295474421883838, 'lowlevel.barkbands.dmean.22_sin'),\n",
       " (0.04241206926686464, 'lowlevel.barkbands.dmean.7'),\n",
       " (0.04216832298351321, 'tonal.tuning_equal_tempered_deviation'),\n",
       " (0.04140878276682003, 'rhythm.bpm_histogram_first_peak_spread.max'),\n",
       " (0.0397495987344904, 'tonal.hpcp_entropy.mean_exp'),\n",
       " (0.03949803177973011, 'lowlevel.spectral_contrast_coeffs.dvar.0'),\n",
       " (0.03895052730095304, 'lowlevel.spectral_contrast_coeffs.dmean.2'),\n",
       " (0.03837499846697018, 'rhythm.beats_loudness_band_ratio.dmean.5'),\n",
       " (0.037865131545358914, 'lowlevel.barkbands.mean.1_sin'),\n",
       " (0.037388963499691306, 'lowlevel.erbbands.dmean.9'),\n",
       " (0.03668250239688202, 'lowlevel.spectral_contrast_coeffs.dmean.4'),\n",
       " (0.03592362507077891, 'lowlevel.spectral_energyband_middle_high.median_sin'),\n",
       " (0.03538013491090862, 'lowlevel.melbands_crest.var'),\n",
       " (0.03245039791164632, 'lowlevel.spectral_energyband_low.dvar_sin'),\n",
       " (0.03202943945292546, 'lowlevel.pitch_salience.max'),\n",
       " (0.03166800483876902, 'lowlevel.barkbands.median.2'),\n",
       " (0.0313497488385507, 'tonal.thpcp.6'),\n",
       " (0.031149404815073986, 'tonal.hpcp.var.29'),\n",
       " (0.03092003633224882, 'rhythm.bpm'),\n",
       " (0.03072031596698734, 'tonal.hpcp_entropy.mean'),\n",
       " (0.030436436160430305, 'tonal.thpcp.9'),\n",
       " (0.029390023451730373, 'lowlevel.spectral_complexity.max'),\n",
       " (0.028480421376059138, 'lowlevel.spectral_rolloff.dmean'),\n",
       " (0.028367040831523638, 'lowlevel.mfcc.mean.5_sin'),\n",
       " (0.027652060466304494, 'lowlevel.erbbands_crest.var_sin'),\n",
       " (0.02743477272479013, 'lowlevel.barkbands_flatness_db.min'),\n",
       " (0.027299623402797537, 'lowlevel.mfcc.mean.5'),\n",
       " (0.027108848924999436, 'lowlevel.spectral_contrast_coeffs.mean.3'),\n",
       " (0.0267857980323021, 'lowlevel.melbands.dmean.8'),\n",
       " (0.026590554728070887, 'lowlevel.spectral_contrast_valleys.max.3'),\n",
       " (0.026507008654347932, 'lowlevel.spectral_contrast_valleys.mean.0'),\n",
       " (0.026315632870792572, 'lowlevel.melbands_spread.max'),\n",
       " (0.02592271777572311, 'lowlevel.spectral_decrease.median_sin'),\n",
       " (0.02570261157582582, 'lowlevel.pitch_salience.dvar_sin'),\n",
       " (0.025463862304006265, 'lowlevel.mfcc.mean.3_sin'),\n",
       " (0.025375701814716583, 'lowlevel.spectral_flux.dvar_sin'),\n",
       " (0.024500628428844762, 'lowlevel.erbbands_flatness_db.max'),\n",
       " (0.024364777379699016, 'lowlevel.barkbands_spread.mean'),\n",
       " (0.024261446458117796, 'lowlevel.erbbands_spread.dmean_sin'),\n",
       " (0.023924816313117242, 'lowlevel.spectral_contrast_coeffs.dvar.0_sin'),\n",
       " (0.023844914221473695, 'lowlevel.mfcc.mean.2'),\n",
       " (0.02349449937292434, 'lowlevel.erbbands.mean.20'),\n",
       " (0.023105292767378674, 'lowlevel.spectral_flux.dmean_sin'),\n",
       " (0.023064141764948344, 'rhythm.beats_loudness_band_ratio.dmean.3'),\n",
       " (0.02271437127149202, 'tonal.hpcp_entropy.var'),\n",
       " (0.02218661406134149, 'lowlevel.dynamic_complexity'),\n",
       " (0.02211908792778749, 'lowlevel.barkbands.dmean.3'),\n",
       " (0.02143612162498017, 'lowlevel.silence_rate_60dB.median'),\n",
       " (0.021115033502221204, 'lowlevel.melbands_crest.dmean'),\n",
       " (0.02072444336031825, 'lowlevel.barkbands.dvar.1_sin'),\n",
       " (0.020661174442632813, 'lowlevel.mfcc.mean.6'),\n",
       " (0.020443709732810362, 'rhythm.beats_loudness_band_ratio.dvar.2_sin'),\n",
       " (0.02000681287819734, 'rhythm.beats_loudness_band_ratio.mean.2_sin'),\n",
       " (0.019964519076601846, 'lowlevel.barkbands.dmean2.3_sin'),\n",
       " (0.01907335596859392, 'lowlevel.barkbands_crest.dvar'),\n",
       " (0.018385894959457222, 'lowlevel.erbbands_flatness_db.mean_sin'),\n",
       " (0.018213278906807635, 'lowlevel.melbands.mean.22'),\n",
       " (0.018127635177834785, 'lowlevel.melbands.mean.35'),\n",
       " (0.017374893780760525, 'lowlevel.barkbands_spread.max'),\n",
       " (0.01707723085669715, 'lowlevel.spectral_skewness.min'),\n",
       " (0.017057577101092534, 'lowlevel.barkbands.dmean.1_sin'),\n",
       " (0.016614399386401815, 'tonal.tuning_frequency'),\n",
       " (0.016590294566848136, 'lowlevel.barkbands.median.13'),\n",
       " (0.01653513315431739, 'lowlevel.erbbands.median.26'),\n",
       " (0.015511327294128617, 'lowlevel.erbbands_crest.max'),\n",
       " (0.015157241598533228, 'rhythm.beats_loudness.mean_sin'),\n",
       " (0.015000632535245481, 'tonal.thpcp.16'),\n",
       " (0.014897466935738372, 'lowlevel.spectral_spread.dmean_sin'),\n",
       " (0.014420193425319123, 'lowlevel.spectral_contrast_coeffs.dvar.2'),\n",
       " (0.01426741396285142, 'tonal.hpcp.var.30'),\n",
       " (0.013855811794898806, 'lowlevel.melbands.median.1_sin'),\n",
       " (0.013586596510092742, 'lowlevel.barkbands.median.11'),\n",
       " (0.013287630061705054, 'tonal.thpcp.15'),\n",
       " (0.013269338236784743, 'lowlevel.spectral_spread.mean'),\n",
       " (0.013124131815361234, 'lowlevel.erbbands.median.4'),\n",
       " (0.012406786826253038, 'lowlevel.barkbands_spread.dvar_sin'),\n",
       " (0.012380890720937605, 'lowlevel.barkbands.mean.15_sin'),\n",
       " (0.012367304175561554, 'lowlevel.spectral_spread.dvar_sin'),\n",
       " (0.012264688848398105, 'lowlevel.barkbands.median.20_sin'),\n",
       " (0.012081673903848823, 'lowlevel.melbands_spread.dvar'),\n",
       " (0.011702812235219977, 'lowlevel.dynamic_complexity_sin'),\n",
       " (0.011471657087687165, 'lowlevel.erbbands.dvar2.0_sin'),\n",
       " (0.011386542639741933, 'tonal.thpcp.26'),\n",
       " (0.011209741608650108, 'lowlevel.spectral_contrast_coeffs.max.0'),\n",
       " (0.010974774391799634, 'tonal.thpcp.30'),\n",
       " (0.01089815414250738, 'lowlevel.spectral_contrast_valleys.dmean.1'),\n",
       " (0.010777978391500196, 'lowlevel.spectral_contrast_valleys.dmean.3'),\n",
       " (0.010621865977346287, 'rhythm.beats_loudness_band_ratio.dvar.1'),\n",
       " (0.010590275424638482, 'lowlevel.barkbands_spread.var_sin'),\n",
       " (0.010361302736072076, 'rhythm.beats_loudness_band_ratio.mean.0_exp'),\n",
       " (0.010296381469047591, 'lowlevel.zerocrossingrate.min'),\n",
       " (0.010232791020206364, 'lowlevel.spectral_contrast_valleys.median.5'),\n",
       " (0.01008863588242674, 'lowlevel.spectral_flux.mean'),\n",
       " (0.00992212557245645, 'lowlevel.melbands.var.1_sin'),\n",
       " (0.009867901726496656, 'lowlevel.erbbands.dmean.31'),\n",
       " (0.009673822017217122, 'lowlevel.melbands.dmean.35'),\n",
       " (0.00910429730273772, 'lowlevel.spectral_centroid.dvar'),\n",
       " (0.008903109961849525, 'lowlevel.spectral_complexity.max_exp'),\n",
       " (0.008893244586388998, 'lowlevel.barkbands.dmean.21_sin'),\n",
       " (0.008574436450981885, 'lowlevel.barkbands.var.2_sin'),\n",
       " (0.008417138435717486, 'tonal.hpcp.var.9'),\n",
       " (0.008195882869557735, 'lowlevel.spectral_contrast_valleys.dmean.0'),\n",
       " (0.007489150439087425, 'lowlevel.erbbands_spread.var_sin'),\n",
       " (0.007466600637228307, 'lowlevel.barkbands.dvar.2_sin'),\n",
       " (0.007186525135670387, 'lowlevel.barkbands.median.14'),\n",
       " (0.007010620510790412, 'lowlevel.spectral_contrast_coeffs.max.1'),\n",
       " (0.006860725970181304, 'lowlevel.melbands.mean.1'),\n",
       " (0.006633015309044467, 'lowlevel.gfcc.mean.2'),\n",
       " (0.0065956886036730306, 'lowlevel.erbbands.median.4_sin'),\n",
       " (0.005918697184284322, 'lowlevel.erbbands.dvar.1_sin'),\n",
       " (0.005899100973013972, 'rhythm.beats_loudness_band_ratio.var.0'),\n",
       " (0.005832048647182728, 'lowlevel.spectral_flux.dmean'),\n",
       " (0.005491258541673798, 'lowlevel.dissonance.dmean_sin'),\n",
       " (0.005276114332330926, 'lowlevel.gfcc.mean.3'),\n",
       " (0.00496114191293598, 'rhythm.bpm_histogram_second_peak_bpm.max'),\n",
       " (0.004585629075979916, 'lowlevel.melbands_spread.dmean'),\n",
       " (0.004010838625496092, 'tonal.thpcp.8'),\n",
       " (0.0036551606410802325, 'lowlevel.spectral_entropy.var'),\n",
       " (0.0034974665321574113, 'lowlevel.melbands_flatness_db.dvar_sin'),\n",
       " (0.003208774499848502, 'tonal.hpcp.median.28'),\n",
       " (0.0025067197916904113, 'lowlevel.barkbands.median.14_sin'),\n",
       " (0.002350043979226656, 'lowlevel.erbbands.max.14'),\n",
       " (0.0021024674533294437, 'lowlevel.spectral_contrast_valleys.dmean2.4_sin'),\n",
       " (0.002071195954185004, 'lowlevel.erbbands.dmean.12'),\n",
       " (0.0019328794324121605, 'lowlevel.spectral_contrast_valleys.dvar2.1'),\n",
       " (0.0011992883625023718, 'tonal.thpcp.21'),\n",
       " (0.0011594000409584197, 'lowlevel.barkbands.median.13_sin'),\n",
       " (0.0011441159352432373, 'lowlevel.spectral_spread.min'),\n",
       " (0.0010967951910380105, 'tonal.hpcp.median.27'),\n",
       " (0.0007938397533549231, 'lowlevel.spectral_contrast_coeffs.max.5'),\n",
       " (0.0007185182765048143, 'tonal.hpcp.median.7'),\n",
       " (0.0006713634053913806, 'tonal.hpcp.var.3'),\n",
       " (0.00042504987335262025, 'lowlevel.barkbands.dmean.6')]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(dizio.items(),reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tonal.chords_strength.dmean',\n",
       " 'lowlevel.average_loudness_sq',\n",
       " 'rhythm.beats_loudness_band_ratio.dmean.0',\n",
       " 'rhythm.onset_rate',\n",
       " 'rhythm.beats_loudness_band_ratio.dmean2.0_sin',\n",
       " 'tonal.chords_changes_rate',\n",
       " 'rhythm.bpm_histogram_first_peak_weight.max',\n",
       " 'lowlevel.spectral_complexity.dvar',\n",
       " 'lowlevel.silence_rate_60dB.dmean_sin',\n",
       " 'lowlevel.spectral_complexity.var',\n",
       " 'lowlevel.spectral_contrast_coeffs.var.2_sin',\n",
       " 'lowlevel.spectral_centroid.dvar_sin',\n",
       " 'rhythm.beats_loudness_band_ratio.dmean.4',\n",
       " 'lowlevel.melbands_flatness_db.min',\n",
       " 'lowlevel.spectral_complexity.mean',\n",
       " 'lowlevel.spectral_contrast_coeffs.dmean.1',\n",
       " 'tonal.chords_strength.min',\n",
       " 'lowlevel.average_loudness',\n",
       " 'lowlevel.spectral_complexity.dvar_sin',\n",
       " 'lowlevel.spectral_contrast_coeffs.dvar.1',\n",
       " 'lowlevel.barkbands.median.16_sin',\n",
       " 'lowlevel.erbbands_crest.dmean',\n",
       " 'lowlevel.spectral_contrast_coeffs.var.3_sin',\n",
       " 'lowlevel.barkbands.median.16',\n",
       " 'rhythm.danceability_sin',\n",
       " 'lowlevel.barkbands.median.15_sin',\n",
       " 'lowlevel.melbands_crest.min',\n",
       " 'lowlevel.barkbands_crest.var',\n",
       " 'lowlevel.spectral_contrast_coeffs.var.3',\n",
       " 'lowlevel.spectral_contrast_valleys.dvar.1_sin',\n",
       " 'lowlevel.spectral_contrast_valleys.max.4',\n",
       " 'lowlevel.barkbands.median.18',\n",
       " 'lowlevel.barkbands_flatness_db.var',\n",
       " 'tonal.chords_strength.mean',\n",
       " 'lowlevel.barkbands.median.15',\n",
       " 'lowlevel.silence_rate_60dB.mean',\n",
       " 'lowlevel.spectral_contrast_coeffs.dmean.5',\n",
       " 'lowlevel.barkbands.dmean.23_sin',\n",
       " 'lowlevel.spectral_contrast_valleys.dmean.1_sin',\n",
       " 'lowlevel.spectral_contrast_coeffs.dmean.3',\n",
       " 'lowlevel.erbbands_skewness.mean_sin',\n",
       " 'lowlevel.barkbands.median.17',\n",
       " 'lowlevel.spectral_contrast_valleys.median.3_exp',\n",
       " 'rhythm.beats_loudness.dmean',\n",
       " 'lowlevel.barkbands.median.2_sin',\n",
       " 'lowlevel.spectral_centroid.max',\n",
       " 'lowlevel.spectral_contrast_coeffs.mean.4',\n",
       " 'lowlevel.spectral_contrast_coeffs.var.2',\n",
       " 'lowlevel.barkbands.dmean.24_sin',\n",
       " 'lowlevel.pitch_salience.var',\n",
       " 'lowlevel.erbbands_flatness_db.var',\n",
       " 'lowlevel.spectral_contrast_coeffs.var.0_sin',\n",
       " 'rhythm.beats_loudness_band_ratio.dmean.1',\n",
       " 'lowlevel.erbbands_skewness.mean',\n",
       " 'lowlevel.spectral_complexity.dmean',\n",
       " 'lowlevel.spectral_rolloff.mean',\n",
       " 'lowlevel.spectral_contrast_valleys.mean.0_sin',\n",
       " 'lowlevel.spectral_energyband_middle_low.max',\n",
       " 'lowlevel.spectral_contrast_coeffs.max.2',\n",
       " 'lowlevel.barkbands_crest.dmean',\n",
       " 'rhythm.beats_loudness_band_ratio.mean.2',\n",
       " 'lowlevel.silence_rate_60dB.dmean',\n",
       " 'rhythm.beats_loudness_band_ratio.dmean.2',\n",
       " 'lowlevel.barkbands.median.3_sin',\n",
       " 'lowlevel.spectral_contrast_coeffs.var.1_sin',\n",
       " 'lowlevel.spectral_decrease.mean_sin',\n",
       " 'lowlevel.barkbands.mean.24_sin',\n",
       " 'rhythm.beats_loudness_band_ratio.mean.0',\n",
       " 'lowlevel.gfcc.mean.5',\n",
       " 'lowlevel.barkbands_flatness_db.dvar',\n",
       " 'rhythm.beats_loudness_band_ratio.dvar.0',\n",
       " 'lowlevel.barkbands.median.3',\n",
       " 'lowlevel.spectral_contrast_coeffs.dvar.3',\n",
       " 'lowlevel.spectral_energyband_high.dmean_sin',\n",
       " 'lowlevel.spectral_rolloff.max',\n",
       " 'lowlevel.spectral_centroid.dmean_sin',\n",
       " 'lowlevel.barkbands_spread.median_sin',\n",
       " 'lowlevel.pitch_salience.dvar',\n",
       " 'lowlevel.spectral_contrast_valleys.max.4_sin',\n",
       " 'tonal.hpcp_entropy.max_sin',\n",
       " 'tonal.thpcp.27',\n",
       " 'lowlevel.melbands_spread.dvar_sin',\n",
       " 'lowlevel.spectral_skewness.max',\n",
       " 'lowlevel.barkbands.median.17_sin',\n",
       " 'tonal.hpcp_entropy.max',\n",
       " 'lowlevel.spectral_spread.mean_sin',\n",
       " 'lowlevel.spectral_contrast_coeffs.max.3',\n",
       " 'lowlevel.spectral_centroid.dmean',\n",
       " 'rhythm.beats_count',\n",
       " 'lowlevel.barkbands.median.18_sin',\n",
       " 'lowlevel.erbbands.mean.35_sin',\n",
       " 'lowlevel.erbbands_spread.dvar_sin',\n",
       " 'lowlevel.barkbands.dmean.22_sin',\n",
       " 'lowlevel.barkbands.dmean.7',\n",
       " 'tonal.tuning_equal_tempered_deviation',\n",
       " 'rhythm.bpm_histogram_first_peak_spread.max',\n",
       " 'tonal.hpcp_entropy.mean_exp',\n",
       " 'lowlevel.spectral_contrast_coeffs.dvar.0',\n",
       " 'lowlevel.spectral_contrast_coeffs.dmean.2',\n",
       " 'rhythm.beats_loudness_band_ratio.dmean.5',\n",
       " 'lowlevel.barkbands.mean.1_sin',\n",
       " 'lowlevel.erbbands.dmean.9',\n",
       " 'lowlevel.spectral_contrast_coeffs.dmean.4',\n",
       " 'lowlevel.spectral_energyband_middle_high.median_sin',\n",
       " 'lowlevel.melbands_crest.var',\n",
       " 'lowlevel.spectral_energyband_low.dvar_sin',\n",
       " 'lowlevel.pitch_salience.max',\n",
       " 'lowlevel.barkbands.median.2',\n",
       " 'tonal.thpcp.6',\n",
       " 'tonal.hpcp.var.29',\n",
       " 'rhythm.bpm',\n",
       " 'tonal.hpcp_entropy.mean',\n",
       " 'tonal.thpcp.9',\n",
       " 'lowlevel.spectral_complexity.max',\n",
       " 'lowlevel.spectral_rolloff.dmean',\n",
       " 'lowlevel.mfcc.mean.5_sin',\n",
       " 'lowlevel.erbbands_crest.var_sin',\n",
       " 'lowlevel.barkbands_flatness_db.min',\n",
       " 'lowlevel.mfcc.mean.5',\n",
       " 'lowlevel.spectral_contrast_coeffs.mean.3',\n",
       " 'lowlevel.melbands.dmean.8',\n",
       " 'lowlevel.spectral_contrast_valleys.max.3',\n",
       " 'lowlevel.spectral_contrast_valleys.mean.0',\n",
       " 'lowlevel.melbands_spread.max',\n",
       " 'lowlevel.spectral_decrease.median_sin',\n",
       " 'lowlevel.pitch_salience.dvar_sin',\n",
       " 'lowlevel.mfcc.mean.3_sin',\n",
       " 'lowlevel.spectral_flux.dvar_sin',\n",
       " 'lowlevel.erbbands_flatness_db.max',\n",
       " 'lowlevel.barkbands_spread.mean',\n",
       " 'lowlevel.erbbands_spread.dmean_sin',\n",
       " 'lowlevel.spectral_contrast_coeffs.dvar.0_sin',\n",
       " 'lowlevel.mfcc.mean.2',\n",
       " 'lowlevel.erbbands.mean.20',\n",
       " 'lowlevel.spectral_flux.dmean_sin',\n",
       " 'rhythm.beats_loudness_band_ratio.dmean.3',\n",
       " 'tonal.hpcp_entropy.var',\n",
       " 'lowlevel.dynamic_complexity',\n",
       " 'lowlevel.barkbands.dmean.3',\n",
       " 'lowlevel.silence_rate_60dB.median',\n",
       " 'lowlevel.melbands_crest.dmean',\n",
       " 'lowlevel.barkbands.dvar.1_sin',\n",
       " 'lowlevel.mfcc.mean.6',\n",
       " 'rhythm.beats_loudness_band_ratio.dvar.2_sin',\n",
       " 'rhythm.beats_loudness_band_ratio.mean.2_sin',\n",
       " 'lowlevel.barkbands.dmean2.3_sin',\n",
       " 'lowlevel.barkbands_crest.dvar',\n",
       " 'lowlevel.erbbands_flatness_db.mean_sin',\n",
       " 'lowlevel.melbands.mean.22',\n",
       " 'lowlevel.melbands.mean.35',\n",
       " 'lowlevel.barkbands_spread.max',\n",
       " 'lowlevel.spectral_skewness.min',\n",
       " 'lowlevel.barkbands.dmean.1_sin',\n",
       " 'tonal.tuning_frequency',\n",
       " 'lowlevel.barkbands.median.13',\n",
       " 'lowlevel.erbbands.median.26',\n",
       " 'lowlevel.erbbands_crest.max',\n",
       " 'rhythm.beats_loudness.mean_sin',\n",
       " 'tonal.thpcp.16',\n",
       " 'lowlevel.spectral_spread.dmean_sin',\n",
       " 'lowlevel.spectral_contrast_coeffs.dvar.2',\n",
       " 'tonal.hpcp.var.30',\n",
       " 'lowlevel.melbands.median.1_sin',\n",
       " 'lowlevel.barkbands.median.11',\n",
       " 'tonal.thpcp.15',\n",
       " 'lowlevel.spectral_spread.mean',\n",
       " 'lowlevel.erbbands.median.4',\n",
       " 'lowlevel.barkbands_spread.dvar_sin',\n",
       " 'lowlevel.barkbands.mean.15_sin',\n",
       " 'lowlevel.spectral_spread.dvar_sin',\n",
       " 'lowlevel.barkbands.median.20_sin',\n",
       " 'lowlevel.melbands_spread.dvar',\n",
       " 'lowlevel.dynamic_complexity_sin',\n",
       " 'lowlevel.erbbands.dvar2.0_sin',\n",
       " 'tonal.thpcp.26',\n",
       " 'lowlevel.spectral_contrast_coeffs.max.0',\n",
       " 'tonal.thpcp.30',\n",
       " 'lowlevel.spectral_contrast_valleys.dmean.1',\n",
       " 'lowlevel.spectral_contrast_valleys.dmean.3',\n",
       " 'rhythm.beats_loudness_band_ratio.dvar.1',\n",
       " 'lowlevel.barkbands_spread.var_sin',\n",
       " 'rhythm.beats_loudness_band_ratio.mean.0_exp',\n",
       " 'lowlevel.zerocrossingrate.min',\n",
       " 'lowlevel.spectral_contrast_valleys.median.5',\n",
       " 'lowlevel.spectral_flux.mean',\n",
       " 'lowlevel.melbands.var.1_sin',\n",
       " 'lowlevel.erbbands.dmean.31',\n",
       " 'lowlevel.melbands.dmean.35',\n",
       " 'lowlevel.spectral_centroid.dvar',\n",
       " 'lowlevel.spectral_complexity.max_exp',\n",
       " 'lowlevel.barkbands.dmean.21_sin',\n",
       " 'lowlevel.barkbands.var.2_sin',\n",
       " 'tonal.hpcp.var.9',\n",
       " 'lowlevel.spectral_contrast_valleys.dmean.0',\n",
       " 'lowlevel.erbbands_spread.var_sin',\n",
       " 'lowlevel.barkbands.dvar.2_sin',\n",
       " 'lowlevel.barkbands.median.14',\n",
       " 'lowlevel.spectral_contrast_coeffs.max.1',\n",
       " 'lowlevel.melbands.mean.1',\n",
       " 'lowlevel.gfcc.mean.2',\n",
       " 'lowlevel.erbbands.median.4_sin',\n",
       " 'lowlevel.erbbands.dvar.1_sin',\n",
       " 'rhythm.beats_loudness_band_ratio.var.0',\n",
       " 'lowlevel.spectral_flux.dmean',\n",
       " 'lowlevel.dissonance.dmean_sin',\n",
       " 'lowlevel.gfcc.mean.3',\n",
       " 'rhythm.bpm_histogram_second_peak_bpm.max',\n",
       " 'lowlevel.melbands_spread.dmean',\n",
       " 'tonal.thpcp.8',\n",
       " 'lowlevel.spectral_entropy.var',\n",
       " 'lowlevel.melbands_flatness_db.dvar_sin',\n",
       " 'tonal.hpcp.median.28',\n",
       " 'lowlevel.barkbands.median.14_sin',\n",
       " 'lowlevel.erbbands.max.14',\n",
       " 'lowlevel.spectral_contrast_valleys.dmean2.4_sin',\n",
       " 'lowlevel.erbbands.dmean.12',\n",
       " 'lowlevel.spectral_contrast_valleys.dvar2.1',\n",
       " 'tonal.thpcp.21',\n",
       " 'lowlevel.barkbands.median.13_sin',\n",
       " 'lowlevel.spectral_spread.min',\n",
       " 'tonal.hpcp.median.27',\n",
       " 'lowlevel.spectral_contrast_coeffs.max.5',\n",
       " 'tonal.hpcp.median.7',\n",
       " 'tonal.hpcp.var.3',\n",
       " 'lowlevel.barkbands.dmean.6']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var=[i[1] for i in sorted(dizio.items(),reverse=True)]\n",
    "altezze=[i[0] for i in sorted(dizio.items(),reverse=True)]\n",
    "var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.348385484450048"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(dizio.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Container object of 5 artists>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb8f0703610>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "totale=sum(dizio.keys())\n",
    "var=[i[1] for i in sorted(dizio.items(),reverse=True)[:5]]\n",
    "altezze=[i[0] for i in sorted(dizio.items(),reverse=True)[:5]]\n",
    "\n",
    "plt.bar(var,altezze,align=\"center\",width=0.35)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object has no attribute '__getitem__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-cca8d3be10c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maltezze\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdizio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object has no attribute '__getitem__'"
     ]
    }
   ],
   "source": [
    "altezze=[i[0] for i in sorted(dizio.items(),reverse=True)[:5]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rifacciamo la stessa cosa con la libreria sklearn.feature_selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/anaconda/lib/python2.7/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.001, class_weight='balanced', dual=False,\n",
       "          fit_intercept=False, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
       "          random_state=40, solver='saga', tol=0.0001, verbose=0,\n",
       "          warm_start=True)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kj=LogisticRegression(fit_intercept=False,solver=\"saga\",penalty=\"l1\",multi_class=\"multinomial\",warm_start=True,class_weight=\"balanced\",random_state=40,C=0.001)\n",
    "kj.fit(X.iloc[idx_train,:],y[idx_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=SelectFromModel(kj, prefit=True)\n",
    "X_new = model.transform(X.iloc[idx_train,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43876, 225)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.72906434,  0.30807798, -0.40233248, ..., -0.30046189,\n",
       "        -0.76315729, -0.34173983],\n",
       "       [-1.82821164, -0.92846671,  1.37843465, ..., -1.00476506,\n",
       "         0.67450486, -0.65055452],\n",
       "       [-1.93347114, -0.4473279 , -0.6685697 , ..., -1.43387103,\n",
       "         0.95987585, -0.39567469],\n",
       "       ...,\n",
       "       [ 0.89312846,  1.45977589, -0.46881345, ...,  1.63526556,\n",
       "        -0.20801931, -0.46140602],\n",
       "       [ 0.68653409,  0.3206533 , -0.39651549, ..., -0.08500286,\n",
       "         0.97732977, -0.38535856],\n",
       "       [-1.18005553, -0.20064604, -0.01074839, ..., -0.83356042,\n",
       "         0.7733843 ,  0.20508542]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boxplot sul training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lowlevel.average_loudness</th>\n",
       "      <th>lowlevel.barkbands.dmean.0</th>\n",
       "      <th>lowlevel.barkbands.dmean.1</th>\n",
       "      <th>lowlevel.barkbands.dmean.10</th>\n",
       "      <th>lowlevel.barkbands.dmean.11</th>\n",
       "      <th>lowlevel.barkbands.dmean.12</th>\n",
       "      <th>lowlevel.barkbands.dmean.13</th>\n",
       "      <th>lowlevel.barkbands.dmean.14</th>\n",
       "      <th>lowlevel.barkbands.dmean.15</th>\n",
       "      <th>lowlevel.barkbands.dmean.16</th>\n",
       "      <th>...</th>\n",
       "      <th>tonal.key_key_C</th>\n",
       "      <th>tonal.key_key_C#</th>\n",
       "      <th>tonal.key_key_D</th>\n",
       "      <th>tonal.key_key_D#</th>\n",
       "      <th>tonal.key_key_E</th>\n",
       "      <th>tonal.key_key_F</th>\n",
       "      <th>tonal.key_key_F#</th>\n",
       "      <th>tonal.key_key_G</th>\n",
       "      <th>tonal.key_key_G#</th>\n",
       "      <th>tonal.key_scale_minor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.933478</td>\n",
       "      <td>-0.252938</td>\n",
       "      <td>-0.769658</td>\n",
       "      <td>-0.767473</td>\n",
       "      <td>-0.828734</td>\n",
       "      <td>-0.567508</td>\n",
       "      <td>-0.877682</td>\n",
       "      <td>-0.775922</td>\n",
       "      <td>-0.492656</td>\n",
       "      <td>-0.323093</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.326029</td>\n",
       "      <td>-0.245245</td>\n",
       "      <td>-0.328163</td>\n",
       "      <td>-0.257115</td>\n",
       "      <td>3.945435</td>\n",
       "      <td>-0.425187</td>\n",
       "      <td>-0.195689</td>\n",
       "      <td>-0.272166</td>\n",
       "      <td>-0.238888</td>\n",
       "      <td>-1.032949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-1.561443</td>\n",
       "      <td>-0.252196</td>\n",
       "      <td>-0.766901</td>\n",
       "      <td>-1.100435</td>\n",
       "      <td>-1.165131</td>\n",
       "      <td>-0.959365</td>\n",
       "      <td>-0.841397</td>\n",
       "      <td>-0.920995</td>\n",
       "      <td>-0.778780</td>\n",
       "      <td>-0.991258</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.326029</td>\n",
       "      <td>-0.245245</td>\n",
       "      <td>-0.328163</td>\n",
       "      <td>-0.257115</td>\n",
       "      <td>-0.253456</td>\n",
       "      <td>-0.425187</td>\n",
       "      <td>-0.195689</td>\n",
       "      <td>3.674202</td>\n",
       "      <td>-0.238888</td>\n",
       "      <td>-1.032949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.025669</td>\n",
       "      <td>-0.246448</td>\n",
       "      <td>-0.754854</td>\n",
       "      <td>-0.809402</td>\n",
       "      <td>-0.949452</td>\n",
       "      <td>0.403677</td>\n",
       "      <td>-0.723800</td>\n",
       "      <td>-0.406159</td>\n",
       "      <td>-0.707008</td>\n",
       "      <td>-0.811454</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.326029</td>\n",
       "      <td>-0.245245</td>\n",
       "      <td>-0.328163</td>\n",
       "      <td>-0.257115</td>\n",
       "      <td>3.945435</td>\n",
       "      <td>-0.425187</td>\n",
       "      <td>-0.195689</td>\n",
       "      <td>-0.272166</td>\n",
       "      <td>-0.238888</td>\n",
       "      <td>0.968097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.695776</td>\n",
       "      <td>-0.252199</td>\n",
       "      <td>-0.738517</td>\n",
       "      <td>0.192666</td>\n",
       "      <td>0.933054</td>\n",
       "      <td>-0.097670</td>\n",
       "      <td>0.458684</td>\n",
       "      <td>-0.011114</td>\n",
       "      <td>-0.204984</td>\n",
       "      <td>-0.198566</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.326029</td>\n",
       "      <td>-0.245245</td>\n",
       "      <td>-0.328163</td>\n",
       "      <td>-0.257115</td>\n",
       "      <td>-0.253456</td>\n",
       "      <td>-0.425187</td>\n",
       "      <td>-0.195689</td>\n",
       "      <td>3.674202</td>\n",
       "      <td>-0.238888</td>\n",
       "      <td>0.968097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.328220</td>\n",
       "      <td>-0.209634</td>\n",
       "      <td>-0.617558</td>\n",
       "      <td>0.322618</td>\n",
       "      <td>-0.481548</td>\n",
       "      <td>-0.567403</td>\n",
       "      <td>-0.025168</td>\n",
       "      <td>0.261256</td>\n",
       "      <td>-0.354897</td>\n",
       "      <td>-0.143807</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.326029</td>\n",
       "      <td>-0.245245</td>\n",
       "      <td>-0.328163</td>\n",
       "      <td>3.889284</td>\n",
       "      <td>-0.253456</td>\n",
       "      <td>-0.425187</td>\n",
       "      <td>-0.195689</td>\n",
       "      <td>-0.272166</td>\n",
       "      <td>-0.238888</td>\n",
       "      <td>-1.032949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.403754</td>\n",
       "      <td>-0.191243</td>\n",
       "      <td>0.229714</td>\n",
       "      <td>-0.521394</td>\n",
       "      <td>-0.879364</td>\n",
       "      <td>-0.838972</td>\n",
       "      <td>1.140033</td>\n",
       "      <td>0.013459</td>\n",
       "      <td>1.933514</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>...</td>\n",
       "      <td>3.067198</td>\n",
       "      <td>-0.245245</td>\n",
       "      <td>-0.328163</td>\n",
       "      <td>-0.257115</td>\n",
       "      <td>-0.253456</td>\n",
       "      <td>-0.425187</td>\n",
       "      <td>-0.195689</td>\n",
       "      <td>-0.272166</td>\n",
       "      <td>-0.238888</td>\n",
       "      <td>-1.032949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>-0.037093</td>\n",
       "      <td>-0.252802</td>\n",
       "      <td>-0.763122</td>\n",
       "      <td>-0.058935</td>\n",
       "      <td>-0.955006</td>\n",
       "      <td>0.092924</td>\n",
       "      <td>-0.062920</td>\n",
       "      <td>-0.751057</td>\n",
       "      <td>0.822206</td>\n",
       "      <td>1.134482</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.326029</td>\n",
       "      <td>-0.245245</td>\n",
       "      <td>-0.328163</td>\n",
       "      <td>-0.257115</td>\n",
       "      <td>-0.253456</td>\n",
       "      <td>-0.425187</td>\n",
       "      <td>-0.195689</td>\n",
       "      <td>-0.272166</td>\n",
       "      <td>-0.238888</td>\n",
       "      <td>-1.032949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.250347</td>\n",
       "      <td>-0.232370</td>\n",
       "      <td>-0.637411</td>\n",
       "      <td>2.653680</td>\n",
       "      <td>0.434309</td>\n",
       "      <td>0.502723</td>\n",
       "      <td>1.119830</td>\n",
       "      <td>0.371545</td>\n",
       "      <td>0.241938</td>\n",
       "      <td>-1.075317</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.326029</td>\n",
       "      <td>-0.245245</td>\n",
       "      <td>-0.328163</td>\n",
       "      <td>-0.257115</td>\n",
       "      <td>-0.253456</td>\n",
       "      <td>-0.425187</td>\n",
       "      <td>-0.195689</td>\n",
       "      <td>-0.272166</td>\n",
       "      <td>-0.238888</td>\n",
       "      <td>0.968097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>-1.859063</td>\n",
       "      <td>-0.242266</td>\n",
       "      <td>-0.763860</td>\n",
       "      <td>-0.678696</td>\n",
       "      <td>-0.700260</td>\n",
       "      <td>-0.678084</td>\n",
       "      <td>-0.246393</td>\n",
       "      <td>-0.583844</td>\n",
       "      <td>-0.853334</td>\n",
       "      <td>-1.068188</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.326029</td>\n",
       "      <td>-0.245245</td>\n",
       "      <td>-0.328163</td>\n",
       "      <td>3.889284</td>\n",
       "      <td>-0.253456</td>\n",
       "      <td>-0.425187</td>\n",
       "      <td>-0.195689</td>\n",
       "      <td>-0.272166</td>\n",
       "      <td>-0.238888</td>\n",
       "      <td>-1.032949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>-1.723454</td>\n",
       "      <td>-0.252569</td>\n",
       "      <td>-0.762573</td>\n",
       "      <td>0.585290</td>\n",
       "      <td>0.642320</td>\n",
       "      <td>1.165259</td>\n",
       "      <td>1.384593</td>\n",
       "      <td>0.470450</td>\n",
       "      <td>-0.364627</td>\n",
       "      <td>-0.273674</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.326029</td>\n",
       "      <td>-0.245245</td>\n",
       "      <td>-0.328163</td>\n",
       "      <td>3.889284</td>\n",
       "      <td>-0.253456</td>\n",
       "      <td>-0.425187</td>\n",
       "      <td>-0.195689</td>\n",
       "      <td>-0.272166</td>\n",
       "      <td>-0.238888</td>\n",
       "      <td>-1.032949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.456635</td>\n",
       "      <td>-0.245963</td>\n",
       "      <td>-0.766584</td>\n",
       "      <td>-0.664301</td>\n",
       "      <td>-0.874970</td>\n",
       "      <td>-0.644288</td>\n",
       "      <td>-0.988963</td>\n",
       "      <td>-1.025278</td>\n",
       "      <td>-1.041450</td>\n",
       "      <td>-0.920718</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.326029</td>\n",
       "      <td>-0.245245</td>\n",
       "      <td>-0.328163</td>\n",
       "      <td>-0.257115</td>\n",
       "      <td>-0.253456</td>\n",
       "      <td>-0.425187</td>\n",
       "      <td>-0.195689</td>\n",
       "      <td>-0.272166</td>\n",
       "      <td>-0.238888</td>\n",
       "      <td>-1.032949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.385666</td>\n",
       "      <td>-0.253003</td>\n",
       "      <td>-0.772766</td>\n",
       "      <td>-0.609606</td>\n",
       "      <td>-0.882104</td>\n",
       "      <td>-0.744480</td>\n",
       "      <td>-1.082683</td>\n",
       "      <td>-1.120553</td>\n",
       "      <td>-1.055501</td>\n",
       "      <td>-1.018685</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.326029</td>\n",
       "      <td>-0.245245</td>\n",
       "      <td>-0.328163</td>\n",
       "      <td>-0.257115</td>\n",
       "      <td>-0.253456</td>\n",
       "      <td>-0.425187</td>\n",
       "      <td>-0.195689</td>\n",
       "      <td>-0.272166</td>\n",
       "      <td>-0.238888</td>\n",
       "      <td>-1.032949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>-1.789565</td>\n",
       "      <td>-0.248445</td>\n",
       "      <td>-0.760524</td>\n",
       "      <td>0.622826</td>\n",
       "      <td>2.366301</td>\n",
       "      <td>3.054099</td>\n",
       "      <td>-0.185316</td>\n",
       "      <td>-0.364310</td>\n",
       "      <td>-0.873309</td>\n",
       "      <td>-0.971050</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.326029</td>\n",
       "      <td>-0.245245</td>\n",
       "      <td>-0.328163</td>\n",
       "      <td>-0.257115</td>\n",
       "      <td>-0.253456</td>\n",
       "      <td>-0.425187</td>\n",
       "      <td>5.110127</td>\n",
       "      <td>-0.272166</td>\n",
       "      <td>-0.238888</td>\n",
       "      <td>-1.032949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>-1.863409</td>\n",
       "      <td>-0.253001</td>\n",
       "      <td>-0.765305</td>\n",
       "      <td>-0.969464</td>\n",
       "      <td>-1.051239</td>\n",
       "      <td>-1.119407</td>\n",
       "      <td>-1.075171</td>\n",
       "      <td>-1.155094</td>\n",
       "      <td>-1.027695</td>\n",
       "      <td>-1.068110</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.326029</td>\n",
       "      <td>-0.245245</td>\n",
       "      <td>-0.328163</td>\n",
       "      <td>-0.257115</td>\n",
       "      <td>-0.253456</td>\n",
       "      <td>-0.425187</td>\n",
       "      <td>-0.195689</td>\n",
       "      <td>3.674202</td>\n",
       "      <td>-0.238888</td>\n",
       "      <td>-1.032949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.165936</td>\n",
       "      <td>-0.252863</td>\n",
       "      <td>-0.765875</td>\n",
       "      <td>-0.405332</td>\n",
       "      <td>-1.082553</td>\n",
       "      <td>-0.773524</td>\n",
       "      <td>-0.788962</td>\n",
       "      <td>-1.115389</td>\n",
       "      <td>-0.918575</td>\n",
       "      <td>-0.994865</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.326029</td>\n",
       "      <td>-0.245245</td>\n",
       "      <td>-0.328163</td>\n",
       "      <td>-0.257115</td>\n",
       "      <td>-0.253456</td>\n",
       "      <td>-0.425187</td>\n",
       "      <td>-0.195689</td>\n",
       "      <td>3.674202</td>\n",
       "      <td>-0.238888</td>\n",
       "      <td>0.968097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.139320</td>\n",
       "      <td>-0.252860</td>\n",
       "      <td>-0.765845</td>\n",
       "      <td>-0.398386</td>\n",
       "      <td>-1.081786</td>\n",
       "      <td>-0.775745</td>\n",
       "      <td>-0.785849</td>\n",
       "      <td>-1.114492</td>\n",
       "      <td>-0.915221</td>\n",
       "      <td>-0.993254</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.326029</td>\n",
       "      <td>-0.245245</td>\n",
       "      <td>-0.328163</td>\n",
       "      <td>-0.257115</td>\n",
       "      <td>-0.253456</td>\n",
       "      <td>-0.425187</td>\n",
       "      <td>-0.195689</td>\n",
       "      <td>3.674202</td>\n",
       "      <td>-0.238888</td>\n",
       "      <td>0.968097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>-1.917836</td>\n",
       "      <td>-0.251567</td>\n",
       "      <td>-0.746627</td>\n",
       "      <td>-0.665235</td>\n",
       "      <td>-0.657104</td>\n",
       "      <td>-0.654776</td>\n",
       "      <td>-0.807018</td>\n",
       "      <td>-0.784984</td>\n",
       "      <td>-0.843063</td>\n",
       "      <td>-0.841871</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.326029</td>\n",
       "      <td>-0.245245</td>\n",
       "      <td>-0.328163</td>\n",
       "      <td>3.889284</td>\n",
       "      <td>-0.253456</td>\n",
       "      <td>-0.425187</td>\n",
       "      <td>-0.195689</td>\n",
       "      <td>-0.272166</td>\n",
       "      <td>-0.238888</td>\n",
       "      <td>0.968097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.269304</td>\n",
       "      <td>-0.240496</td>\n",
       "      <td>-0.593984</td>\n",
       "      <td>-1.009442</td>\n",
       "      <td>-1.132753</td>\n",
       "      <td>-1.242159</td>\n",
       "      <td>-1.279528</td>\n",
       "      <td>-1.282288</td>\n",
       "      <td>-1.136982</td>\n",
       "      <td>-1.173977</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.326029</td>\n",
       "      <td>-0.245245</td>\n",
       "      <td>-0.328163</td>\n",
       "      <td>-0.257115</td>\n",
       "      <td>-0.253456</td>\n",
       "      <td>-0.425187</td>\n",
       "      <td>-0.195689</td>\n",
       "      <td>-0.272166</td>\n",
       "      <td>-0.238888</td>\n",
       "      <td>0.968097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.749359</td>\n",
       "      <td>-0.253001</td>\n",
       "      <td>-0.772332</td>\n",
       "      <td>-0.661113</td>\n",
       "      <td>-0.508592</td>\n",
       "      <td>-0.229389</td>\n",
       "      <td>0.097514</td>\n",
       "      <td>-0.126870</td>\n",
       "      <td>-0.576591</td>\n",
       "      <td>-0.567994</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.326029</td>\n",
       "      <td>-0.245245</td>\n",
       "      <td>-0.328163</td>\n",
       "      <td>-0.257115</td>\n",
       "      <td>-0.253456</td>\n",
       "      <td>-0.425187</td>\n",
       "      <td>-0.195689</td>\n",
       "      <td>3.674202</td>\n",
       "      <td>-0.238888</td>\n",
       "      <td>-1.032949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.792735</td>\n",
       "      <td>-0.245440</td>\n",
       "      <td>-0.569308</td>\n",
       "      <td>0.074242</td>\n",
       "      <td>-0.418774</td>\n",
       "      <td>-0.059347</td>\n",
       "      <td>0.837759</td>\n",
       "      <td>1.868186</td>\n",
       "      <td>1.595549</td>\n",
       "      <td>0.952370</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.326029</td>\n",
       "      <td>-0.245245</td>\n",
       "      <td>-0.328163</td>\n",
       "      <td>-0.257115</td>\n",
       "      <td>-0.253456</td>\n",
       "      <td>-0.425187</td>\n",
       "      <td>-0.195689</td>\n",
       "      <td>-0.272166</td>\n",
       "      <td>-0.238888</td>\n",
       "      <td>0.968097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>-1.641125</td>\n",
       "      <td>-0.250871</td>\n",
       "      <td>-0.768213</td>\n",
       "      <td>-0.403302</td>\n",
       "      <td>-0.823337</td>\n",
       "      <td>1.527840</td>\n",
       "      <td>-0.607210</td>\n",
       "      <td>-0.555238</td>\n",
       "      <td>0.096251</td>\n",
       "      <td>0.251995</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.326029</td>\n",
       "      <td>-0.245245</td>\n",
       "      <td>-0.328163</td>\n",
       "      <td>-0.257115</td>\n",
       "      <td>-0.253456</td>\n",
       "      <td>-0.425187</td>\n",
       "      <td>-0.195689</td>\n",
       "      <td>-0.272166</td>\n",
       "      <td>-0.238888</td>\n",
       "      <td>-1.032949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>-1.641124</td>\n",
       "      <td>-0.250871</td>\n",
       "      <td>-0.768212</td>\n",
       "      <td>-0.403301</td>\n",
       "      <td>-0.823336</td>\n",
       "      <td>1.527846</td>\n",
       "      <td>-0.607208</td>\n",
       "      <td>-0.555237</td>\n",
       "      <td>0.096253</td>\n",
       "      <td>0.251998</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.326029</td>\n",
       "      <td>-0.245245</td>\n",
       "      <td>-0.328163</td>\n",
       "      <td>-0.257115</td>\n",
       "      <td>-0.253456</td>\n",
       "      <td>-0.425187</td>\n",
       "      <td>-0.195689</td>\n",
       "      <td>-0.272166</td>\n",
       "      <td>-0.238888</td>\n",
       "      <td>-1.032949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>-1.934279</td>\n",
       "      <td>-0.252778</td>\n",
       "      <td>-0.766793</td>\n",
       "      <td>-0.811736</td>\n",
       "      <td>-0.504318</td>\n",
       "      <td>0.030618</td>\n",
       "      <td>0.208357</td>\n",
       "      <td>-0.734322</td>\n",
       "      <td>-0.765695</td>\n",
       "      <td>-0.900364</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.326029</td>\n",
       "      <td>-0.245245</td>\n",
       "      <td>-0.328163</td>\n",
       "      <td>-0.257115</td>\n",
       "      <td>-0.253456</td>\n",
       "      <td>-0.425187</td>\n",
       "      <td>-0.195689</td>\n",
       "      <td>-0.272166</td>\n",
       "      <td>-0.238888</td>\n",
       "      <td>0.968097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.233428</td>\n",
       "      <td>-0.246622</td>\n",
       "      <td>-0.115401</td>\n",
       "      <td>-0.141778</td>\n",
       "      <td>-0.405157</td>\n",
       "      <td>0.355373</td>\n",
       "      <td>-0.099636</td>\n",
       "      <td>0.675836</td>\n",
       "      <td>1.086185</td>\n",
       "      <td>1.148900</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.326029</td>\n",
       "      <td>-0.245245</td>\n",
       "      <td>3.047247</td>\n",
       "      <td>-0.257115</td>\n",
       "      <td>-0.253456</td>\n",
       "      <td>-0.425187</td>\n",
       "      <td>-0.195689</td>\n",
       "      <td>-0.272166</td>\n",
       "      <td>-0.238888</td>\n",
       "      <td>0.968097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.224608</td>\n",
       "      <td>-0.246641</td>\n",
       "      <td>-0.119241</td>\n",
       "      <td>-0.110232</td>\n",
       "      <td>-0.387593</td>\n",
       "      <td>0.347239</td>\n",
       "      <td>-0.095778</td>\n",
       "      <td>0.659473</td>\n",
       "      <td>1.067646</td>\n",
       "      <td>1.177756</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.326029</td>\n",
       "      <td>-0.245245</td>\n",
       "      <td>3.047247</td>\n",
       "      <td>-0.257115</td>\n",
       "      <td>-0.253456</td>\n",
       "      <td>-0.425187</td>\n",
       "      <td>-0.195689</td>\n",
       "      <td>-0.272166</td>\n",
       "      <td>-0.238888</td>\n",
       "      <td>0.968097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.256376</td>\n",
       "      <td>-0.246126</td>\n",
       "      <td>-0.103344</td>\n",
       "      <td>-0.120902</td>\n",
       "      <td>-0.391115</td>\n",
       "      <td>0.344095</td>\n",
       "      <td>-0.100221</td>\n",
       "      <td>0.652203</td>\n",
       "      <td>1.081152</td>\n",
       "      <td>1.192272</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.326029</td>\n",
       "      <td>-0.245245</td>\n",
       "      <td>3.047247</td>\n",
       "      <td>-0.257115</td>\n",
       "      <td>-0.253456</td>\n",
       "      <td>-0.425187</td>\n",
       "      <td>-0.195689</td>\n",
       "      <td>-0.272166</td>\n",
       "      <td>-0.238888</td>\n",
       "      <td>0.968097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>-1.069476</td>\n",
       "      <td>-0.252278</td>\n",
       "      <td>-0.764819</td>\n",
       "      <td>-0.953461</td>\n",
       "      <td>-0.994527</td>\n",
       "      <td>-0.995256</td>\n",
       "      <td>-0.936334</td>\n",
       "      <td>-1.017154</td>\n",
       "      <td>-0.869955</td>\n",
       "      <td>-0.447912</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.326029</td>\n",
       "      <td>-0.245245</td>\n",
       "      <td>-0.328163</td>\n",
       "      <td>-0.257115</td>\n",
       "      <td>-0.253456</td>\n",
       "      <td>-0.425187</td>\n",
       "      <td>-0.195689</td>\n",
       "      <td>3.674202</td>\n",
       "      <td>-0.238888</td>\n",
       "      <td>-1.032949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>-1.928900</td>\n",
       "      <td>-0.246637</td>\n",
       "      <td>-0.730955</td>\n",
       "      <td>-0.180079</td>\n",
       "      <td>2.593203</td>\n",
       "      <td>-0.150819</td>\n",
       "      <td>0.164706</td>\n",
       "      <td>1.823361</td>\n",
       "      <td>0.176422</td>\n",
       "      <td>-0.219386</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.326029</td>\n",
       "      <td>-0.245245</td>\n",
       "      <td>3.047247</td>\n",
       "      <td>-0.257115</td>\n",
       "      <td>-0.253456</td>\n",
       "      <td>-0.425187</td>\n",
       "      <td>-0.195689</td>\n",
       "      <td>-0.272166</td>\n",
       "      <td>-0.238888</td>\n",
       "      <td>-1.032949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>-1.928900</td>\n",
       "      <td>-0.246637</td>\n",
       "      <td>-0.730955</td>\n",
       "      <td>-0.180077</td>\n",
       "      <td>2.593209</td>\n",
       "      <td>-0.150817</td>\n",
       "      <td>0.164708</td>\n",
       "      <td>1.823364</td>\n",
       "      <td>0.176424</td>\n",
       "      <td>-0.219385</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.326029</td>\n",
       "      <td>-0.245245</td>\n",
       "      <td>3.047247</td>\n",
       "      <td>-0.257115</td>\n",
       "      <td>-0.253456</td>\n",
       "      <td>-0.425187</td>\n",
       "      <td>-0.195689</td>\n",
       "      <td>-0.272166</td>\n",
       "      <td>-0.238888</td>\n",
       "      <td>-1.032949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>-0.851286</td>\n",
       "      <td>-0.252011</td>\n",
       "      <td>-0.771737</td>\n",
       "      <td>0.166825</td>\n",
       "      <td>-0.540317</td>\n",
       "      <td>-0.969820</td>\n",
       "      <td>-1.053513</td>\n",
       "      <td>-1.168007</td>\n",
       "      <td>-1.068201</td>\n",
       "      <td>-1.113347</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.326029</td>\n",
       "      <td>-0.245245</td>\n",
       "      <td>-0.328163</td>\n",
       "      <td>-0.257115</td>\n",
       "      <td>-0.253456</td>\n",
       "      <td>-0.425187</td>\n",
       "      <td>-0.195689</td>\n",
       "      <td>-0.272166</td>\n",
       "      <td>-0.238888</td>\n",
       "      <td>-1.032949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175407</th>\n",
       "      <td>0.709537</td>\n",
       "      <td>-0.083387</td>\n",
       "      <td>0.095359</td>\n",
       "      <td>1.338057</td>\n",
       "      <td>0.162141</td>\n",
       "      <td>-0.438185</td>\n",
       "      <td>-0.515730</td>\n",
       "      <td>-0.764466</td>\n",
       "      <td>-0.804132</td>\n",
       "      <td>-1.025775</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.326029</td>\n",
       "      <td>-0.245245</td>\n",
       "      <td>-0.328163</td>\n",
       "      <td>-0.257115</td>\n",
       "      <td>-0.253456</td>\n",
       "      <td>-0.425187</td>\n",
       "      <td>5.110127</td>\n",
       "      <td>-0.272166</td>\n",
       "      <td>-0.238888</td>\n",
       "      <td>0.968097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175410</th>\n",
       "      <td>-0.034583</td>\n",
       "      <td>-0.252850</td>\n",
       "      <td>-0.770590</td>\n",
       "      <td>-0.802179</td>\n",
       "      <td>-1.044911</td>\n",
       "      <td>-1.215112</td>\n",
       "      <td>-1.199144</td>\n",
       "      <td>-1.260811</td>\n",
       "      <td>-1.112071</td>\n",
       "      <td>-1.163022</td>\n",
       "      <td>...</td>\n",
       "      <td>3.067198</td>\n",
       "      <td>-0.245245</td>\n",
       "      <td>-0.328163</td>\n",
       "      <td>-0.257115</td>\n",
       "      <td>-0.253456</td>\n",
       "      <td>-0.425187</td>\n",
       "      <td>-0.195689</td>\n",
       "      <td>-0.272166</td>\n",
       "      <td>-0.238888</td>\n",
       "      <td>-1.032949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175411</th>\n",
       "      <td>-1.932944</td>\n",
       "      <td>-0.252750</td>\n",
       "      <td>-0.762684</td>\n",
       "      <td>-1.068773</td>\n",
       "      <td>-0.808701</td>\n",
       "      <td>-0.618798</td>\n",
       "      <td>-0.817403</td>\n",
       "      <td>-0.567676</td>\n",
       "      <td>-0.952021</td>\n",
       "      <td>-0.856665</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.326029</td>\n",
       "      <td>-0.245245</td>\n",
       "      <td>-0.328163</td>\n",
       "      <td>-0.257115</td>\n",
       "      <td>-0.253456</td>\n",
       "      <td>-0.425187</td>\n",
       "      <td>-0.195689</td>\n",
       "      <td>-0.272166</td>\n",
       "      <td>4.186044</td>\n",
       "      <td>-1.032949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175413</th>\n",
       "      <td>-1.906037</td>\n",
       "      <td>-0.252660</td>\n",
       "      <td>-0.772486</td>\n",
       "      <td>4.683341</td>\n",
       "      <td>-0.842888</td>\n",
       "      <td>-1.110025</td>\n",
       "      <td>-0.580482</td>\n",
       "      <td>-0.957451</td>\n",
       "      <td>-1.019162</td>\n",
       "      <td>-1.015555</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.326029</td>\n",
       "      <td>-0.245245</td>\n",
       "      <td>-0.328163</td>\n",
       "      <td>-0.257115</td>\n",
       "      <td>-0.253456</td>\n",
       "      <td>-0.425187</td>\n",
       "      <td>-0.195689</td>\n",
       "      <td>-0.272166</td>\n",
       "      <td>-0.238888</td>\n",
       "      <td>0.968097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175414</th>\n",
       "      <td>-1.899280</td>\n",
       "      <td>-0.251668</td>\n",
       "      <td>-0.754803</td>\n",
       "      <td>-0.392209</td>\n",
       "      <td>0.302969</td>\n",
       "      <td>-0.115610</td>\n",
       "      <td>-0.408399</td>\n",
       "      <td>-0.628795</td>\n",
       "      <td>-0.548865</td>\n",
       "      <td>-0.665288</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.326029</td>\n",
       "      <td>-0.245245</td>\n",
       "      <td>-0.328163</td>\n",
       "      <td>-0.257115</td>\n",
       "      <td>-0.253456</td>\n",
       "      <td>-0.425187</td>\n",
       "      <td>-0.195689</td>\n",
       "      <td>3.674202</td>\n",
       "      <td>-0.238888</td>\n",
       "      <td>-1.032949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175415</th>\n",
       "      <td>-1.899280</td>\n",
       "      <td>-0.251668</td>\n",
       "      <td>-0.754803</td>\n",
       "      <td>-0.392206</td>\n",
       "      <td>0.302974</td>\n",
       "      <td>-0.115606</td>\n",
       "      <td>-0.408396</td>\n",
       "      <td>-0.628793</td>\n",
       "      <td>-0.548863</td>\n",
       "      <td>-0.665286</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.326029</td>\n",
       "      <td>-0.245245</td>\n",
       "      <td>-0.328163</td>\n",
       "      <td>-0.257115</td>\n",
       "      <td>-0.253456</td>\n",
       "      <td>-0.425187</td>\n",
       "      <td>-0.195689</td>\n",
       "      <td>3.674202</td>\n",
       "      <td>-0.238888</td>\n",
       "      <td>-1.032949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175417</th>\n",
       "      <td>-1.062146</td>\n",
       "      <td>-0.227497</td>\n",
       "      <td>-0.749673</td>\n",
       "      <td>0.019760</td>\n",
       "      <td>-0.163252</td>\n",
       "      <td>0.976363</td>\n",
       "      <td>-0.421603</td>\n",
       "      <td>-0.022824</td>\n",
       "      <td>-0.543641</td>\n",
       "      <td>-0.488750</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.326029</td>\n",
       "      <td>-0.245245</td>\n",
       "      <td>-0.328163</td>\n",
       "      <td>-0.257115</td>\n",
       "      <td>3.945435</td>\n",
       "      <td>-0.425187</td>\n",
       "      <td>-0.195689</td>\n",
       "      <td>-0.272166</td>\n",
       "      <td>-0.238888</td>\n",
       "      <td>0.968097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175419</th>\n",
       "      <td>-1.928564</td>\n",
       "      <td>-0.242027</td>\n",
       "      <td>-0.747964</td>\n",
       "      <td>-1.126145</td>\n",
       "      <td>-1.076406</td>\n",
       "      <td>0.264125</td>\n",
       "      <td>-0.721029</td>\n",
       "      <td>-1.261512</td>\n",
       "      <td>-1.134777</td>\n",
       "      <td>-1.170268</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.326029</td>\n",
       "      <td>-0.245245</td>\n",
       "      <td>-0.328163</td>\n",
       "      <td>-0.257115</td>\n",
       "      <td>-0.253456</td>\n",
       "      <td>-0.425187</td>\n",
       "      <td>-0.195689</td>\n",
       "      <td>-0.272166</td>\n",
       "      <td>4.186044</td>\n",
       "      <td>-1.032949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175422</th>\n",
       "      <td>-1.876137</td>\n",
       "      <td>-0.248189</td>\n",
       "      <td>-0.770411</td>\n",
       "      <td>-0.760739</td>\n",
       "      <td>0.387026</td>\n",
       "      <td>10.138069</td>\n",
       "      <td>0.147496</td>\n",
       "      <td>0.470554</td>\n",
       "      <td>-0.861570</td>\n",
       "      <td>-0.810323</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.326029</td>\n",
       "      <td>-0.245245</td>\n",
       "      <td>3.047247</td>\n",
       "      <td>-0.257115</td>\n",
       "      <td>-0.253456</td>\n",
       "      <td>-0.425187</td>\n",
       "      <td>-0.195689</td>\n",
       "      <td>-0.272166</td>\n",
       "      <td>-0.238888</td>\n",
       "      <td>0.968097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175428</th>\n",
       "      <td>-1.884049</td>\n",
       "      <td>-0.249347</td>\n",
       "      <td>-0.769267</td>\n",
       "      <td>-0.522344</td>\n",
       "      <td>-0.172999</td>\n",
       "      <td>-0.748073</td>\n",
       "      <td>-0.579604</td>\n",
       "      <td>-0.400942</td>\n",
       "      <td>-0.340258</td>\n",
       "      <td>-0.510243</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.326029</td>\n",
       "      <td>4.077536</td>\n",
       "      <td>-0.328163</td>\n",
       "      <td>-0.257115</td>\n",
       "      <td>-0.253456</td>\n",
       "      <td>-0.425187</td>\n",
       "      <td>-0.195689</td>\n",
       "      <td>-0.272166</td>\n",
       "      <td>-0.238888</td>\n",
       "      <td>0.968097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175437</th>\n",
       "      <td>-0.766365</td>\n",
       "      <td>-0.252561</td>\n",
       "      <td>-0.766041</td>\n",
       "      <td>-0.355869</td>\n",
       "      <td>0.531515</td>\n",
       "      <td>-0.366811</td>\n",
       "      <td>-0.024284</td>\n",
       "      <td>-0.495044</td>\n",
       "      <td>-0.699183</td>\n",
       "      <td>-0.627078</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.326029</td>\n",
       "      <td>-0.245245</td>\n",
       "      <td>-0.328163</td>\n",
       "      <td>-0.257115</td>\n",
       "      <td>-0.253456</td>\n",
       "      <td>-0.425187</td>\n",
       "      <td>5.110127</td>\n",
       "      <td>-0.272166</td>\n",
       "      <td>-0.238888</td>\n",
       "      <td>0.968097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175440</th>\n",
       "      <td>-1.907710</td>\n",
       "      <td>-0.250623</td>\n",
       "      <td>-0.771172</td>\n",
       "      <td>2.175510</td>\n",
       "      <td>-0.575050</td>\n",
       "      <td>-0.748409</td>\n",
       "      <td>-0.589581</td>\n",
       "      <td>-1.062304</td>\n",
       "      <td>-0.556833</td>\n",
       "      <td>-0.909060</td>\n",
       "      <td>...</td>\n",
       "      <td>3.067198</td>\n",
       "      <td>-0.245245</td>\n",
       "      <td>-0.328163</td>\n",
       "      <td>-0.257115</td>\n",
       "      <td>-0.253456</td>\n",
       "      <td>-0.425187</td>\n",
       "      <td>-0.195689</td>\n",
       "      <td>-0.272166</td>\n",
       "      <td>-0.238888</td>\n",
       "      <td>0.968097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175442</th>\n",
       "      <td>0.656559</td>\n",
       "      <td>-0.244762</td>\n",
       "      <td>-0.441028</td>\n",
       "      <td>-0.497877</td>\n",
       "      <td>-0.198918</td>\n",
       "      <td>0.059638</td>\n",
       "      <td>-0.182356</td>\n",
       "      <td>-0.715287</td>\n",
       "      <td>-0.356035</td>\n",
       "      <td>0.529078</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.326029</td>\n",
       "      <td>-0.245245</td>\n",
       "      <td>-0.328163</td>\n",
       "      <td>3.889284</td>\n",
       "      <td>-0.253456</td>\n",
       "      <td>-0.425187</td>\n",
       "      <td>-0.195689</td>\n",
       "      <td>-0.272166</td>\n",
       "      <td>-0.238888</td>\n",
       "      <td>-1.032949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175448</th>\n",
       "      <td>-1.253859</td>\n",
       "      <td>-0.252656</td>\n",
       "      <td>-0.772781</td>\n",
       "      <td>0.084791</td>\n",
       "      <td>-0.656532</td>\n",
       "      <td>-0.734182</td>\n",
       "      <td>-0.968919</td>\n",
       "      <td>-1.024479</td>\n",
       "      <td>-0.942395</td>\n",
       "      <td>-0.410265</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.326029</td>\n",
       "      <td>-0.245245</td>\n",
       "      <td>3.047247</td>\n",
       "      <td>-0.257115</td>\n",
       "      <td>-0.253456</td>\n",
       "      <td>-0.425187</td>\n",
       "      <td>-0.195689</td>\n",
       "      <td>-0.272166</td>\n",
       "      <td>-0.238888</td>\n",
       "      <td>0.968097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175449</th>\n",
       "      <td>-1.934298</td>\n",
       "      <td>-0.244575</td>\n",
       "      <td>-0.739613</td>\n",
       "      <td>-0.500561</td>\n",
       "      <td>-0.826032</td>\n",
       "      <td>-0.835080</td>\n",
       "      <td>-0.194489</td>\n",
       "      <td>0.357499</td>\n",
       "      <td>-0.849940</td>\n",
       "      <td>-0.762282</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.326029</td>\n",
       "      <td>-0.245245</td>\n",
       "      <td>-0.328163</td>\n",
       "      <td>-0.257115</td>\n",
       "      <td>-0.253456</td>\n",
       "      <td>-0.425187</td>\n",
       "      <td>-0.195689</td>\n",
       "      <td>-0.272166</td>\n",
       "      <td>-0.238888</td>\n",
       "      <td>0.968097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175452</th>\n",
       "      <td>-1.506687</td>\n",
       "      <td>-0.207015</td>\n",
       "      <td>-0.755979</td>\n",
       "      <td>-1.143210</td>\n",
       "      <td>-1.182036</td>\n",
       "      <td>-1.215631</td>\n",
       "      <td>-1.231180</td>\n",
       "      <td>-1.237657</td>\n",
       "      <td>-1.037270</td>\n",
       "      <td>-1.124223</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.326029</td>\n",
       "      <td>-0.245245</td>\n",
       "      <td>3.047247</td>\n",
       "      <td>-0.257115</td>\n",
       "      <td>-0.253456</td>\n",
       "      <td>-0.425187</td>\n",
       "      <td>-0.195689</td>\n",
       "      <td>-0.272166</td>\n",
       "      <td>-0.238888</td>\n",
       "      <td>-1.032949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175473</th>\n",
       "      <td>-0.932200</td>\n",
       "      <td>-0.250462</td>\n",
       "      <td>-0.742270</td>\n",
       "      <td>-0.352622</td>\n",
       "      <td>-0.526559</td>\n",
       "      <td>-0.490460</td>\n",
       "      <td>-0.467200</td>\n",
       "      <td>-0.216106</td>\n",
       "      <td>-0.373441</td>\n",
       "      <td>-0.824622</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.326029</td>\n",
       "      <td>-0.245245</td>\n",
       "      <td>3.047247</td>\n",
       "      <td>-0.257115</td>\n",
       "      <td>-0.253456</td>\n",
       "      <td>-0.425187</td>\n",
       "      <td>-0.195689</td>\n",
       "      <td>-0.272166</td>\n",
       "      <td>-0.238888</td>\n",
       "      <td>0.968097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175474</th>\n",
       "      <td>-1.928285</td>\n",
       "      <td>-0.252961</td>\n",
       "      <td>-0.752087</td>\n",
       "      <td>-0.915046</td>\n",
       "      <td>-0.265570</td>\n",
       "      <td>-0.662486</td>\n",
       "      <td>-0.443755</td>\n",
       "      <td>-0.742859</td>\n",
       "      <td>-0.833133</td>\n",
       "      <td>-0.283591</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.326029</td>\n",
       "      <td>-0.245245</td>\n",
       "      <td>-0.328163</td>\n",
       "      <td>-0.257115</td>\n",
       "      <td>-0.253456</td>\n",
       "      <td>-0.425187</td>\n",
       "      <td>-0.195689</td>\n",
       "      <td>3.674202</td>\n",
       "      <td>-0.238888</td>\n",
       "      <td>0.968097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175475</th>\n",
       "      <td>-1.928285</td>\n",
       "      <td>-0.252961</td>\n",
       "      <td>-0.752087</td>\n",
       "      <td>-0.915047</td>\n",
       "      <td>-0.265571</td>\n",
       "      <td>-0.662486</td>\n",
       "      <td>-0.443757</td>\n",
       "      <td>-0.742860</td>\n",
       "      <td>-0.833134</td>\n",
       "      <td>-0.283593</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.326029</td>\n",
       "      <td>-0.245245</td>\n",
       "      <td>-0.328163</td>\n",
       "      <td>-0.257115</td>\n",
       "      <td>-0.253456</td>\n",
       "      <td>-0.425187</td>\n",
       "      <td>-0.195689</td>\n",
       "      <td>3.674202</td>\n",
       "      <td>-0.238888</td>\n",
       "      <td>0.968097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175480</th>\n",
       "      <td>-1.312953</td>\n",
       "      <td>-0.251350</td>\n",
       "      <td>-0.692598</td>\n",
       "      <td>0.699915</td>\n",
       "      <td>0.396298</td>\n",
       "      <td>0.811469</td>\n",
       "      <td>0.302677</td>\n",
       "      <td>0.822576</td>\n",
       "      <td>0.512364</td>\n",
       "      <td>-0.341381</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.326029</td>\n",
       "      <td>-0.245245</td>\n",
       "      <td>-0.328163</td>\n",
       "      <td>-0.257115</td>\n",
       "      <td>-0.253456</td>\n",
       "      <td>-0.425187</td>\n",
       "      <td>-0.195689</td>\n",
       "      <td>3.674202</td>\n",
       "      <td>-0.238888</td>\n",
       "      <td>-1.032949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175481</th>\n",
       "      <td>-1.646944</td>\n",
       "      <td>-0.252055</td>\n",
       "      <td>-0.764425</td>\n",
       "      <td>0.035320</td>\n",
       "      <td>1.803804</td>\n",
       "      <td>1.943865</td>\n",
       "      <td>0.812066</td>\n",
       "      <td>2.237956</td>\n",
       "      <td>-0.675188</td>\n",
       "      <td>-0.911580</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.326029</td>\n",
       "      <td>-0.245245</td>\n",
       "      <td>-0.328163</td>\n",
       "      <td>-0.257115</td>\n",
       "      <td>-0.253456</td>\n",
       "      <td>-0.425187</td>\n",
       "      <td>-0.195689</td>\n",
       "      <td>-0.272166</td>\n",
       "      <td>4.186044</td>\n",
       "      <td>-1.032949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175482</th>\n",
       "      <td>-1.646944</td>\n",
       "      <td>-0.252055</td>\n",
       "      <td>-0.764425</td>\n",
       "      <td>0.035320</td>\n",
       "      <td>1.803804</td>\n",
       "      <td>1.943865</td>\n",
       "      <td>0.812066</td>\n",
       "      <td>2.237956</td>\n",
       "      <td>-0.675188</td>\n",
       "      <td>-0.911580</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.326029</td>\n",
       "      <td>-0.245245</td>\n",
       "      <td>-0.328163</td>\n",
       "      <td>-0.257115</td>\n",
       "      <td>-0.253456</td>\n",
       "      <td>-0.425187</td>\n",
       "      <td>-0.195689</td>\n",
       "      <td>-0.272166</td>\n",
       "      <td>4.186044</td>\n",
       "      <td>-1.032949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175486</th>\n",
       "      <td>-1.918536</td>\n",
       "      <td>-0.252771</td>\n",
       "      <td>-0.747044</td>\n",
       "      <td>0.071944</td>\n",
       "      <td>0.042584</td>\n",
       "      <td>0.078288</td>\n",
       "      <td>-0.053827</td>\n",
       "      <td>-0.340060</td>\n",
       "      <td>-0.470820</td>\n",
       "      <td>-0.717709</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.326029</td>\n",
       "      <td>-0.245245</td>\n",
       "      <td>-0.328163</td>\n",
       "      <td>-0.257115</td>\n",
       "      <td>-0.253456</td>\n",
       "      <td>-0.425187</td>\n",
       "      <td>-0.195689</td>\n",
       "      <td>-0.272166</td>\n",
       "      <td>-0.238888</td>\n",
       "      <td>0.968097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175494</th>\n",
       "      <td>0.609896</td>\n",
       "      <td>-0.252906</td>\n",
       "      <td>-0.711627</td>\n",
       "      <td>-0.331287</td>\n",
       "      <td>-0.634694</td>\n",
       "      <td>-0.547932</td>\n",
       "      <td>-0.684133</td>\n",
       "      <td>-0.666754</td>\n",
       "      <td>-0.861824</td>\n",
       "      <td>-0.701500</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.326029</td>\n",
       "      <td>-0.245245</td>\n",
       "      <td>-0.328163</td>\n",
       "      <td>-0.257115</td>\n",
       "      <td>-0.253456</td>\n",
       "      <td>-0.425187</td>\n",
       "      <td>-0.195689</td>\n",
       "      <td>3.674202</td>\n",
       "      <td>-0.238888</td>\n",
       "      <td>-1.032949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175497</th>\n",
       "      <td>-1.389824</td>\n",
       "      <td>-0.252826</td>\n",
       "      <td>-0.769185</td>\n",
       "      <td>0.880398</td>\n",
       "      <td>0.050455</td>\n",
       "      <td>-0.131691</td>\n",
       "      <td>-0.539209</td>\n",
       "      <td>-0.315561</td>\n",
       "      <td>0.135296</td>\n",
       "      <td>-0.505637</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.326029</td>\n",
       "      <td>-0.245245</td>\n",
       "      <td>-0.328163</td>\n",
       "      <td>-0.257115</td>\n",
       "      <td>-0.253456</td>\n",
       "      <td>2.351892</td>\n",
       "      <td>-0.195689</td>\n",
       "      <td>-0.272166</td>\n",
       "      <td>-0.238888</td>\n",
       "      <td>0.968097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175499</th>\n",
       "      <td>-1.835813</td>\n",
       "      <td>-0.251356</td>\n",
       "      <td>-0.768192</td>\n",
       "      <td>-1.086057</td>\n",
       "      <td>-1.038630</td>\n",
       "      <td>-1.227034</td>\n",
       "      <td>-1.278191</td>\n",
       "      <td>-1.290581</td>\n",
       "      <td>-1.142611</td>\n",
       "      <td>-1.165520</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.326029</td>\n",
       "      <td>-0.245245</td>\n",
       "      <td>3.047247</td>\n",
       "      <td>-0.257115</td>\n",
       "      <td>-0.253456</td>\n",
       "      <td>-0.425187</td>\n",
       "      <td>-0.195689</td>\n",
       "      <td>-0.272166</td>\n",
       "      <td>-0.238888</td>\n",
       "      <td>-1.032949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175501</th>\n",
       "      <td>-1.854515</td>\n",
       "      <td>-0.252242</td>\n",
       "      <td>-0.735622</td>\n",
       "      <td>-0.281772</td>\n",
       "      <td>-0.177398</td>\n",
       "      <td>-0.481192</td>\n",
       "      <td>-0.468759</td>\n",
       "      <td>-0.517405</td>\n",
       "      <td>-0.699946</td>\n",
       "      <td>-0.767248</td>\n",
       "      <td>...</td>\n",
       "      <td>3.067198</td>\n",
       "      <td>-0.245245</td>\n",
       "      <td>-0.328163</td>\n",
       "      <td>-0.257115</td>\n",
       "      <td>-0.253456</td>\n",
       "      <td>-0.425187</td>\n",
       "      <td>-0.195689</td>\n",
       "      <td>-0.272166</td>\n",
       "      <td>-0.238888</td>\n",
       "      <td>0.968097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175502</th>\n",
       "      <td>-1.854515</td>\n",
       "      <td>-0.252242</td>\n",
       "      <td>-0.735621</td>\n",
       "      <td>-0.281768</td>\n",
       "      <td>-0.177394</td>\n",
       "      <td>-0.481189</td>\n",
       "      <td>-0.468755</td>\n",
       "      <td>-0.517402</td>\n",
       "      <td>-0.699944</td>\n",
       "      <td>-0.767247</td>\n",
       "      <td>...</td>\n",
       "      <td>3.067198</td>\n",
       "      <td>-0.245245</td>\n",
       "      <td>-0.328163</td>\n",
       "      <td>-0.257115</td>\n",
       "      <td>-0.253456</td>\n",
       "      <td>-0.425187</td>\n",
       "      <td>-0.195689</td>\n",
       "      <td>-0.272166</td>\n",
       "      <td>-0.238888</td>\n",
       "      <td>0.968097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175503</th>\n",
       "      <td>-1.678437</td>\n",
       "      <td>-0.250654</td>\n",
       "      <td>-0.771013</td>\n",
       "      <td>1.152618</td>\n",
       "      <td>4.208599</td>\n",
       "      <td>-0.566432</td>\n",
       "      <td>-0.612386</td>\n",
       "      <td>-0.060338</td>\n",
       "      <td>-0.938777</td>\n",
       "      <td>-0.804255</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.326029</td>\n",
       "      <td>-0.245245</td>\n",
       "      <td>-0.328163</td>\n",
       "      <td>-0.257115</td>\n",
       "      <td>-0.253456</td>\n",
       "      <td>-0.425187</td>\n",
       "      <td>-0.195689</td>\n",
       "      <td>-0.272166</td>\n",
       "      <td>-0.238888</td>\n",
       "      <td>-1.032949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175504</th>\n",
       "      <td>0.445497</td>\n",
       "      <td>-0.250996</td>\n",
       "      <td>-0.772128</td>\n",
       "      <td>-0.363842</td>\n",
       "      <td>0.166301</td>\n",
       "      <td>-0.241091</td>\n",
       "      <td>2.349492</td>\n",
       "      <td>-0.705870</td>\n",
       "      <td>-0.705610</td>\n",
       "      <td>-0.678029</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.326029</td>\n",
       "      <td>4.077536</td>\n",
       "      <td>-0.328163</td>\n",
       "      <td>-0.257115</td>\n",
       "      <td>-0.253456</td>\n",
       "      <td>-0.425187</td>\n",
       "      <td>-0.195689</td>\n",
       "      <td>-0.272166</td>\n",
       "      <td>-0.238888</td>\n",
       "      <td>-1.032949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36947 rows × 1032 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        lowlevel.average_loudness  lowlevel.barkbands.dmean.0  \\\n",
       "1                       -1.933478                   -0.252938   \n",
       "12                      -1.561443                   -0.252196   \n",
       "20                       0.025669                   -0.246448   \n",
       "22                       0.695776                   -0.252199   \n",
       "23                      -0.328220                   -0.209634   \n",
       "24                      -0.403754                   -0.191243   \n",
       "31                      -0.037093                   -0.252802   \n",
       "35                       0.250347                   -0.232370   \n",
       "36                      -1.859063                   -0.242266   \n",
       "40                      -1.723454                   -0.252569   \n",
       "41                       0.456635                   -0.245963   \n",
       "42                       0.385666                   -0.253003   \n",
       "47                      -1.789565                   -0.248445   \n",
       "61                      -1.863409                   -0.253001   \n",
       "63                       0.165936                   -0.252863   \n",
       "64                       0.139320                   -0.252860   \n",
       "66                      -1.917836                   -0.251567   \n",
       "68                       0.269304                   -0.240496   \n",
       "69                       0.749359                   -0.253001   \n",
       "70                       0.792735                   -0.245440   \n",
       "71                      -1.641125                   -0.250871   \n",
       "72                      -1.641124                   -0.250871   \n",
       "84                      -1.934279                   -0.252778   \n",
       "87                       0.233428                   -0.246622   \n",
       "88                       0.224608                   -0.246641   \n",
       "89                       0.256376                   -0.246126   \n",
       "94                      -1.069476                   -0.252278   \n",
       "95                      -1.928900                   -0.246637   \n",
       "96                      -1.928900                   -0.246637   \n",
       "98                      -0.851286                   -0.252011   \n",
       "...                           ...                         ...   \n",
       "175407                   0.709537                   -0.083387   \n",
       "175410                  -0.034583                   -0.252850   \n",
       "175411                  -1.932944                   -0.252750   \n",
       "175413                  -1.906037                   -0.252660   \n",
       "175414                  -1.899280                   -0.251668   \n",
       "175415                  -1.899280                   -0.251668   \n",
       "175417                  -1.062146                   -0.227497   \n",
       "175419                  -1.928564                   -0.242027   \n",
       "175422                  -1.876137                   -0.248189   \n",
       "175428                  -1.884049                   -0.249347   \n",
       "175437                  -0.766365                   -0.252561   \n",
       "175440                  -1.907710                   -0.250623   \n",
       "175442                   0.656559                   -0.244762   \n",
       "175448                  -1.253859                   -0.252656   \n",
       "175449                  -1.934298                   -0.244575   \n",
       "175452                  -1.506687                   -0.207015   \n",
       "175473                  -0.932200                   -0.250462   \n",
       "175474                  -1.928285                   -0.252961   \n",
       "175475                  -1.928285                   -0.252961   \n",
       "175480                  -1.312953                   -0.251350   \n",
       "175481                  -1.646944                   -0.252055   \n",
       "175482                  -1.646944                   -0.252055   \n",
       "175486                  -1.918536                   -0.252771   \n",
       "175494                   0.609896                   -0.252906   \n",
       "175497                  -1.389824                   -0.252826   \n",
       "175499                  -1.835813                   -0.251356   \n",
       "175501                  -1.854515                   -0.252242   \n",
       "175502                  -1.854515                   -0.252242   \n",
       "175503                  -1.678437                   -0.250654   \n",
       "175504                   0.445497                   -0.250996   \n",
       "\n",
       "        lowlevel.barkbands.dmean.1  lowlevel.barkbands.dmean.10  \\\n",
       "1                        -0.769658                    -0.767473   \n",
       "12                       -0.766901                    -1.100435   \n",
       "20                       -0.754854                    -0.809402   \n",
       "22                       -0.738517                     0.192666   \n",
       "23                       -0.617558                     0.322618   \n",
       "24                        0.229714                    -0.521394   \n",
       "31                       -0.763122                    -0.058935   \n",
       "35                       -0.637411                     2.653680   \n",
       "36                       -0.763860                    -0.678696   \n",
       "40                       -0.762573                     0.585290   \n",
       "41                       -0.766584                    -0.664301   \n",
       "42                       -0.772766                    -0.609606   \n",
       "47                       -0.760524                     0.622826   \n",
       "61                       -0.765305                    -0.969464   \n",
       "63                       -0.765875                    -0.405332   \n",
       "64                       -0.765845                    -0.398386   \n",
       "66                       -0.746627                    -0.665235   \n",
       "68                       -0.593984                    -1.009442   \n",
       "69                       -0.772332                    -0.661113   \n",
       "70                       -0.569308                     0.074242   \n",
       "71                       -0.768213                    -0.403302   \n",
       "72                       -0.768212                    -0.403301   \n",
       "84                       -0.766793                    -0.811736   \n",
       "87                       -0.115401                    -0.141778   \n",
       "88                       -0.119241                    -0.110232   \n",
       "89                       -0.103344                    -0.120902   \n",
       "94                       -0.764819                    -0.953461   \n",
       "95                       -0.730955                    -0.180079   \n",
       "96                       -0.730955                    -0.180077   \n",
       "98                       -0.771737                     0.166825   \n",
       "...                            ...                          ...   \n",
       "175407                    0.095359                     1.338057   \n",
       "175410                   -0.770590                    -0.802179   \n",
       "175411                   -0.762684                    -1.068773   \n",
       "175413                   -0.772486                     4.683341   \n",
       "175414                   -0.754803                    -0.392209   \n",
       "175415                   -0.754803                    -0.392206   \n",
       "175417                   -0.749673                     0.019760   \n",
       "175419                   -0.747964                    -1.126145   \n",
       "175422                   -0.770411                    -0.760739   \n",
       "175428                   -0.769267                    -0.522344   \n",
       "175437                   -0.766041                    -0.355869   \n",
       "175440                   -0.771172                     2.175510   \n",
       "175442                   -0.441028                    -0.497877   \n",
       "175448                   -0.772781                     0.084791   \n",
       "175449                   -0.739613                    -0.500561   \n",
       "175452                   -0.755979                    -1.143210   \n",
       "175473                   -0.742270                    -0.352622   \n",
       "175474                   -0.752087                    -0.915046   \n",
       "175475                   -0.752087                    -0.915047   \n",
       "175480                   -0.692598                     0.699915   \n",
       "175481                   -0.764425                     0.035320   \n",
       "175482                   -0.764425                     0.035320   \n",
       "175486                   -0.747044                     0.071944   \n",
       "175494                   -0.711627                    -0.331287   \n",
       "175497                   -0.769185                     0.880398   \n",
       "175499                   -0.768192                    -1.086057   \n",
       "175501                   -0.735622                    -0.281772   \n",
       "175502                   -0.735621                    -0.281768   \n",
       "175503                   -0.771013                     1.152618   \n",
       "175504                   -0.772128                    -0.363842   \n",
       "\n",
       "        lowlevel.barkbands.dmean.11  lowlevel.barkbands.dmean.12  \\\n",
       "1                         -0.828734                    -0.567508   \n",
       "12                        -1.165131                    -0.959365   \n",
       "20                        -0.949452                     0.403677   \n",
       "22                         0.933054                    -0.097670   \n",
       "23                        -0.481548                    -0.567403   \n",
       "24                        -0.879364                    -0.838972   \n",
       "31                        -0.955006                     0.092924   \n",
       "35                         0.434309                     0.502723   \n",
       "36                        -0.700260                    -0.678084   \n",
       "40                         0.642320                     1.165259   \n",
       "41                        -0.874970                    -0.644288   \n",
       "42                        -0.882104                    -0.744480   \n",
       "47                         2.366301                     3.054099   \n",
       "61                        -1.051239                    -1.119407   \n",
       "63                        -1.082553                    -0.773524   \n",
       "64                        -1.081786                    -0.775745   \n",
       "66                        -0.657104                    -0.654776   \n",
       "68                        -1.132753                    -1.242159   \n",
       "69                        -0.508592                    -0.229389   \n",
       "70                        -0.418774                    -0.059347   \n",
       "71                        -0.823337                     1.527840   \n",
       "72                        -0.823336                     1.527846   \n",
       "84                        -0.504318                     0.030618   \n",
       "87                        -0.405157                     0.355373   \n",
       "88                        -0.387593                     0.347239   \n",
       "89                        -0.391115                     0.344095   \n",
       "94                        -0.994527                    -0.995256   \n",
       "95                         2.593203                    -0.150819   \n",
       "96                         2.593209                    -0.150817   \n",
       "98                        -0.540317                    -0.969820   \n",
       "...                             ...                          ...   \n",
       "175407                     0.162141                    -0.438185   \n",
       "175410                    -1.044911                    -1.215112   \n",
       "175411                    -0.808701                    -0.618798   \n",
       "175413                    -0.842888                    -1.110025   \n",
       "175414                     0.302969                    -0.115610   \n",
       "175415                     0.302974                    -0.115606   \n",
       "175417                    -0.163252                     0.976363   \n",
       "175419                    -1.076406                     0.264125   \n",
       "175422                     0.387026                    10.138069   \n",
       "175428                    -0.172999                    -0.748073   \n",
       "175437                     0.531515                    -0.366811   \n",
       "175440                    -0.575050                    -0.748409   \n",
       "175442                    -0.198918                     0.059638   \n",
       "175448                    -0.656532                    -0.734182   \n",
       "175449                    -0.826032                    -0.835080   \n",
       "175452                    -1.182036                    -1.215631   \n",
       "175473                    -0.526559                    -0.490460   \n",
       "175474                    -0.265570                    -0.662486   \n",
       "175475                    -0.265571                    -0.662486   \n",
       "175480                     0.396298                     0.811469   \n",
       "175481                     1.803804                     1.943865   \n",
       "175482                     1.803804                     1.943865   \n",
       "175486                     0.042584                     0.078288   \n",
       "175494                    -0.634694                    -0.547932   \n",
       "175497                     0.050455                    -0.131691   \n",
       "175499                    -1.038630                    -1.227034   \n",
       "175501                    -0.177398                    -0.481192   \n",
       "175502                    -0.177394                    -0.481189   \n",
       "175503                     4.208599                    -0.566432   \n",
       "175504                     0.166301                    -0.241091   \n",
       "\n",
       "        lowlevel.barkbands.dmean.13  lowlevel.barkbands.dmean.14  \\\n",
       "1                         -0.877682                    -0.775922   \n",
       "12                        -0.841397                    -0.920995   \n",
       "20                        -0.723800                    -0.406159   \n",
       "22                         0.458684                    -0.011114   \n",
       "23                        -0.025168                     0.261256   \n",
       "24                         1.140033                     0.013459   \n",
       "31                        -0.062920                    -0.751057   \n",
       "35                         1.119830                     0.371545   \n",
       "36                        -0.246393                    -0.583844   \n",
       "40                         1.384593                     0.470450   \n",
       "41                        -0.988963                    -1.025278   \n",
       "42                        -1.082683                    -1.120553   \n",
       "47                        -0.185316                    -0.364310   \n",
       "61                        -1.075171                    -1.155094   \n",
       "63                        -0.788962                    -1.115389   \n",
       "64                        -0.785849                    -1.114492   \n",
       "66                        -0.807018                    -0.784984   \n",
       "68                        -1.279528                    -1.282288   \n",
       "69                         0.097514                    -0.126870   \n",
       "70                         0.837759                     1.868186   \n",
       "71                        -0.607210                    -0.555238   \n",
       "72                        -0.607208                    -0.555237   \n",
       "84                         0.208357                    -0.734322   \n",
       "87                        -0.099636                     0.675836   \n",
       "88                        -0.095778                     0.659473   \n",
       "89                        -0.100221                     0.652203   \n",
       "94                        -0.936334                    -1.017154   \n",
       "95                         0.164706                     1.823361   \n",
       "96                         0.164708                     1.823364   \n",
       "98                        -1.053513                    -1.168007   \n",
       "...                             ...                          ...   \n",
       "175407                    -0.515730                    -0.764466   \n",
       "175410                    -1.199144                    -1.260811   \n",
       "175411                    -0.817403                    -0.567676   \n",
       "175413                    -0.580482                    -0.957451   \n",
       "175414                    -0.408399                    -0.628795   \n",
       "175415                    -0.408396                    -0.628793   \n",
       "175417                    -0.421603                    -0.022824   \n",
       "175419                    -0.721029                    -1.261512   \n",
       "175422                     0.147496                     0.470554   \n",
       "175428                    -0.579604                    -0.400942   \n",
       "175437                    -0.024284                    -0.495044   \n",
       "175440                    -0.589581                    -1.062304   \n",
       "175442                    -0.182356                    -0.715287   \n",
       "175448                    -0.968919                    -1.024479   \n",
       "175449                    -0.194489                     0.357499   \n",
       "175452                    -1.231180                    -1.237657   \n",
       "175473                    -0.467200                    -0.216106   \n",
       "175474                    -0.443755                    -0.742859   \n",
       "175475                    -0.443757                    -0.742860   \n",
       "175480                     0.302677                     0.822576   \n",
       "175481                     0.812066                     2.237956   \n",
       "175482                     0.812066                     2.237956   \n",
       "175486                    -0.053827                    -0.340060   \n",
       "175494                    -0.684133                    -0.666754   \n",
       "175497                    -0.539209                    -0.315561   \n",
       "175499                    -1.278191                    -1.290581   \n",
       "175501                    -0.468759                    -0.517405   \n",
       "175502                    -0.468755                    -0.517402   \n",
       "175503                    -0.612386                    -0.060338   \n",
       "175504                     2.349492                    -0.705870   \n",
       "\n",
       "        lowlevel.barkbands.dmean.15  lowlevel.barkbands.dmean.16  \\\n",
       "1                         -0.492656                    -0.323093   \n",
       "12                        -0.778780                    -0.991258   \n",
       "20                        -0.707008                    -0.811454   \n",
       "22                        -0.204984                    -0.198566   \n",
       "23                        -0.354897                    -0.143807   \n",
       "24                         1.933514                     0.130400   \n",
       "31                         0.822206                     1.134482   \n",
       "35                         0.241938                    -1.075317   \n",
       "36                        -0.853334                    -1.068188   \n",
       "40                        -0.364627                    -0.273674   \n",
       "41                        -1.041450                    -0.920718   \n",
       "42                        -1.055501                    -1.018685   \n",
       "47                        -0.873309                    -0.971050   \n",
       "61                        -1.027695                    -1.068110   \n",
       "63                        -0.918575                    -0.994865   \n",
       "64                        -0.915221                    -0.993254   \n",
       "66                        -0.843063                    -0.841871   \n",
       "68                        -1.136982                    -1.173977   \n",
       "69                        -0.576591                    -0.567994   \n",
       "70                         1.595549                     0.952370   \n",
       "71                         0.096251                     0.251995   \n",
       "72                         0.096253                     0.251998   \n",
       "84                        -0.765695                    -0.900364   \n",
       "87                         1.086185                     1.148900   \n",
       "88                         1.067646                     1.177756   \n",
       "89                         1.081152                     1.192272   \n",
       "94                        -0.869955                    -0.447912   \n",
       "95                         0.176422                    -0.219386   \n",
       "96                         0.176424                    -0.219385   \n",
       "98                        -1.068201                    -1.113347   \n",
       "...                             ...                          ...   \n",
       "175407                    -0.804132                    -1.025775   \n",
       "175410                    -1.112071                    -1.163022   \n",
       "175411                    -0.952021                    -0.856665   \n",
       "175413                    -1.019162                    -1.015555   \n",
       "175414                    -0.548865                    -0.665288   \n",
       "175415                    -0.548863                    -0.665286   \n",
       "175417                    -0.543641                    -0.488750   \n",
       "175419                    -1.134777                    -1.170268   \n",
       "175422                    -0.861570                    -0.810323   \n",
       "175428                    -0.340258                    -0.510243   \n",
       "175437                    -0.699183                    -0.627078   \n",
       "175440                    -0.556833                    -0.909060   \n",
       "175442                    -0.356035                     0.529078   \n",
       "175448                    -0.942395                    -0.410265   \n",
       "175449                    -0.849940                    -0.762282   \n",
       "175452                    -1.037270                    -1.124223   \n",
       "175473                    -0.373441                    -0.824622   \n",
       "175474                    -0.833133                    -0.283591   \n",
       "175475                    -0.833134                    -0.283593   \n",
       "175480                     0.512364                    -0.341381   \n",
       "175481                    -0.675188                    -0.911580   \n",
       "175482                    -0.675188                    -0.911580   \n",
       "175486                    -0.470820                    -0.717709   \n",
       "175494                    -0.861824                    -0.701500   \n",
       "175497                     0.135296                    -0.505637   \n",
       "175499                    -1.142611                    -1.165520   \n",
       "175501                    -0.699946                    -0.767248   \n",
       "175502                    -0.699944                    -0.767247   \n",
       "175503                    -0.938777                    -0.804255   \n",
       "175504                    -0.705610                    -0.678029   \n",
       "\n",
       "                ...            tonal.key_key_C  tonal.key_key_C#  \\\n",
       "1               ...                  -0.326029         -0.245245   \n",
       "12              ...                  -0.326029         -0.245245   \n",
       "20              ...                  -0.326029         -0.245245   \n",
       "22              ...                  -0.326029         -0.245245   \n",
       "23              ...                  -0.326029         -0.245245   \n",
       "24              ...                   3.067198         -0.245245   \n",
       "31              ...                  -0.326029         -0.245245   \n",
       "35              ...                  -0.326029         -0.245245   \n",
       "36              ...                  -0.326029         -0.245245   \n",
       "40              ...                  -0.326029         -0.245245   \n",
       "41              ...                  -0.326029         -0.245245   \n",
       "42              ...                  -0.326029         -0.245245   \n",
       "47              ...                  -0.326029         -0.245245   \n",
       "61              ...                  -0.326029         -0.245245   \n",
       "63              ...                  -0.326029         -0.245245   \n",
       "64              ...                  -0.326029         -0.245245   \n",
       "66              ...                  -0.326029         -0.245245   \n",
       "68              ...                  -0.326029         -0.245245   \n",
       "69              ...                  -0.326029         -0.245245   \n",
       "70              ...                  -0.326029         -0.245245   \n",
       "71              ...                  -0.326029         -0.245245   \n",
       "72              ...                  -0.326029         -0.245245   \n",
       "84              ...                  -0.326029         -0.245245   \n",
       "87              ...                  -0.326029         -0.245245   \n",
       "88              ...                  -0.326029         -0.245245   \n",
       "89              ...                  -0.326029         -0.245245   \n",
       "94              ...                  -0.326029         -0.245245   \n",
       "95              ...                  -0.326029         -0.245245   \n",
       "96              ...                  -0.326029         -0.245245   \n",
       "98              ...                  -0.326029         -0.245245   \n",
       "...             ...                        ...               ...   \n",
       "175407          ...                  -0.326029         -0.245245   \n",
       "175410          ...                   3.067198         -0.245245   \n",
       "175411          ...                  -0.326029         -0.245245   \n",
       "175413          ...                  -0.326029         -0.245245   \n",
       "175414          ...                  -0.326029         -0.245245   \n",
       "175415          ...                  -0.326029         -0.245245   \n",
       "175417          ...                  -0.326029         -0.245245   \n",
       "175419          ...                  -0.326029         -0.245245   \n",
       "175422          ...                  -0.326029         -0.245245   \n",
       "175428          ...                  -0.326029          4.077536   \n",
       "175437          ...                  -0.326029         -0.245245   \n",
       "175440          ...                   3.067198         -0.245245   \n",
       "175442          ...                  -0.326029         -0.245245   \n",
       "175448          ...                  -0.326029         -0.245245   \n",
       "175449          ...                  -0.326029         -0.245245   \n",
       "175452          ...                  -0.326029         -0.245245   \n",
       "175473          ...                  -0.326029         -0.245245   \n",
       "175474          ...                  -0.326029         -0.245245   \n",
       "175475          ...                  -0.326029         -0.245245   \n",
       "175480          ...                  -0.326029         -0.245245   \n",
       "175481          ...                  -0.326029         -0.245245   \n",
       "175482          ...                  -0.326029         -0.245245   \n",
       "175486          ...                  -0.326029         -0.245245   \n",
       "175494          ...                  -0.326029         -0.245245   \n",
       "175497          ...                  -0.326029         -0.245245   \n",
       "175499          ...                  -0.326029         -0.245245   \n",
       "175501          ...                   3.067198         -0.245245   \n",
       "175502          ...                   3.067198         -0.245245   \n",
       "175503          ...                  -0.326029         -0.245245   \n",
       "175504          ...                  -0.326029          4.077536   \n",
       "\n",
       "        tonal.key_key_D  tonal.key_key_D#  tonal.key_key_E  tonal.key_key_F  \\\n",
       "1             -0.328163         -0.257115         3.945435        -0.425187   \n",
       "12            -0.328163         -0.257115        -0.253456        -0.425187   \n",
       "20            -0.328163         -0.257115         3.945435        -0.425187   \n",
       "22            -0.328163         -0.257115        -0.253456        -0.425187   \n",
       "23            -0.328163          3.889284        -0.253456        -0.425187   \n",
       "24            -0.328163         -0.257115        -0.253456        -0.425187   \n",
       "31            -0.328163         -0.257115        -0.253456        -0.425187   \n",
       "35            -0.328163         -0.257115        -0.253456        -0.425187   \n",
       "36            -0.328163          3.889284        -0.253456        -0.425187   \n",
       "40            -0.328163          3.889284        -0.253456        -0.425187   \n",
       "41            -0.328163         -0.257115        -0.253456        -0.425187   \n",
       "42            -0.328163         -0.257115        -0.253456        -0.425187   \n",
       "47            -0.328163         -0.257115        -0.253456        -0.425187   \n",
       "61            -0.328163         -0.257115        -0.253456        -0.425187   \n",
       "63            -0.328163         -0.257115        -0.253456        -0.425187   \n",
       "64            -0.328163         -0.257115        -0.253456        -0.425187   \n",
       "66            -0.328163          3.889284        -0.253456        -0.425187   \n",
       "68            -0.328163         -0.257115        -0.253456        -0.425187   \n",
       "69            -0.328163         -0.257115        -0.253456        -0.425187   \n",
       "70            -0.328163         -0.257115        -0.253456        -0.425187   \n",
       "71            -0.328163         -0.257115        -0.253456        -0.425187   \n",
       "72            -0.328163         -0.257115        -0.253456        -0.425187   \n",
       "84            -0.328163         -0.257115        -0.253456        -0.425187   \n",
       "87             3.047247         -0.257115        -0.253456        -0.425187   \n",
       "88             3.047247         -0.257115        -0.253456        -0.425187   \n",
       "89             3.047247         -0.257115        -0.253456        -0.425187   \n",
       "94            -0.328163         -0.257115        -0.253456        -0.425187   \n",
       "95             3.047247         -0.257115        -0.253456        -0.425187   \n",
       "96             3.047247         -0.257115        -0.253456        -0.425187   \n",
       "98            -0.328163         -0.257115        -0.253456        -0.425187   \n",
       "...                 ...               ...              ...              ...   \n",
       "175407        -0.328163         -0.257115        -0.253456        -0.425187   \n",
       "175410        -0.328163         -0.257115        -0.253456        -0.425187   \n",
       "175411        -0.328163         -0.257115        -0.253456        -0.425187   \n",
       "175413        -0.328163         -0.257115        -0.253456        -0.425187   \n",
       "175414        -0.328163         -0.257115        -0.253456        -0.425187   \n",
       "175415        -0.328163         -0.257115        -0.253456        -0.425187   \n",
       "175417        -0.328163         -0.257115         3.945435        -0.425187   \n",
       "175419        -0.328163         -0.257115        -0.253456        -0.425187   \n",
       "175422         3.047247         -0.257115        -0.253456        -0.425187   \n",
       "175428        -0.328163         -0.257115        -0.253456        -0.425187   \n",
       "175437        -0.328163         -0.257115        -0.253456        -0.425187   \n",
       "175440        -0.328163         -0.257115        -0.253456        -0.425187   \n",
       "175442        -0.328163          3.889284        -0.253456        -0.425187   \n",
       "175448         3.047247         -0.257115        -0.253456        -0.425187   \n",
       "175449        -0.328163         -0.257115        -0.253456        -0.425187   \n",
       "175452         3.047247         -0.257115        -0.253456        -0.425187   \n",
       "175473         3.047247         -0.257115        -0.253456        -0.425187   \n",
       "175474        -0.328163         -0.257115        -0.253456        -0.425187   \n",
       "175475        -0.328163         -0.257115        -0.253456        -0.425187   \n",
       "175480        -0.328163         -0.257115        -0.253456        -0.425187   \n",
       "175481        -0.328163         -0.257115        -0.253456        -0.425187   \n",
       "175482        -0.328163         -0.257115        -0.253456        -0.425187   \n",
       "175486        -0.328163         -0.257115        -0.253456        -0.425187   \n",
       "175494        -0.328163         -0.257115        -0.253456        -0.425187   \n",
       "175497        -0.328163         -0.257115        -0.253456         2.351892   \n",
       "175499         3.047247         -0.257115        -0.253456        -0.425187   \n",
       "175501        -0.328163         -0.257115        -0.253456        -0.425187   \n",
       "175502        -0.328163         -0.257115        -0.253456        -0.425187   \n",
       "175503        -0.328163         -0.257115        -0.253456        -0.425187   \n",
       "175504        -0.328163         -0.257115        -0.253456        -0.425187   \n",
       "\n",
       "        tonal.key_key_F#  tonal.key_key_G  tonal.key_key_G#  \\\n",
       "1              -0.195689        -0.272166         -0.238888   \n",
       "12             -0.195689         3.674202         -0.238888   \n",
       "20             -0.195689        -0.272166         -0.238888   \n",
       "22             -0.195689         3.674202         -0.238888   \n",
       "23             -0.195689        -0.272166         -0.238888   \n",
       "24             -0.195689        -0.272166         -0.238888   \n",
       "31             -0.195689        -0.272166         -0.238888   \n",
       "35             -0.195689        -0.272166         -0.238888   \n",
       "36             -0.195689        -0.272166         -0.238888   \n",
       "40             -0.195689        -0.272166         -0.238888   \n",
       "41             -0.195689        -0.272166         -0.238888   \n",
       "42             -0.195689        -0.272166         -0.238888   \n",
       "47              5.110127        -0.272166         -0.238888   \n",
       "61             -0.195689         3.674202         -0.238888   \n",
       "63             -0.195689         3.674202         -0.238888   \n",
       "64             -0.195689         3.674202         -0.238888   \n",
       "66             -0.195689        -0.272166         -0.238888   \n",
       "68             -0.195689        -0.272166         -0.238888   \n",
       "69             -0.195689         3.674202         -0.238888   \n",
       "70             -0.195689        -0.272166         -0.238888   \n",
       "71             -0.195689        -0.272166         -0.238888   \n",
       "72             -0.195689        -0.272166         -0.238888   \n",
       "84             -0.195689        -0.272166         -0.238888   \n",
       "87             -0.195689        -0.272166         -0.238888   \n",
       "88             -0.195689        -0.272166         -0.238888   \n",
       "89             -0.195689        -0.272166         -0.238888   \n",
       "94             -0.195689         3.674202         -0.238888   \n",
       "95             -0.195689        -0.272166         -0.238888   \n",
       "96             -0.195689        -0.272166         -0.238888   \n",
       "98             -0.195689        -0.272166         -0.238888   \n",
       "...                  ...              ...               ...   \n",
       "175407          5.110127        -0.272166         -0.238888   \n",
       "175410         -0.195689        -0.272166         -0.238888   \n",
       "175411         -0.195689        -0.272166          4.186044   \n",
       "175413         -0.195689        -0.272166         -0.238888   \n",
       "175414         -0.195689         3.674202         -0.238888   \n",
       "175415         -0.195689         3.674202         -0.238888   \n",
       "175417         -0.195689        -0.272166         -0.238888   \n",
       "175419         -0.195689        -0.272166          4.186044   \n",
       "175422         -0.195689        -0.272166         -0.238888   \n",
       "175428         -0.195689        -0.272166         -0.238888   \n",
       "175437          5.110127        -0.272166         -0.238888   \n",
       "175440         -0.195689        -0.272166         -0.238888   \n",
       "175442         -0.195689        -0.272166         -0.238888   \n",
       "175448         -0.195689        -0.272166         -0.238888   \n",
       "175449         -0.195689        -0.272166         -0.238888   \n",
       "175452         -0.195689        -0.272166         -0.238888   \n",
       "175473         -0.195689        -0.272166         -0.238888   \n",
       "175474         -0.195689         3.674202         -0.238888   \n",
       "175475         -0.195689         3.674202         -0.238888   \n",
       "175480         -0.195689         3.674202         -0.238888   \n",
       "175481         -0.195689        -0.272166          4.186044   \n",
       "175482         -0.195689        -0.272166          4.186044   \n",
       "175486         -0.195689        -0.272166         -0.238888   \n",
       "175494         -0.195689         3.674202         -0.238888   \n",
       "175497         -0.195689        -0.272166         -0.238888   \n",
       "175499         -0.195689        -0.272166         -0.238888   \n",
       "175501         -0.195689        -0.272166         -0.238888   \n",
       "175502         -0.195689        -0.272166         -0.238888   \n",
       "175503         -0.195689        -0.272166         -0.238888   \n",
       "175504         -0.195689        -0.272166         -0.238888   \n",
       "\n",
       "        tonal.key_scale_minor  \n",
       "1                   -1.032949  \n",
       "12                  -1.032949  \n",
       "20                   0.968097  \n",
       "22                   0.968097  \n",
       "23                  -1.032949  \n",
       "24                  -1.032949  \n",
       "31                  -1.032949  \n",
       "35                   0.968097  \n",
       "36                  -1.032949  \n",
       "40                  -1.032949  \n",
       "41                  -1.032949  \n",
       "42                  -1.032949  \n",
       "47                  -1.032949  \n",
       "61                  -1.032949  \n",
       "63                   0.968097  \n",
       "64                   0.968097  \n",
       "66                   0.968097  \n",
       "68                   0.968097  \n",
       "69                  -1.032949  \n",
       "70                   0.968097  \n",
       "71                  -1.032949  \n",
       "72                  -1.032949  \n",
       "84                   0.968097  \n",
       "87                   0.968097  \n",
       "88                   0.968097  \n",
       "89                   0.968097  \n",
       "94                  -1.032949  \n",
       "95                  -1.032949  \n",
       "96                  -1.032949  \n",
       "98                  -1.032949  \n",
       "...                       ...  \n",
       "175407               0.968097  \n",
       "175410              -1.032949  \n",
       "175411              -1.032949  \n",
       "175413               0.968097  \n",
       "175414              -1.032949  \n",
       "175415              -1.032949  \n",
       "175417               0.968097  \n",
       "175419              -1.032949  \n",
       "175422               0.968097  \n",
       "175428               0.968097  \n",
       "175437               0.968097  \n",
       "175440               0.968097  \n",
       "175442              -1.032949  \n",
       "175448               0.968097  \n",
       "175449               0.968097  \n",
       "175452              -1.032949  \n",
       "175473               0.968097  \n",
       "175474               0.968097  \n",
       "175475               0.968097  \n",
       "175480              -1.032949  \n",
       "175481              -1.032949  \n",
       "175482              -1.032949  \n",
       "175486               0.968097  \n",
       "175494              -1.032949  \n",
       "175497               0.968097  \n",
       "175499              -1.032949  \n",
       "175501               0.968097  \n",
       "175502               0.968097  \n",
       "175503              -1.032949  \n",
       "175504              -1.032949  \n",
       "\n",
       "[36947 rows x 1032 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[y==\"Classical\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "xjazz,xclassical,xmetal,xtechnohouse,xhiphop=X[y==\"Jazz\"],X[y==\"Classical\"],X[y==\"Metal\"],X[y==\"Techno-House\"],X[y==\"Hip-Hop\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33867, 36947, 43501, 43133, 18058)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1=len(xjazz['tonal.chords_strength.dmean'])\n",
    "l2=len(xclassical['tonal.chords_strength.dmean'])\n",
    "l3=len(xmetal['tonal.chords_strength.dmean'])\n",
    "l4=len(xtechnohouse['tonal.chords_strength.dmean'])\n",
    "l5=len(xhiphop['tonal.chords_strength.dmean'])\n",
    "l1,l2,l3,l4,l5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BOXPLOTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VARIABILE CHE SPIEGA DI PIù MARGINALMENTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/anaconda/lib/python2.7/site-packages/numpy/core/fromnumeric.py:52: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  return getattr(obj, method)(*args, **kwds)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Text(0,0,u\"['Jazz']\"),\n",
       " Text(0,0,u\"['Classical']\"),\n",
       " Text(0,0,u\"['Techno-House']\"),\n",
       " Text(0,0,u\"['Hip-Hop']\"),\n",
       " Text(0,0,u\"['Metal']\")]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f85399a9f50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax=plt.subplots()\n",
    "ax.boxplot([X[y==\"Jazz\"]['tonal.chords_strength.dmean'],X[y==\"Classical\"]['tonal.chords_strength.dmean'],X[y==\"Techno-House\"]['tonal.chords_strength.dmean'],X[y==\"Hip-Hop\"]['tonal.chords_strength.dmean'],X[y==\"Metal\"]['tonal.chords_strength.dmean']])\n",
    "ax.set_xticklabels([['Jazz'],['Classical'],[\"Techno-House\"],[\"Hip-Hop\"],[\"Metal\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VARIABILE CHE SPIEGA MENO MARGINALMENTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0,0,u\"['Jazz']\"),\n",
       " Text(0,0,u\"['Classical']\"),\n",
       " Text(0,0,u\"['Techno-House']\"),\n",
       " Text(0,0,u\"['Hip-Hop']\"),\n",
       " Text(0,0,u\"['Metal']\")]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f85399632d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax=plt.subplots()\n",
    "ax.boxplot([X[y==\"Jazz\"]['lowlevel.barkbands.dmean.6'],X[y==\"Classical\"]['lowlevel.barkbands.dmean.6'],X[y==\"Techno-House\"]['lowlevel.barkbands.dmean.6'],X[y==\"Hip-Hop\"]['lowlevel.barkbands.dmean.6'],X[y==\"Metal\"]['lowlevel.barkbands.dmean.6']])\n",
    "ax.set_xticklabels([['Jazz'],['Classical'],[\"Techno-House\"],[\"Hip-Hop\"],[\"Metal\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
